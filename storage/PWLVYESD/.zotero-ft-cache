IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022

1301

Multi-Layer Computation Ofﬂoading in Distributed Heterogeneous Mobile Edge Computing Networks
Pengfei Wang , Graduate Student Member, IEEE, Boya Di , Member, IEEE, Lingyang Song, Fellow, IEEE, and Nicholas R. Jennings, Fellow, IEEE

Abstract—In this paper, we consider distributed heterogeneous multi-layer mobile edge computing (HetMEC) networks, where resource-poor edge devices (EDs) upload computing tasks for processing to the mobile edge computing (MEC) servers and a cloud center (CC). To reduce total energy consumption, computation ofﬂoading and resource allocation are independently performed by each device and each server. However, due to the partial information available at each device and server, the ofﬂoading strategies may overwhelm the layers above. This may lead to network congestion, i.e., so many tasks are ofﬂoaded to the same node that this node is overloaded. To address this problem, we develop a smart pricing mechanism to coordinate the computation ofﬂoading of multi-layer devices, where the CC charges the MEC servers and EDs for computing services and network congestion. In particular, to satisfy the latency constraints of each task, we construct a Lagrangian framework where multi-agent reinforcement learning is utilized by each MEC server to determine its ofﬂoading strategies and resource allocation, so that the total energy consumption is reduced. Simulation results show that our algorithm achieves an energy consumption reduction of 28% and a decrease in congestion probability of between 28% and 100% compared to the state of the art.
Index Terms—Minimum energy control, distributed computing, resource management.
I. INTRODUCTION
W ITH the emergence of various mobile applications propelled by the increasing popularity of mobile devices, vast numbers of computation-intensive and energy-consuming tasks are generated at edge devices (EDs), i.e., mobile devices
Manuscript received October 27, 2021; revised January 31, 2022; accepted March 18, 2022. Date of publication March 24, 2022; date of current version June 9, 2022. This work was supported by the National Nature Science Foundation of China under grant number 61941101 and 61931019, and in part by Beijing Natural Science Foundation under Grant L212027. This current submission is an extension of our conference paper [1] published at the IEEE ICC, Dublin, Ireland, June 2020 [DOI: 10.1109/ICC40277.2020.9148801]. Our conference paper [1] only describes the basic model and presents some preliminary results. We have rewritten the major parts of the paper to present the problem statement and proposed algorithm more clearly. We have enriched the related works on the distributed methods. The theoretical analysis and simulation results have been greatly extended. The associate editor coordinating the review of this article and approving it for publication was N. Zhang. (Corresponding authors: Lingyang Song; Boya Di.)
Pengfei Wang, Boya Di, and Lingyang Song are with the National Engineering Laboratory for Big Data Analysis and Applications, Department of Electronics, Peking University, Beijing 100871, China (e-mail: wangpengfei13@pku.edu.cn; diboya@pku.edu.cn; lingyang.song@ pku.edu.cn).
Nicholas R. Jennings is with the Department of Computer Science, Loughborough University, Loughborough LE11 3TU, U.K. (e-mail: n.r.jennings@lboro.ac.uk).
Digital Object Identiﬁer 10.1109/TCCN.2022.3161955

at the edge of the communication network [2]. Typical applications include virtual and augmented reality, face recognition and monitoring data analysis [2]. To overcome the challenges of the resource-poor and battery-limited mobile devices for processing such tasks, mobile edge computing (MEC) has been proposed to enable the computation to be performed at the MEC servers [3]. However, tremendous computation burden is placed on the MEC servers which are often equipped with limited computing capacities. To further mitigate this issue, heterogeneous multi-layer MEC (HetMEC) has been proposed [4], where the computing tasks of EDs can be ﬁrst ofﬂoaded to the MEC servers, and then the tasks that cannot be processed by MEC servers are further ofﬂoaded to a cloud center (CC). Effectively exploring the computation ofﬂoading among multiple layers in the HetMEC network allows the computing resources of both MEC servers and CC to be fully exploited to support the computation-intensive tasks of EDs.
To extend battery lifetime of devices, energy saving is a key goal in HetMEC networks. Since the energy consumption of the computing and transmission varies at different devices (i.e., ED, MEC server, and CC), effective energy saving requires the suitable computation ofﬂoading and resource allocation among multiple devices on different layers [5]. However, such coordination introduces a heavy signaling overhead for the centralized management of computation ofﬂoading strategies. They require global information about all devices at the central node [4], [6], [7], which is not practical enough especially when the MEC servers belong to different operators. Thus, a distributed scheme is desirable in which each device determines its computation ofﬂoading and resource allocation individually. However, such distributed approaches bring two main challenges:
• It is hard to achieve the overall energy saving goal in a distributed HetMEC network. Servers with different computing capacities, serving areas, and energy consumption models only make independent strategies to minimize their own energy consumption, which usually deviates from the goal of reducing the total energy consumption.
• The individual decisions made by different servers are likely to induce the data aggregation due to the partial information available at each other. The network congestion occurs when the amount of aggregated data surpasses that servers’ computing capacity.
To handle these challenges, we adopt a pricing-based distributed approach, where the CC charges EDs and MEC servers for providing computing services and compensating

2332-7731 c 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

1302

IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022

for the loss of network congestion they cause. When a high price is charged, the EDs and MEC servers are driven to process computing tasks locally for lower cost rather than to upload tasks to the upper-layer. However, in traditional pricing mechanisms [10], [11], given an undifferentiated price for various devices, similar ofﬂoading decisions may be made by MEC servers, which leads to the computation overload at one node. To avoid the congestion induced by computation overload, we develop a multi-layer smart pricing mechanism that uses differentiated prices for various devices on multiple layers, so as to adjust the ofﬂoading behaviors of different device respectively. Moreover, coordinated by the developed smart pricing mechanism, the interests of each ED, MEC server and CC are aligned to the overall energy saving target. Thus, the global energy consumption reduction can be realized by the distributed computation ofﬂoading and resource allocation of different devices.
Several existing works investigate distributed energyefﬁcient computation ofﬂoading and resource allocation in either single-server [12]–[16] or multi-server [17]–[20] twolayer MEC networks. For single-server MEC networks, [13]–[15] utilize game theory for the distributed computation ofﬂoading and resource allocation. A Nash equilibrium is achieved via the distributed computation ofﬂoading or multiagent stochastic learning of multiple interacting devices. By charging mobile users a fee for the congestion they cause, [12] proposes a pricing mechanism for a single MEC server which ensures the selﬁsh mobile users make socially beneﬁcial ofﬂoading decisions. For multi-server MEC networks, [19] proposes a coalitional game-based pricing scheme to arrange computation ofﬂoading between EDs and MEC servers, where each scheduled ED selects the MEC server within the same coalition and pays for the MEC service.
Unfortunately, these aforementioned works do not fully consider the interactions of computation ofﬂoading and resource allocation between the CC and multiple MEC servers in a distributed HetMEC network. The self-interested decisions may cause the concentrated computation ofﬂoading that overloads the receiving node, but the network congestion loss induced by such self-interested decisions is not fully investigated, thus resulting in the waste of energy and resources [13]–[20]. Though congestion games could be utilized to model the competition of selﬁsh players for resources [21], this line of work traditionally assumes that the cost functions of all players for a resource are the same. However, given the heterogeneous nature1 of devices in the HetMEC network, the energy consumption of the ED, MEC server and CC differs when processing the same task. Thus, the congestion games cannot resolve our difﬁculty.
Against this background, the main contributions of our work are summarized as below:
• We design a pricing-based multi-layer computation ofﬂoading scheme to reduce the total energy consumption of the distributed HetMEC network. A novel method

Fig. 1. The multi-layer HetMEC network architecture.
is developed for the CC to adjust prices discriminatively for multiple MEC servers and EDs on different layers. Such developed pricing mechanism aligns the targets of these self-interested devices to the overall energy saving in that distributed network. • Different MEC servers determine their own computation ofﬂoading and resource allocation schemes using the multi-agent reinforcement learning (RL) in a Lagrangian framework. Given such developed Lagrangian-based multi-agent RL framework, each MEC server can be guaranteed to achieve a feasible ofﬂoading strategy satisfying all constraints, thus greatly alleviating the network congestion. • Theoretical analysis shows that our mechanism can always meet all latency constraints even though only partial environment information is known to each node. Simulation results show that our algorithm obtains a 28% energy consumption reduction and a maximum 100% network congestion alleviation compared to the state of the art schemes. The rest of the paper is organized as follows. In Section II we describe the system model of the distributed HetMEC network. In Section III we formulate the distributed energy consumption minimization problem. To solve this problem, we design a pricing based distributed task ofﬂoading and resource allocation algorithm, and analyze the feasibility as well as ofﬂoading strategies in Section IV. Simulation results are given in Section VI. Finally the conclusions are drawn in Section VII.
II. SYSTEM MODEL
We ﬁrst describe the pricing based distributed HetMEC network, and then present the computing model, transmission model and energy consumption model of each device.
A. Scenario Description
As shown in Fig. 1, we consider a three-layer HetMEC network consisting of one CC on the top layer, M MEC servers2 (integrated with access points(APs)) in the middle

1Although the heterogeneous nature of HetMEC has been discussed in [4], the authors only investigate a centralized latency minimization approach without considering the distributed feature of servers or discussing the energy saving.

2Given a three-layer HetMEC network, we use APs (Access Points) to represent MEC servers in the radio access network in this paper, because the MEC servers and APs are usually integrated to realize both the computing and data transmission.

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MULTI-LAYER COMPUTATION OFFLOADING IN DISTRIBUTED HETEROGENEOUS MEC NETWORKS

1303

layer and N EDs on the bottom layer. The EDs connect with the APs via wireless links according to the distance-aware3 criteria [22], and the APs communicate with the CC via wired links.
A typical uplink computation ofﬂoading scenario is considered, where the computing tasks are generated at the EDs and the task can be processed at the ED, AP or CC. For each task, each ED chooses to process locally or ofﬂoad to the AP via wireless link individually. Similarly, the AP either processes the received task itself or continues to ofﬂoad the task to the CC via a wired link [4]. The CC then processes all tasks received from the APs. Binary ofﬂoading is performed.4 The processing results are fed back to the ED.5 However, due to the incomplete view of the environment for each device in such a distributed network, the individual decisions of devices may not avoid network congestion or satisfy latency constraints.
To resolve this issue, we use a smart pricing based multilayer computation ofﬂoading strategy in the Lagrangian framework.6 The strategy maintains the stable functioning of the distributed HetMEC network while minimizing each device’s ofﬂoading cost (e.g., energy consumption) during task processing. Speciﬁcally, the CC charge other devices (including APs and EDs) to compensate for its resources usage and congestion cost7 for processing their ofﬂoaded tasks, thereby motivating other devices to adjust their strategies. According to the prices announced by the CC, the EDs and APs make their ofﬂoading decisions by weighing the cost of processing themselves and ofﬂoading to the upper layer. Therefore, the CC coordinates the ofﬂoading decisions of EDs and APs dynamically by adjusting the prices according to the real-time data generation speed of tasks.
Remark 1: In the discussed HetMEC network, we focus on reducing the network congestion induced by improper computation ofﬂoading strategies in approach of adjusting the multi-layer computation ofﬂoading and resource allocation scheme. For the case where the network is congested whatever the ofﬂoading strategies due to the large amount of data, we have discussed in our other work [9], which is not the focus of this paper.
B. Computing Model
1) Edge Device: The EDs, including the smart phones, cameras, sensors and so on, communicate with the AP via wireless links. The set of N EDs is denoted by N . We consider the data generation process in each time unit T0 at the ED. The amount of data generated in each time unit at ED i is denoted by λi , and the number of total CPU cycles required per unit of time to process these data, i.e., the computing load,
3In the distance-aware criteria, the ED is associated with the AP with the minimum distance.
4Binary ofﬂoading model is generally applied for the highly integrated task that is impartible and has to be processed as a whole at the ED, AP or CC, e.g., the image recognition task that require all information of the whole image.
5Since the amount of results is usually much smaller than that of the raw data, we only consider the uplink transmissions.
6Our proposed pricing based ofﬂoading strategy can also be expanded to the partial ofﬂoading case.
7The congestion cost refers to the additional resource consumption cost of the CC resulted from the congestion.

is denoted by bi . The data generation speed of ED i can be expressed by λi /T0.
The computation ofﬂoading indicator at the ED i on the bottom layer is denoted by xib ∈ {0, 1}, where the data are processed at the ED when xib = 1 and ofﬂoaded to the AP when xib = 0. Thus, the amount of data processed to the ED i is expressed by λi xib . Therefore, the computing capacity of ED i, denoted by θib , should ensure that

θib ≥ xib bi /T0, ∀1 ≤ i ≤ N ,

(1)

θib ≤ Θbi , ∀1 ≤ i ≤ N ,

(2)

where Θbi represents the upper bound of the computing capacity of ED i. Therefore, the computing time of ED i can be
expressed by

tib,comp

=

bi xib θib

.

(3)

2) Access Point: The AP receives the uploaded tasks from
the connected EDs via wireless links, and chooses to process
them itself or to ofﬂoad to the CC. Let M denote the set of
APs. The number of EDs connected to AP j is denoted by Nj , the set of which is expressed by Nj .
We introduce a binary variable xim to indicate whether the AP on the middle layer processes the task delivered from ED i, and thus, the amount of data that the AP processes is λi xim . Similarly, the computation ofﬂoading indicator at the CC on
the top layer for the data generated at the ED i is denoted by xit . Different tasks assigned to the same AP are processed in parallel using their allocated computing capacity. The comput-
ing capacity of AP j allocated to the task uploaded from ED i is denoted by θjm,i , which should satisfy

θjm,i ≥ xim bi /T0, ∀i ∈ Nj , 1 ≤ j ≤ M ,

(4)

θjm,i ≤ Θmj , ∀1 ≤ j ≤ M ,

(5)

i ∈Nj

awnhderΘe mjximisbithreepurpepseerntbsouthned

required CPU cycles for the of the computing capacity of

AP, the

AP j. Therefore, the computing time of the data from ED i at

AP j can be expressed by [23]

tim,comp

=

bi xim θjm,i

.

(6)

3) Cloud Center: Different tasks received by the CC are
processed in parallel using the allocated computing capacity. The amount of data ofﬂoaded to the CC from ED i is λi xit , and the computing capacity of the CC allocated to ED i for processing its data is denoted by θit , which should satisfy that

θit ≥ xit bi /T0,

(7)

N

θit ≤ θ0t ,

(8)

i =1

where θ0t denotes the upper bound of the computing capacity of the CC. Therefore, to avoid the congestion, the total amount

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

1304

IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022
TABLE I SUMMARY OF KEY NOTATION

of ofﬂoaded data should be smaller than the total computing capacity of the CC, expressed by

N

θ0t ≥ xit bi /T0.

(9)

i =1

Considering the task ofﬂoaded from ED i, the computing time at the CC can be calculated by

tit,comp

=

bi xit θit

.

(10)

C. Transmission Model

We consider the linear correlated transmission resources, e.g., the bandwidth resources in the Ethernet and the frequency resources in the wireless network [24], which represent the fact that the transmission data rate is linearly related to the amount of transmission resources. Therefore, we model the delays in a linear way as the load over the allocated capacity.
1) Edge Device: Orthogonal channels with bandwidth W are allocated to the wireless links between the EDs and the AP, and the set of these channels are denoted by K = {1, 2, . . . , K }. The transmission power of ED i is denoted by pi . The transmission data rate from ED i to AP j can be expressed by

ri,j (pi ) = W · log

1

+

pi gi,j σ2

,

(11)

where gi,j is the channel gain of the wireless channel between ED i and AP j, and σ2 denotes the variance of the additive white Gaussian noise (AWGN). The channel gain is deﬁned by

gi ,j

=

G |h0(k ) |2 (di,j )α

,

(12)

where G is the power gain constant introduced by the ampliﬁer and antenna, h0(k) ∼ CN (0, 1) is a complex Gaussian variable

representing the Rayleigh fading,8 and di,j is the distance from ED i to AP j, and α is the fading factor [26]. The transmission rate between ED i and AP j should satisfy that
ri,j (pi ) ≥ 1 − xib λi /T0, ∀1 ≤ i ≤ N , 1 ≤ j ≤ M , i ∈ Nj , (13)
where λi (1 − xib ) is the amount of raw data transmitted to the AP. The transmission latency from the ED i to the AP is given by

tib,tran

=

λi 1 − xib ri,j (pi )

.

(14)

2) Access Point: Considering the task uploaded from ED i, when the AP j continues to deliver these data up to the CC, the required wired transmission rate φi should satisfy that

φi ≥ xit λi /T0,

(15)

where λi xit is the amount of raw data ofﬂoaded to the CC from ED i. Therefore, the transmission time of these data from AP
j to the CC can be calculated by

tim,tran

=

λi xit φi

.

(16)

The wired transmission resources of all APs allocated by the CC are constrained by the amount of total transmission resources possessed by the CC, denoted by φ0, expressed by

N

φ0 ≥ φi .

(17)

i =1

8The Rayleigh fading is reasonable for modeling the effect of heavily builtup urban environments on radio signals, especially when there is no dominant propagation along a line of sight between the transmitter and receiver [25].

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MULTI-LAYER COMPUTATION OFFLOADING IN DISTRIBUTED HETEROGENEOUS MEC NETWORKS

1305

D. Energy Consumption Model
1) Edge Device: The energy consumption of the ED includes the computing and transmission consumption [14]. The computing energy consumption of ED i is expressed by

Eib,c = κb bi xib

θib

2
,

(18)

where κb is the effective switched capacitance depending on the chip architecture at the ED, and θib denotes the computing capacity (CPU cycles per second) of ED i. The transmission
energy consumption of ED i is expressed by

Eib,t = pi tib,tran ,

(19)

which is proportional to the transmission power and transmission time of ED i. Therefore, the energy consumption of ED i is expressed by

Eib = Eib,c + Eib,t .

(20)

2) Access Point: For AP j, e.g., the base station equipped
with an MEC server, we consider the computation energy
consumption with low CPU voltage [27], [28], which is given by9

⎛

⎞⎛

⎞2

Ejm = κm ⎝

bi xim ⎠⎝

θjm,i ⎠ ,

(21)

i ∈Nj

i ∈Nj

where κm is the effective switched capacitance depending on

the chip architecture at the AP, total required CPU cycles of AP

j,

ai ∈ndNjθbjm,iixidmenroetpersestheentcs otmhe-

puting capacity (CPU cycles per second) of AP j allocated to

the data from ED i [27].

3) Cloud Center: The energy consumption of the CC can

be expressed by

N

Et =

β1 θit ε + β2 · tit,comp ,

(22)

i =1

where β1 and β2 are positive constants, and the parameter ε ranges from 2.5 to 3 [27], and tit,comp represents the computing time for the CC to process the task ofﬂoaded from ED i.

The total energy consumption of the whole network includes
the energy consumption of the CC, the APs and the EDs, which can be expressed10 by

M

N

E (x , p, θ , φ) = E t (x , θ ) + Ejm (x , θ , φ) + Eib (x , p, θ ),

j =1

i =1

(23)

where E t is the energy consumption of the CC as shown
in (22), Ejm denotes the energy consumption of AP j as shown in (21), and Eib represents the energy consumption of ED i as shown in (20). According to the different computation ofﬂoad-

ing strategies, the latency of processing the task generated at

ED i can be classiﬁed to three cases:

1)

When 1, xim

the =

task of 0, xit

ED i is processed = 0, the latency

locally, comes

i.e., xib = from the

computing time of ED;

2) When the task of ED i is processed at the AP, i.e.,
xib = 0, xim = 1, xit = 0, the latency comes from the transmission time of ED and the computing time of AP;

3) When the task of ED i is processed at the CC, i.e.,
xib = 0, xim = 0, xit = 1, the latency consists of the transmission time of ED and AP, as well as the

computing time of CC.

Therefore, we present the latency of processing the task

generated by ED i as below.

ti = xib tib,comp + xim · tib,tran + tim,comp + xit · tib,tran + tim,tran + tit,comp , xib + xim + xit = 1, xib , xim , xit ∈ {0, 1}. (24)

A. Smart Pricing Based Energy Consumption Minimization
While satisfying the task latency requirements, we aim to minimize the total energy consumption of the whole network by adjusting the computation ofﬂoading decision x , the power control for the wireless transmission p, the computing resource allocation of each device θ , and the wired transmission resource allocation of the CC φ. The total energy consumption minimization problem is formulated as

min E (x , p, θ , φ)

(25)

x ,p,θ,φ

III. PROBLEM FORMULATION
In this section, we aim to minimize the total energy consumption of all entities in the distributed HetMEC network via the multi-layer computation ofﬂoading and resource allocation. Due to the distributed nature, each entity (ED, AP, or CC) optimizes its own component and only limited information can be exchanged among these entities. The smart pricing mechanism is utilized for aligning the respective objectives of different entities with the global objective (total energy consumption minimization) in the Lagrangian framework.

s.t. (1), (2), (4), (5), (7), (8), (9), (13), (15), (17), (24), xib + xim + xit = 1, xib , xim , xit ∈ {0, 1}, ∀1 ≤ i ≤ N , (25a)

ti ≤ τi , ∀1 ≤ i ≤ N ,

(25b)

where constraint (25a) indicates that the data generated by ED i needs to be processed thoroughly at ED i, the corresponding AP, or the CC. Constraint (25b) implies that the latency of processing the task generated by each ED i should be no longer than the requirement τi .

9Here we neglect the unimportant wired transmission energy consumption, which is very common in the literature [27].

10The bold form x (similar for p, θ , φ) denotes the vector of all computation ofﬂoading indicators xib/m/t .

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

1306

IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022

Based on the Lagrangian multiplier theory [29], we convert problem (25) into an equivalent Lagrange duality problem (26), as described below. For the distributed HetMEC network where each entity handles its own Lagrangian component and individually minimizes its own energy consumption, we then decompose the converted problem to each ED, AP and the CC using the smart pricing mechanism. To alleviate the congestion in the HetMEC network during the distributed optimization, a monetary penalty is charged by the CC for the EDs and APs when their ofﬂoading decisions induce network congestion. Speciﬁcally, the Lagrangian multiplier method is applied to reformulate the problem (25), where the Lagrange multipliers ω = {ω1, ω2, ω3(i), ω4(i), ω5(i)}, 1 ≤ i ≤ N , refer to the prices for the EDs and APs. To simplify the expression, we substitute 1 s into the time unit duration T0 in the next parts. The pricing based energy consumption minimization and smart pricing mechanism design problem is formulated as

min max L(x , p, θ , φ, ω) = E (x , p, θ , φ)
x ,p,θ ,φ ω

N

+ ω1

λi xit − φ0

i =1

N

+

ω3(i) bi xit − θit

i =1

N

+ ω2

bi xit − θ0t

i =1

M
+ ω4(i) λi xit − φi +

ω5(i )

j =1 i∈Nj

×

xib bi θib

+

1 − xib λi

W

· log

1+

pi gi,j σ2

+

xim bi θjm,i

+

xit λi φi

+

xit bi θit

− τi

(26)

s.t. (1), (2), (4), (5), (8), (13), (17), xib + xim + xit = 1, xib , xim , xit ∈ {0, 1}, ∀1 ≤ i ≤ N ,
(26a) ω1 ≥ 0, ω2 ≥ 0, ω3(i) ≥ 0, ω4(i) ≥ 0, ω5(i) ≥ 0, ∀1 ≤ i ≤ N ,
(26b)
where xit = (1 − xib − xim ) is determined by the ofﬂoading decisions of both ED and AP. Below we illustrate the physical meaning of each Lagrangian multiplier in the designed pricing mechanism.
• The Lagrange multipliers ω1 and ω2 indicate the monetary penalty for the network congestion. The congestion occurs when the computing or transmission capacity of the CC cannot support the processing or transmission of the tasks ofﬂoaded by EDs and APs. In this case, both EDs and APs are charged by the CC for the congestion cost.
• The Lagrange multiplier ω3(i) represents the price for the computing resources of the CC imposed upon ED i and its connected AP. For processing the ofﬂoaded task, the CC allocates the computing resources for the tasks generated by the ED and delivered by the AP.
• The Lagrange multiplier ω4(i) represents the price for the transmission resources of the CC. The CC allocates the wired transmission resources to APs for computation ofﬂoading. The ED and AP need to pay for the allocated transmission resources.
• The Lagrange multiplier ω5(i) denotes the monetary penalty posed on ED i and its connected AP when

the latency requirement is not satisﬁed, i.e., when the processing time ti > τi . We then decompose the above global optimization problem (26) for each ED, AP and the CC, where each entity handles its own Lagrangian component.

B. ED Layer: Ofﬂoading Strategy Design and Power Control Problem

In response to the prices set by the CC, each ED determines whether to ofﬂoad the task xib , and its computing capacity θib and wireless transmission power pi . We only consider the part that ED i controls in the pricing based energy consumption
expressed in (26), expressed by

min xib ,pi ,θib

Lbi

xib , pi , θib

= κb bi xib

θib

2

pi λi 1 − xib

+ W · log

1+

pi gi,j σ2

+ω1 1 − xib λi +ω2 1 − xib bi +ω3(i) 1 − xib bi +ω4(i) 1 − xib λi

⎡

+ω5(i

)

⎣

xib bi θib

+ W

1 − xib λi

log

1+

pi gi,j σ2

+

1 − xib φi

λi +

1 − xib θit

⎤ bi ⎦

(27)

s.t . xib + xim + xit = 1, xib , xim , xit ∈ {0, 1}, (27a)

xib bi ≤ θib ≤ Θbi ,

ri = W · log

1

+

pi gi,j σ2

(27b) ≥ 1 − xib λi . (27c)

Constraint (27a) guarantees that the task generated at ED

i can be processed thoroughly, derived from constraint

(26a). Constraints (27b) and (27c) are consistent with con-

straints (1), (2) and (13).

C. AP Layer: Ofﬂoading Strategy Design and Computing Resource Allocation Problem

According to the prices set by the CC, each AP chooses

to deliver the received tasks to the CC or to process them by

itself,

and

x

m i

,

i

∈

Nj ,

denotes

the

computation

ofﬂoading

decisions of AP j for the tasks uploaded from its connected

EDs.

Accordingly,

the

computing

capacity

allocation

θ

m j ,i

for

the tasks from different EDs is performed. We only con-

sider the part that AP j determines in the pricing based

energy consumption expressed in (26). Therefore, the dis-

tributed energy consumption minimization problem for AP j

can be formulated by
⎛

⎞⎛

⎞2

min

x

m i

,θ

m j ,i

Lmj

x

m i

,

θ

m j ,i

= κm ⎝

bi xim ⎠⎝

θjm,i ⎠

i ∈Nj

i ∈Nj

+

(1 − xim )(ω1λi + ω2bi ) +

ω3(i)(1 − xim )bi

i ∈Nj

i ∈Nj

+ ω4(i)(1 − xim )λi + ω5(i)

xim bi θjm,i

+

1 − xim λi + φi

1 − xim bi θit

(28)

s.t . xib + xim + xit = 1, xib , xim , xit ∈ {0, 1}, ∀i ∈ Nj , (28a)

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MULTI-LAYER COMPUTATION OFFLOADING IN DISTRIBUTED HETEROGENEOUS MEC NETWORKS

1307

xim bi ≤ θjm,i , ∀i ∈ Nj ,
θjm,i ≤ Θmj ,
i ∈Nj

(28b) (28c)

where constraints (28a)-(28c) are consistent with constraints (26a), (4) and (5).

D. CC Layer: Smart Pricing Mechanism Design and Resource Allocation Problem

The CC allocates the wired transmission resources and computing capacity to the received tasks, and designs the prices ω for EDs and APs. The CC’s energy consumption minimization and smart pricing mechanism design problem can be formulated by

min max Lt

θ

t i

,φi

ω
⎛

θ

t i

,

φi

,

ω

N

=

β1 θit

⎞ i=1 ⎛

ε +β2

bi xit θit

⎞

N

N

+ ω1⎝ xit λi −φ0⎠+ω2⎝ xit bi −θ0t ⎠

i =1

i =1

N

N

M

+

ω3(i) xit bi −θit +

ω4(i) xit λi −φi +

ω5(i )

i =1

i =1

j =1 i∈Nj

×

⎡ ⎣

xib bi θib

+

W

1−xib log 1+

λi
pi gi,j σ2

+

xim bi θjm,i

+

1−xib −xim

⎤

λi φi

+

bi θit

⎦

(29)

s.t . xib + xim + xit = 1, xib , xim , xit ∈ {0, 1}, ∀1 ≤ i ≤ N ,

(29a)

N

N

φi ≤ φ0,

θit ≤ θ0t ,

(29b)

i =1

i =1

ω1 ≥ 0, ω2 ≥ 0, ω3(i) ≥ 0, ω4(i) ≥ 0, ω5(i) ≥ 0, ∀1 ≤ i ≤ N .

(29c)

Constraints (29a)-(29c) are consistent with constraints (26a), (17), (8) and (26b). The CC adjusts the prices ω to maximize the fees charged from the EDs and APs, and adjusts the computing and transmission resource allocation θ, φ for smaller energy consumption.

IV. PRICING BASED MULTI-LAYER COMPUTATION OFFLOADING ALGORITHM DESIGN
In this section, we ﬁrst illustrate the diagram of pricing based multi-layer computation ofﬂoading and resource allocation,11 as well as the signaling between different devices on different layers in the distributed HetMEC network. The energy consumption minimization approaches for the ED, AP and CC are then proposed, respectively. Finally, we summarize the whole algorithm.

A. Overview of the Pricing Based Multi-Layer Computation Ofﬂoading (P-MCO)
The energy consumption optimization is performed round by round according to the updated prices until the ﬁnal

11The time scale of the resource allocation and computation ofﬂoading is much smaller than the pace of environmenta˛´rs change.

Fig. 2. Pricing based multi-layer computation ofﬂoading strategy design.

solutions are reached within the feasible set. As illustrated

in Fig. 2, in each round, the ED, AP and CC perform their

optimization successively as follows.

• ED Strategy Design: Each ED ﬁrst minimizes its own

cost (27) given the prices of the computing and transmis-

sion resources, as well as the network congestion and task

processing timeout. The computing capacity and wireless

transmission power are determined according to the com-

putation ofﬂoading decision. If the minimum latency of

local computing cannot satisfy the latency requirement of

the corresponding task, the data can only be ofﬂoaded to

the AP; otherwise, the ED makes the ofﬂoading decision

to achieve a lower cost.

• Signaling from ED to AP: After the optimization of

EDs, they inform the connected APs of their ofﬂoading

decisions. For those ofﬂoaded tasks, the data generation

speed λ and required CPU cycles b and remaining task processing time12 are transmitted to the AP.

• AP Strategy Design: Each AP then determines its action,

i.e., the computation ofﬂoading

puting

capacity

allocation

θ

m i

.

A

matrix

x

m i

multi-agent

and comQ-learning

method [33] is utilized to solve (28) given current data

arrival speed and remaining task processing time.13

• Signaling from AP to CC: After the optimization of APs,

each AP transmits its ofﬂoading decision to the CC. For

those ofﬂoaded tasks, the data generation speed λ and

required CPU cycles b and remaining task processing

time are also transmitted to the CC.

• CC Price Design and Resource Allocation: Receiving

the tasks from APs, the CC then adjusts the transmis-

sion resource allocation and computing capacity allo-

cation. Prices for resources, as well as penalty charges

for congestion and task processing timeout are updated

according to the smart pricing mechanism.

12The remaining task processing time for the AP refers to latency require-

ment minus the transmission time of the ED.

13Using the multi-agent Q-learning, the state in the current round of pricing

based multi-layer computation ofﬂoading (P-MCO) algorithm is inﬂuenced

by the joint actions of all APs mainly via the binary variable ξ, since the

data generation speed and latency requirements remains unchanged. ξ = 0

when i.e.,

the maximum amount of CC’s Ni=1(1 − xib − xim )λi ≤ φ0;

transmission Otherwise, ξ

resources φ0 is enough, = 1. Therefore, the state

is mainly determined by the actions of all APs.

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

1308

IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022

• Price Update and Feedback: The CC then launches these prices to the APs and EDs, together with its adjusted computing and transmission resource allocation schemes θ t and φ. The AP then delivers these messages as well as its own ofﬂoading decisions and computing resource allocation to the corresponding EDs. Based on the updated information, the EDs and APs adjust their ofﬂoading decisions and resource allocation scheme. The optimization goes on round by round until the ﬁnal solutions converge under the Lagrangian framework.
Being the mechanism designer, we aim to minimize the total energy consumption from a global perspective in the distributed HetMEC network where each entity handles its own Lagrangian component. However, the CC, APs, and EDs are independent entities having their own objectives. Information exchange among these cooperative entities are agreed to align their respective objectives with the global objective in the Lagrangian framework. But given that different entities belong to different parties in such a distributed network, only limited information rather than the overall information can be exchanged among different components.

B. ED Layer: Computation Ofﬂoading Algorithm Design
On the ED layer, each ED adjusts its computation ofﬂoading strategy based on the prices determined by the CC in order to minimize its cost. For the ofﬂoading strategy design of the ED, two choices are available, i.e., computing locally xib = 1 or ofﬂoading to the AP xib = 0. When the task is processed at the ED, the cost of ED i as shown in (27) can be simpliﬁed to

Lbi 1, pi , θib

= Lbi θib

= κb bi

θib

2

+

ω5(i )

bi θib

.

Proposition 1: The objective function Lbi (xib = 1, pi , θib )

of ED i for local computing is only related to the computing

capacity θib, and the function is convex in the feasible set, and

the problem can be solved by convex optimization.

Proof: The second derivative of Lbi (xib = 1, pi , θib ) is

d 2Lbi (θib ) d (θib )2

=

2κb bi

+ 2ω5(i)bi (θib )−3

>

0,

and

thus,

the

objec-

tive function Lbi (xib = 1, pi , θib ) is convex. Moreover, since

the feasible set bi ≤ θib ≤ θi0 is the convex set, the problem

can be solved by convex optimization.

When the task is ofﬂoaded to the AP, the cost of ED i as

shown in (27) can be simpliﬁed by

Lbi 0, pi , θib

=

pi λi W log 1 +

pi gi,j σ2

+ ω1λi + ω2bi + ω3(i)bi

+ ω4(i)λi + ω5(i)

λi

W

log

1+

pi gi,j σ2

+

λi φi

+

bi θit

.

Proposition 2: The objective function Lbi (xib = 0, pi , θib ) of ED i for an uploading task is only related to transmission
power pi , and reaches a minimum under the conditions of ω5(i)gi,j ≥ σ2.

Proof: The differential coefﬁcient of the ED’s energy consumption when xib = 0 is

dLbi (pi ) d (pi )

=

log

1

+

pi gi,j σ2

log

−

ln 2

·

pi gi,j +ω5(i)gi,j pi gi,j +σ2

1

+

pi gi,j σ2

2

(30)

Therefore, in the feasible set that pi ≥ 0, the numerator

of

dLbi (pi ) d (pi )

is

incremental,

while

the

denominator

is

always

positive.

Given that

dLbi (pi d (pi )

)

|pi

=0

=

−

2ω5(i)gi,j −σ2 2σ2 ln 2

< 0, and

obviously

dLbi (pi d (pi )

)

|pi

→∞

>

0,

there

must

exist

a

pi∗

>0

sat-

isfying that i reaches a

mdidLn(biip(mpi )iu)m|piw=hpie∗n=pi0.=Tphi∗u.s,

the

cost

Lbi (pi )

of

ED

Therefore, the optimal power for problem min Lbi (xib =

0, pi , θib ) can be obtained by solving

log

1

+

pi gi,j σ2

−

ln

2

·

pi gi,j + pi gi,j

ω5(i ) gi ,j + σ2

= 0.

(31)

C. AP Layer: Multi-Agent Q-Learning Algorithm Design
On the AP layer, according to the prices determined by the CC and the ofﬂoading decisions of the connected EDs, the AP optimizes its computation ofﬂoading and computing resource allocation strategies. It is worth noting that different APs are interactive and jointly constrained by the computing and transmitting capacity of the CC. In this subsection, we solve the energy consumption minimization problems of APs in (28) via multi-agent reinforcement learning (RL).
1) Motivations of Multi-Agent Reinforcement Learning: Reinforcement learning provides a way for an agent to interact with an unknown environment, and learn the optimal solution via repeated actions and observations of the rewards [32]. In multi-agent RL (MARL), multiple agents share the same environment, aiming to maximize their individual interest [33], and the environment can only be partially observed by each agent [34].
In the distributed HetMEC network, each AP can only observe a part of the environment, i.e., the data generation speed, the historical prices and resource allocation scheme of the CC, and the ofﬂoading decisions of connected EDs. At the AP layer, different APs make decisions simultaneously, and thus, only the historical actions of other APs can be observed by each AP, while the real-time actions of other APs are invisible. Therefore, the APs need to ﬁnd the optimal actions via learning in the presence of limited environment information. Therefore, MARL is well suited to solve this problem.14 In particular, different APs aim to minimize their cost individually, and the ofﬂoading decisions of the APs are unaware of each other. However, different APs are jointly bound by the transmission resource amount and the computing capacity of the CC. Thus, their decisions are inter-dependent. By utilizing

14Moreover, for each AP, the energy consumption minimization problem (28) is a mixed integer nonlinear optimization problem, for which it is hard to ﬁnd the optimal solution by optimization methods [30].

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MULTI-LAYER COMPUTATION OFFLOADING IN DISTRIBUTED HETEROGENEOUS MEC NETWORKS

1309

a MARL algorithm,15 APs can predict the actions of each other

according to the historical decisions, and obtain the optimal

actions jointly by learning round by round. The instability of

environment of individual agents can be well solved by the

MARL. Therefore, we use MARL for solving problem (28).

2) Reinforcement Learning Framework for HetMEC: In the

three-layer HetMEC network including the CC, APs and EDs,

each AP is viewed as an agent. The APs decide their action

according to the prices determined by the CC and the ofﬂoad-

ing decisions of EDs. We deﬁne the state, action and reward

of APs in the RL framework.

• State: The state of the environment observed by each AP

is determined by: the data generation speed of connected

EDs Λj = [λi ], Bj = [bi ], i ∈ Nj ; the latency requirements for task processing Tj = [τ i ], i ∈ Nj ; and an transmission congestion indicator ξ ∈ {0, 1} representing

whether the total amount of APs’ required transmission

resources exceeds the maximum amount of CC. Thus, the

state space of AP j is deﬁned by Sj = (Λj , Bj , Tj , ξ).

• Action: The actions of the AP are determined by the

ofﬂoading decisions Xj ing capacity allocation

=

[x

m i

Θj =

], i ∈ Nj , and

[θ

m j ,i

],

i

∈

Nj

the comput. Therefore,

we denote the action of AP j as aj , and the action space of

AP j is deﬁned by Aj = [Xj , Θj ]. It is worth noting that the computing capacity θjm,i is a successive variable. That

is, to limit the size of the action space, the computing

capacity can be discretized into multiple units.

• Reward: Each AP will obtain a reward R(s, a) given the

state s after performing the action a in each iteration. We

aim to minimize the costs of APs, while the RL aims

to maximize the reward. Therefore, the reward function

should be negatively correlated to the cost function (28)

of the AP. The reward of AP j is deﬁned by Rj (s, aj ) =

Lmj

1 (s

,aj

)

.

3) Multi-Agent Q-Learning Algorithm Design for the

Multiple-AP Network: We design the multi-agent Q-learning

(MAQL) algorithm for multiple APs to coordinate their com-

putation ofﬂoading and resource allocation while considering

their mutual effects. We calculate the Q-values Q(s, a) given all

state-action pairs (s, a) and record them in the Q-table (stored

at the corresponding AP), where the Q-value represents the

long-term reward of taking an action in the current state, con-

sidering both immediate reward and future expected reward.

It is worth noting that the ofﬂoading decisions of all APs are

jointly constrained by the amount of resources of the CC. To

reduce the congestion cost, each AP estimates the actions of

others according to their historical actions and makes its own

ofﬂoading decisions for a lower cost.

(i) Action Space Discretization and Available Action Space

Reduction: The action aj of AP j is determined by the ofﬂoad-

ing

decisions

x

m i

and

computing

capacity

θ

m j ,i

.

We

deﬁne

a −j

as the actions of all other APs except AP j. We discretize the

computing

capacities

θ

m j ,i

into

Y

levels,

and

thus,

the

action

space is discrete. In order to reduce the size of the action space,

15The multi-agent multi-armed bandit [31] is not suitable for solving our problem, because it cannot describe the changes of states, and the future rewards cannot be taken into account.

we remove the unfeasible actions according to the strategies
described below. • The allocated computing capacity θim is not smaller than the required CPU cycles bi (1 − xib ). • The AP does not need to allocate computing capacity
unless the task is computed by itself.
• The total allocated computing capacity of one AP to
all connected EDs cannot surpass its own maximum
computing capacity.
Remark 2: The upper bound of the performance loss
induced by the computing capacity discretization of the AP
is proportional to the square of the discretization granular-
ity, so the loss can be signiﬁcantly reduced by increasing the
number of the discretization levels Y.
(ii) Action Selection Strategy: To achieve the trade-off
between exploitation and exploration [35], the AP selects the action based on an −greedy strategy. In each cycle, the AP selects a random action with the probability , aiming to
explore new actions, and the AP selects the optimal action aj∗ given the Q-table with the probability 1 − . The optimal action can be expressed as

aj∗

=

πj (s)

=

argmax

aj

a −j

Φ

s, a −j n (s )

Qj

s,

aj , a −j

,

(32)

where the policy πj (s) maps the state to the optimal action, and Φ(s, a−j ) represents the number of actions a−j of the APs other than AP j are selected in state s, and n(s) is the
total number of times that state s is visited [35].
(iii) Q-table Updating Mechanism: After AP j observes the actions of other APs a−j , and the reward in the previous iteration, it updates the Q-value as follows

Qj s, aj , a −j

= (1 − η)Qj s, aj , a−j + η Rj s, aj , a −j + μVj s , (33)

where η represents the learning rate, and μ is a con-

stant that satisﬁes 0 ≤ μ ≤ 1 representing the

proportion of the future expected reward. Vj (s ) =

maxaj

a −j

Φ(s n

,a (s

−j
)

)

Q

(s

, (aj , a −j ))

represents

the

fact

that AP j selects the action aj in new state s to maximize

the expected discount reward according to distribution of the

historical actions of other APs.

Finally, we summarize the MAQL algorithm for the

multiple-AP networks in each P-MCO round in Algorithm 1.

We ﬁrst initialize the Q-tables and action selection poli-

cies of each AP. In each iteration of the MAQL algorithm,

each AP selects the action following an −greedy strat-

egy. After the APs perform their actions, the Q-tables are

updated according to (33), and the action selection policies

are updated according to (32). The worst-case complexity is

analyzed.

Proposition 3: The worst-case complexity of Algorithm 1

is

O (V

·

2Nmax

(

Y Nmax

)Nmax ),

where

Y

denotes

the

discretiza-

tion levels of the computing capacity, and V implies the

maximum iteration times, and Nmax = max{N1, . . . , NM }

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

1310

IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022

Algorithm 1 Multi-Agent Q-Learning (MAQL) Algorithm for

Multiple-AP Networks

Input: Data generation speed λi ; Require CPU cycles bi ;

Latency requirements Historical computing

τi; and

Ofﬂoading

decisions

of

EDs

x

b i

;

transmission resource allocation

Prices of CC

ω;

θ

t i

and φi ; Max iteration

Output: computation

allocation

scheme

θ

m j ,i

time V. ofﬂoading decision of all APs.

x

m i

,

computing

resources

1: Remove the unfeasible actions and reduce the action space of

AP j to Aj , 1 ≤ j ≤ M .

2: Initialize Q(s, (aj , a−j )) for state s ∈

M j =1

Sj

Aj , a−j ∈

M j =1,j

=j

Aj

.

3:

Initialize

the

action

selection

polity

πj (s) =

1 |Aj

|

.

4: for iteration v < V, each AP j do

and aj ∈

5: With probability (q), AP j randomly selects an action,

otherwise, it selects action optimally following πj (s). 6: Perform the selected action aj .

7: Observe the obtained reward Rj .

8: Update the Q-table according to (33) with the learning rate

η(v )

=

v

−

2 3

according to the actions.

9: Update the polity πj (s) based on (32) according to the

actions in this iteration.

10: v ← v + 1.

indicates the maximum number of EDs connected with the

AP. When N1 = · · · = NM , the worst-case complexity can be

simpliﬁed

into

O

(V

(

2MY N

)N

).

Proof: See the Appendix.

Proposition 4: The computing and transmission resource

allocation problem in (34) is convex.

Proof: Given that the value 2.5 ≤ ε ≤ 3, we can obtain

that

d 2Lt (θ i ,φi ,ω) d (φti )2

= λi xit ω5(i)(φi )−3

≥0

and

d

2

Lt

(θ

t i

,φi

,ω)

d (θit )2

=

fTboihrxeittrh[eβefo1v(reaε,ri−faobr1lea)(gθεiitv−eann2dp)r(φiθciite.)Wεω−,e3fun+nocte2ti(otβhn2aLt+tc(oθωnti5(s,itφ)ra)i(i,nθωtits))−(i2s39]cao)≥navne0xd.

(29b) are also convex. Thus, problem (34) can be solved by

convex optimization.

2) Price Update: The prices announced by the CC enable

it to adjust the ofﬂoading strategies of the APs and EDs in an

economic way. For example, when network congestion occurs,

the prices for computing and transmission resources and the

monetary penalty for congestion increase to motivate the APs

and EDs to process more tasks locally for lower cost. The

prices are updated utilizing the subgradient method [36], which

can be expressed by

ω[k + 1] =

ω[k ]

+

l [k ]

·

∂H (ω) ∂ω

ω=ω[k ]

+
,

(36)

where k is the iteration time, and ω[k ] represents the price

in the k-th round, and l[k] is a sequence of scalar stepsizes, and [·]+ = max{·, 0}. It has been proved that the subgradi-

ent method can converge once the stepsize l[k] is sufﬁciently

small

[36].

Therefore,

we

design

the

stepsize

by

l [k ]

=

ι k

,

where ι is a positive constant and k is the iteration time.

D. CC Layer: The Resource Allocation and Price Update Mechanism Design

Based on the ofﬂoading decisions of the EDs and APs in response to previous prices, the CC updates the prices and allocates the wired transmission and computing resources. We can solve the min-max problem in (29) by solving its dual problem. It has been proved that the original problem and the dual problem are equivalent for a convex function [36]. The dual objective is

H (ω) = min Lt

θ

t i

,φi

θ

t i

,

φ

i

,

ω

.

(34)

Therefore, the dual problem, i.e., the smart pricing mechanism design problem, is expressed by

max H (ω),

(35)

ω

s.t . ω1 ≥ 0, ω2 ≥ 0, ω3(i) ≥ 0, ω4(i) ≥ 0, ω5(i) ≥ 0, ∀1 ≤ i ≤ N , (35a)

The resource allocation of the CC is determined by solv-

ing problem (34) with constraints (29a) and (29b), and the

price updating mechanism can be obtained by solving the dual

problem (35).

1) Computing and Transmission Resource Allocation of

CC: We can prove that the resource allocation problem

minθ

t i

,φi

Lt

(θ

t i

,

φi

,

ω)

is

convex.

Therefore,

the

computing

and transmission resource allocation scheme can be obtained

by convex optimization.

E. Summary of Pricing Based Multi-Layer Computation Ofﬂoading Algorithm

The pricing based multi-layer computation ofﬂoading (P-

MCO) algorithm is summarized in Algorithm 2. By executing

the P-MCO algorithm, we minimize the total energy consump-

tion in a distributed way, where EDs, APs and the CC adjust

their solutions iteratively. Prices are determined by the CC in

each round, to coordinate the ofﬂoading strategies of EDs and

APs for lower network congestion probability.

As described in Algorithm 2, in each round, according to the

prices set by the CC in the previous round, the ED individually

determines its computation ofﬂoading strategy by comparing

its cost of local computing and computation ofﬂoading. The

ofﬂoading

decisions

x

b i

of

all

EDs

are

transmitted

to

the

con-

nected APs, together with the environment information and

latency

requirements.

Given

x

b i

and

prices

set

by

the

CC,

the

APs obtain their computation ofﬂoading strategies and com-

puting resource allocation schemes by Algorithm 1. According

to the received ofﬂoading decisions of the EDs and APs,

the CC allocates the computing resources and wired trans-

mission resources. The prices are updated given the actions

of all devices according to (36) for the next round. The

loop ends when the maximum price change is smaller than

threshold ξ.

V. THEORETICAL ANALYSIS
In this section, we ﬁrst analyze the feasible solution of the energy consumption minimization problem, and then analyze the computation ofﬂoading strategies of the APs and derive the

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MULTI-LAYER COMPUTATION OFFLOADING IN DISTRIBUTED HETEROGENEOUS MEC NETWORKS

1311

Algorithm 2 Pricing Based Multi-Layer Computation

Ofﬂoading (P-MCO) Algorithm

Input: Data generation speed λi ; Require CPU cycles bi ; Latency

requirements τ i .

Output:

computation

ofﬂoading

decision

x

b i

,

x

m i

;

Computing

resources

allocation

scheme

θ

b i

,

θ

m j ,i

,

θ

t i

;

Wireless

transmission

power p and wired transmission resource allocation φ.

1: Initialize maximum iteration times MaxIter, threshold ξ.

2: for k < MaxIter do

3: EDs minimize the cost Lbi (xib = 1) via convex optimization

for locally processing.

4: EDs minimize the cost Lbi (xib = 0) by solving equation (31)

for uploading tasks.

5: Compare Lbi (xib = 1) and Lbi (xib = 0) and select the

ofﬂoading strategy xib for lower cost.

6:

ED

Signaling:

The

EDs

transmit

x

b i

,

λ,

b

and

the

remaining

latency requirements to the connected APs.

7: APs minimize the cost by MAQL algorithm described in

Algorithm 1.

8:

AP

Signaling:

The

APs

transmit

x

m i

,

x

b i

,

λ,

b

and

the

remaining latency requirements to the CC.

9: CC optimizes the resource allocation by solving (34) utilizing

convex optimization.

10: CC updates the pricing according to (36).

11: if max(|ω(k + 1) − ω(k )|) < ξ then

12:

break

13: CC updates the information to APs.

14: APs updates the information to the connected EDs.

15: k ← k + 1.

conditions under which the APs prefer processing all tasks to uploading them to the CC.

A. Feasible Set of the Total Energy Consumption Minimization Problem
Unlike most reinforcement learning algorithms where the obtained solution may be out of the feasible set and the feasible solution cannot be guaranteed, our algorithm guarantees that the results obtained by P-MCO algorithm are always within the feasible set.
Proposition 5: When the feasible set is nonempty, the PMCO algorithm can always ﬁnd a feasible solution.
Proof: According to the pricing based energy consumption minimization problem described in (26), the constraints that are consistent with the problem (25) can be guaranteed by the EDs, APs and CC respectively. We focus on the constraints (7), (9), (15), (17) and (25b). The feasible set is denoted by F. For each solution f, we deﬁne that

N

N

O1(f ) = λi xit − φ0, O2(f ) = bi xit − θ0t ,

i =1

i =1

O3(i)(f ) = bi xit − θit , O4(i)(f ) = λi xit − φi ,

O5(i)(f ) = ti − τi ,

and O = {O1, O2, O3(i), O4(i), O5(i)}. The Lagrangian based

energy consumption can be expressed by L(f ) = E (f ) +

ω1O1(f ) + ω2O2(f ) + ω5(i)O5(i)(f )].

N i =1

[ω3(i ) O3(i ) (f

)

+

ω4(i ) O4(i ) (f

)

+

When the solution is within the feasible set, i.e., f ∈ F, we

also consider to update price ω1. Since O1(f ) ≤ 0 and given that f ∈ F , we note that E (f ) + ω1O1 ≤ E (f ). According

to the price updating mechanism (36), after the k-th iteration,

the updated price is expressed by ω1[k + 1] = [ω1[k ] + l [k ] · O1(f )]+ ≤ ω1[k ]. Therefore, E (f ) + ω1O1(f ) increases with

the iteration times and towards E(f ). Similarly, we can obtain

that L(f )|k→∞ = E (f ). When the solution is out of the feasible set, i.e., f ∈/ F,

we consider the updating of price ω1. Since O1(f ) > 0 given that f ∈/ F , we note that E (f ) + ω1O1 > E (f ). According

to the price updating mechanism (36), after the k-th iteration,

the updated price is expressed by ω1[k + 1] = [ω1[k ] + l [k ] ·

∂

H (ω) ∂ω1

|ω1

=ω1

[k

]

]+

=

ω1[k ] + l [k ]O1(f

)

>

ω1[k ].

Therefore,

E (f )+ω1O1(f ) increases with the iteration times and towards

inﬁnity. Similarly, we can obtain that L(f )|k→∞ = ∞.

Hence, when minimizing the Lagrangian based energy con-

sumption L, the ﬁnal solution is always within the feasible set

F when F = ∅.

B. Computation Ofﬂoading Strategy of the AP

We now investigate the ofﬂoading strategy of the AP. When the required number of CPU cycles exceeds the computing capacity of the EDs, i.e.,

bi > Θbi , ∀i ∈ Nj ,

(37)

the EDs ofﬂoad the tasks to the connected AP j. Let pi∗ denote the optimal transmission power of ED i. Three sufﬁcient con-

ditions that ensure AP j chooses to process all the tasks itself

rather than to upload to the CC are then given below.

First, the energy consumption at the AP is smaller than that

at the CC, expressed by

κm bi

θjm,i

2
<

β1 θit ε + β2

·

bi θit

.

(38)

According to the pricing based energy consumption

minimization problem for AP shown in (28), when the energy

consumption at the CC is larger, the CC can raise the prices

ω4 and ω5 to encourage the AP to process the task itself for lower cost.

Second, the computing capacity of the AP is sufﬁcient

for processing the tasks without congestion, which can be

expressed by

Θmj ≥

bi .

(39)

i ∈Nj

Third, the task processing latency of the tasks should sat-

isfy their latency requirements when processed at the AP.

The minimum required computing capacity for processing

task i is expressed by

τi

bi −(tib,tran

)∗

,

where

(tib,tran )∗

=

W

λi log(1+pi∗gij /σ2)

implies

the

transmission

duration

from

the

ED to the AP. Therefore, the total required computing capac-

ity cannot surpass the maximum computing capacity θ0m of

the AP, described by

θ0m ≥ i∈Nj τi −

bi tib,tran

∗.

(40)

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

1312

IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022
TABLE II HETMEC NETWORK PARAMETERS

Based on the above three statements, when the task processing latency requirements τi , i ∈ Nj , satisfy the constraint (40) under the conditions (37)-(39), AP j will process the task
locally.

VI. SIMULATION RESULTS
In this section, we evaluate the total energy consumption and latency performance of the whole network when executing the P-MCO algorithm. We ﬁrst verify the convergence of the MAQL algorithm and the P-MCO algorithm by the simulation. The total energy consumption and network congestion probability are then evaluated, compared to the traditional distributed method [37] with no pricing mechanism. In the traditional distributed method [37], the APs determine the actions via RL in a distributed manner. Speciﬁcally, each ED decides to ofﬂoad or to compute locally for lower energy consumption, and CC allocates the transmission and computing resources according to the decisions of EDs and APs.

A. Parameters Setting
We consider a HetMEC network consisting of one CC, M = 10 APs16 and N = 60 EDs. The parameters are listed in Table II according to [14], [27], [28]. We assume that the EDs and APs are randomly located with a distance within 100m. The EDs are the smartphones with single-core 1 GHz of maximum CPU clock frequency, and the AP is the IBM server with a quad-core 4 GHz CPU. The CC consists of 10 quad-core 5 GHz CPUs, so the equivalent CPU clock frequency of the CC is 50 GHz [27], [28]. The required number of CPU cycles is proportional to the amount of raw data for the same kind of tasks [38].
The performance of the P-MCO algorithm is evaluated based on the following metrics
• Total Energy Consumption: The total energy consumption of all EDs, APs and the CC.
• Congestion Probability: The probability that the network experiences congestion.
B. Convergence Performance
We illustrate the convergence performance of the P-MCO and MAQL algorithms in Fig. 3. Fig. 3(a) presents the cumulative distribution function (CDF) of the number of iterations
16Our proposed algorithm is scalable for multiple APs. For the ultra-dense networks, multi-layer APs can be considered for the scalability, where MARL can be performed within each group of lower-layer APs connected with the same upper-layer AP.

Fig. 3. Algorithm Convergence Performance.
to converge for the P-MCO algorithm given different numbers of EDs. We observe that the outcomes of the P-MCO algorithm all converge within 27 iterations in different cases. As the number of EDs increases, the range of iteration numbers to converge also increases. The most frequent iteration number to converge is 24, 23, and 22 when the number of EDs is 2, 4, and 6, respectively. Fig. 3(b) shows the reward of each AP versus the iterations of the MAQL algorithm in a round of P-MCO algorithm. Each AP searches for the best solution and reinforces its learning results as the number of iteration times increases. The sudden changes of the reward results from the random action selected in those iterations. Since the ofﬂoading decisions of connected EDs are different for APs, their rewards converge to different values.

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MULTI-LAYER COMPUTATION OFFLOADING IN DISTRIBUTED HETEROGENEOUS MEC NETWORKS

1313

Fig. 4. Energy consumption performance v.s. the change of prices.
C. Energy Consumption Performance
Fig. 4(a) shows the total energy consumption versus the data generation speed in different cases. We assume that one CPU cycle is required for processing each bit of raw data, i.e., the computation load also increases with the data generation speed. Given the latency requirement for task processing, the total energy consumption increases with the data generation speed, as more data needs to be processed. When the required latency decreases, the total energy consumption grows, since larger computing capacity is utilized and more transmission power is required for reducing the task processing latency. We compare our proposed P-MCO algorithm with the traditional distributed method [37]. Our proposed algorithm achieves around 28% lower energy consumption17 , because the ofﬂoading strategies are adjusted by prices for reducing the total energy consumption, implying the signiﬁcance of the pricing mechanism for energy saving. We observe that the performance gap to the optimal solution is smaller than
17We note that when data generation speed λ = 10 ∗ 104 bps, the energy consumption gained by the P-MCO is slightly larger than that gained by the traditional distributed method, because the computation ofﬂoading strategy is adjusted in P-MCO so as to satisfy the latency requirements of task processing (which can be seen in Fig. 7 when λ = 10).

Fig. 5. Inﬂuence of the price on energy consumption and computation ofﬂoading results analysis.
14%, which is induced by distributed decision making and the computing capacity’s discretization.
Fig. 4(b) presents the ﬁnal prices determined by the CC given different data generation speeds when the latency requirement τ = 5 time periods. For a given data generation speed λ, the prices are updated round by round to coordinate the actions of EDs, APs and CC. We note that the average prices increase with the data generation speed, so as to encourage more EDs and APs to process the task themselves for lower latency and network congestion probability. Since no task is ofﬂoaded to the CC when λ ≤ 15, the resources of the CC are not utilized. Thus, the CC’s resource prices (i.e., ω3 and ω4) and congestion penalties (i.e., ω1 and ω2) remain unchanged. When λ > 15, these prices increase signiﬁcantly to discourage tasks being ofﬂoaded to the CC.
Fig. 5(a) illustrates how the average price of computing resources ω3 inﬂuences the energy consumption of the CC. During the iterations, the CC updates the prices based on the ofﬂoading decisions of the EDs and APs, and the prices in turn inﬂuence their strategies. We note that when the price ω3 increases, the CC’s energy consumption decreases, as more

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

1314

IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL. 8, NO. 2, JUNE 2022

EDs make their ofﬂoading decisions via convex optimization, and the APs utilize a MAQL algorithm for the computation ofﬂoading and computing resource allocation. The feasibility of the obtained solutions is guaranteed if the feasible set is not empty, and the timeout percentage is reduced when no feasible solution can be obtained.
Simulation results show that when performing the proposed P-MCO algorithm the total energy consumption decreases by 28% and a maximum 100% network congestion reduction is achieved compared with the traditional distributed method. As the computation load grows, resource prices and monetary penalty increase to discourage EDs and APs to upload tasks, which in turn alleviates the network congestion.

Fig. 6. Congestion Probability v.s. data generation speed.
tasks are encouraged to be processed at the EDs and APs. When the resource price ω3 reduces, it provides the incentive for EDs and APs to upload more tasks, and thus, the energy consumption of the CC increases.
Fig. 5(b) shows the task assignment results of our P-MCO algorithm given different data generation speeds. As the data load increases, the tasks are gradually ofﬂoaded to upper layers. When λ > 2, EDs do not process tasks anymore due to limited computing capacity. When λ = 3, tasks are all processed at the APs as analyzed in Section V. When λ > 3, the AP cannot handle all tasks without congestion, so the CC shares the computation load. The computing capacities of multiple devices are fully used to save energy as well as to reduce the network congestion.
D. Network Congestion Performance
Fig. 6 presents the network congestion probability v.s. the data generation speed given different latency requirements. With our P-MCO algorithm, the network remains non-congested until the data generation speed reaches λ = 35. However, in the traditional distributed method, the network exhibits congestion after λ > 10, and the congestion probability increases gradually with the data generation speed. When the smart pricing mechanism operates, prices increase with the data generation speed. Thus, the ofﬂoading cost grows, motivating more EDs and APs to process tasks locally. Therefore, the computation load is distributed and network congestion can be alleviated.
VII. CONCLUSION
We studied the energy consumption minimization problem in distributed HetMEC networks. A pricing based multilayer computation ofﬂoading (P-MCO) strategy is designed to coordinate the ofﬂoading behaviors and resource allocation schemes of the EDs, APs and CC, so that the network congestion can be alleviated while minimizing the total energy consumption. In the P-MCO algorithm, the CC updates the prices according to the real-time data generation speed of tasks, and adjusts the resource allocation scheme based on the ofﬂoading decisions of the EDs and APs. Given the prices, the

APPENDIX PROOF OF PROPOSITION 3

When performing Algorithm 1, the maximum number of AP’s actions is (2Y )Nmax after the discretization of the

computing capacity, where Y denotes the number of the dis-

cretization levels and Nmax = max{N1, . . . , NM } denotes the maximum number of EDs connected with each AP. Beneﬁt

from the action space reduction described in Section IV-C-3)-

(i), the maximum number of actions can be reduced. The total

allocated computing capacity of each AP cannot surpass its own maximum computing capacity, i.e., i∈Nj yjm,i ≤ Y , where yj ,i denotes the discretized computing capacity of

ED i. Therefore, according to the inequality of arithmetic

and geometric means, we can obtain that i∈Nj yj ,i ≤

(

i ∈Nj
Nj

yj ,i

)Nj

=

(

Y Nj

)Nj .

Therefore,

the maximum number

of actions which can

for be

each AP is expressed by

simpliﬁed

into

(

2MY N

)

N M

2Nmax

(

Y Nmax

when N1 =

)Nmax , N2 =

···

=

NM

=

Nmax

=

N M

.

In each iteration, the complexity of obtaining the optimal

action

is

O (V

·

2Nmax

(

Y Nmax

)Nmax

)

according

to

(32),

and

the complexity of Q-table updating is O(M). Therefore, the

worst-case complexity of multi-agent Q-learning algorithm

is

O (V

·

2Nmax

(

Y Nmax

)Nmax ),

where

V

implies

the

maxi-

mum iteration times. When N1 = N2 = · · · = NM ,

the worst-case complexity of Algorithm 1 can be simpliﬁed

into

O (V

(

2MY N

N
)M

).

REFERENCES
[1] P. Wang, B. Di, Z. Zheng, and L. Song, “Distributed energy saving for heterogeneous multi-layer mobile edge computing,” in Proc. IEEE ICC, Dublin, Ireland, Jun. 2020, pp. 1–6.
[2] Y. Yu, “Mobile edge computing towards 5G: Vision, recent progress, and open challenges,” China Commun., vol. 13, no. 2, pp. 89–99, 2016.
[3] Y. C. Hu, M. Patel, D. Sabella, N. Sprecher, and V. Young, “Mobile edge computing: A key technology towards 5G,” ETSI, Sophia Antipolis, France, Rep. 11, Sep. 2015.
[4] P. Wang, Z. Zheng, B. Di, and L. Song, “HetMEC: Latency-optimal task assignment and resource allocation for heterogeneous multi-layer mobile edge computing,” IEEE Trans. Wireless Commun., vol. 18, no. 10, pp. 4942–4956, Oct. 2019.
[5] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey on mobile edge computing: The communication perspective,” IEEE Commun. Surveys Tuts., vol. 19, no. 4, pp. 2322–2358, 4th Quart., 2017.
[6] C. You, K. Huang, H. Chae, and B.-H. Kim, “Energy-efﬁcient resource allocation for mobile-edge computation ofﬂoading,” IEEE Trans. Wireless Commun., vol. 16, no. 3, pp. 1397–1411, Mar. 2017.

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MULTI-LAYER COMPUTATION OFFLOADING IN DISTRIBUTED HETEROGENEOUS MEC NETWORKS

1315

[7] Q. Liu, T. Han, and N. Ansari, “Joint radio and computation resource management for low latency mobile edge computing,” in Proc. IEEE GLOBECOM, Abu Dhabi, UAE, Dec. 2018, pp. 1–7.
[8] B. Yang, X. Cao, J. Bassey, X. Li, and L. Qian, “Computation ofﬂoading in multi-access edge computing: A multi-task learning approach,” IEEE Trans. Mobile Comput., vol. 20, no. 9, pp. 2745–2762, Sep. 2021.
[9] P. Wang, C. Yao, Z. Zheng, G. Sun, and L. Song, “Joint task assignment, transmission, and computing resource allocation in multilayer mobile edge computing systems,” IEEE Internet Things J., vol. 6, no. 2, pp. 2872–2884, Apr. 2019.
[10] S. Sen, C. Joe-Wong, S. Ha, and M. Chiang, “Smart data pricing: Using economics to manage network congestion,” Commun. ACM, vol. 58, no. 12, pp. 86–93, 2015.
[11] Z. Xiong, S. Feng, D. Niyato, P. Wang, and Z. Han, “Optimal pricingbased edge computing resource management in mobile blockchain,” in Proc. IEEE ICC, Kansas City, MO, USA, 2018, pp. 1–6.
[12] L. Li, M. Siew, and T. Q. S. Quek, “Learning-based pricing for privacypreserving job ofﬂoading in mobile edge computing,” in Proc. IEEE ICASSP, Brighton, U.K., May 2019, pp. 4784–4788.
[13] X. Chen, “Decentralized computation ofﬂoading game for mobile cloud computing,” IEEE Trans. Parallel Distrib. Syst., vol. 26, no. 4, pp. 974–983, Apr. 2015.
[14] X. Chen, L. Jiao, W. Li, and X. Fu, “Efﬁcient multi-user computation ofﬂoading for mobile-edge cloud computing,” IEEE/ACM Trans. Netw., vol. 24, no. 5, pp. 2795–2808, Oct. 2016.
[15] J. Zheng, Y. Cai, Y. Wu, and X. S. Shen, “Dynamic computation ofﬂoading for mobile cloud computing: A stochastic game-theoretic approach,” IEEE Trans. Mobile Comput., vol. 18, no. 4, pp. 771–786, Apr. 2019.
[16] X. Ma, S. Zhang, W. Li, P. Zhang, C. Lin, and X. Shen, “Cost-efﬁcient workload scheduling in cloud assisted mobile edge computing,” in Proc. IEEE/ACM IWQoS, Vilanova i la Geltrú, Spain, Jun. 2017, pp. 1–10.
[17] X. Ma, C. Lin, X. Xiang, and C. Chen, “Game-theoretic analysis of computation ofﬂoading for cloudlet-based mobile cloud computing,” in Proc. ACM MSWiM, Cancun, Mexico, Nov. 2015, pp. 271–278.
[18] S. Sardellitti, G. Scutari, and S. Barbarossa, “Joint optimization of radio and computational resources for multicell mobile-edge computing,” IEEE Trans. Signal Inf. Process. Netw., vol. 1, no. 2, pp. 89–103, Jun. 2015.
[19] T. Zhang, “Data ofﬂoading in mobile edge computing: A coalition and pricing based approach,” IEEE Access, vol. 6, pp. 2760–2767, 2018.
[20] J. Xu, L. Chen, and P. Zhou, “Joint service caching and task ofﬂoading for mobile edge computing in dense networks,” in Proc. IEEE INFOCOM, Honolulu, HI, USA, Apr. 2018, pp. 207–215.
[21] F. Zhang and M. M. Wang, “Stochastic congestion game for load balancing in mobile-edge computing,” IEEE Internet Things J., vol. 8, no. 2, pp. 778–790, Jan. 2021.
[22] E. Hossain, M. Rasti, H. Tabassum, and A. Abdelnasser, “Evolution toward 5G multi-tier cellular wireless networks: An interference management perspective,” IEEE Wireless Commun., vol. 21, no. 3, pp. 118–127, Jun. 2014.
[23] P. Barham et al., “Xen and the art of virtualization,” in Proc. ACM Symp. Oper. Syst. Principles (SOSP), Bolton Landing, NY, USA, Oct. 2003, pp. 164–177.
[24] D. Tse and P. Viswanath, Fundamentals of Wireless Communication. Cambridge, U.K.: Cambridge Univ. Press, 2005.
[25] B. Sklar, “Rayleigh fading channels in mobile digital communication systems .I. Characterization,” IEEE Commun. Mag., vol. 35, no. 7, pp. 90–100, Jul. 1997.
[26] T. S. Rappaport, Wireless Communications: Principles and Practice. Upper Saddle River, NJ, USA: Prentice-Hall PTR, 1996.
[27] L. Rao, X. Liu, M. D. Ilic, and J. Liu, “Distributed coordination of Internet data centers under multiregional electricity markets,” Proc. IEEE, vol. 100, no. 1, pp. 269–282, Jan. 2012.
[28] T. D. Burd, and R. W. Broderson, “Processor design for portable systems,” J. VLSI Singapore Process., vol. 13, nos. 2–3, pp. 203–221, Aug. 1996.
[29] R. T. Rockafellar, “Augmented lagrange multiplier functions and duality in nonconvex programming,” SIAM J. Control, vol. 12, no. 2, pp. 268– 285, 1974.
[30] C. A. Floudas, Nonlinear and Mixed-Integer Optimization: Fundamentals and Applications. New York, NY, USA: Oxford Univ. Press, 1995.
[31] R. Sutton and A. Barto, Reinforcement Learning: An Introduction. Cambridge, U.K.: MIT Press, 2018.
[32] J. Hu, H. Zhang, and L. Song, “Reinforcement learning for decentralized trajectory design in cellular UAV networks with sense-and-send protocol,” IEEE Internet Things J., vol. 6, no. 4, pp. 6177–6189, Aug. 2019.

[33] L. Panait and S. Luke, “Cooperative multi-agent learning: The state of the art,” Auton. Agents Multi-Agent Syst., vol. 11, no. 3, pp. 387–434, Nov. 2015.
[34] C. J. C. H. Watkins, “Learning from delayed rewards,” Ph.D. dissertation, Dept. Psychol., Kings Coll., Cambridge, U.K., 1989.
[35] E. R. Gomes and R. Kowalczyk, “Dynamic analysis of multiagent Q-learning with −greedy exploration,” in Proc. ACM ICML, Montreal, QC, Canada, Jun. 2009, pp. 369–376.
[36] W. Yu and R. Lui, “Dual methods for nonconvex spectrum optimization of multicarrier systems,” IEEE Trans. Commun., vol. 54, no. 7, pp. 1310–1322, Jul. 2006.
[37] S. Ranadheera, S. Maghsudi, and E. Hossain, “Mobile edge computation ofﬂoading using game theory and reinforcement learning,” 2017, arXiv:1711.09012.
[38] A. P. Miettinen and J. K. Nurminen, “Energy efﬁciency of mobile clients in cloud computing,” in Proc. USENIX Conf. Hot Topics Cloud Comput. (HotCloud), Jun. 2010, pp. 1–7.
Pengfei Wang (Graduate Student Member, IEEE) received the B.S. degree in electronics engineering from Peking University, Beijing, China, in 2017, where he is currently pursuing the master’s degree with the Department of Electronics. His current research interest includes wireless communications, vehicular networks, and edge computing.
Boya Di (Member, IEEE) received the B.S. degree in electronic engineering from Peking University, China, in 2014, and the Ph.D. degree from the Department of Electronics, Peking University in 2019. She was a Postdoctoral Researcher with Imperial College London and is currently an Assistant Professor with Peking University. Her current research interests include reconﬁgurable intelligent surfaces, multiagent systems, edge computing, vehicular networks, and aerial access networks. She received the Best Doctoral Thesis Award from China Education Society of Electronics in 2019. She is also the recipient of 2021 IEEE ComSoc Asia–Paciﬁc Outstanding Paper Award. She serves as an Associate Editor for IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY since June 2020. She has also served as the Workshop Co-Chair for IEEE WCNC 2020&2021.
Lingyang Song (Fellow, IEEE) received the Ph.D. degree from the University of York, U.K., in 2007, where he received the K. M. Stott Prize for Excellent Research. He worked as a Research Fellow with the University of Oslo, Norway, until rejoining Philips Research U.K. in March 2008. In May 2009, he joined the Department of Electronics, School of Electronics Engineering and Computer Science, Peking University, and is currently a Boya Distinguished Professor. His main research interests include wireless communication and networks, signal processing, and machine learning. He was the recipient of the IEEE Leonard G. Abraham Prize in 2016 and the IEEE Asia–Paciﬁc Young Researcher Award in 2012. He has been an IEEE Distinguished Lecturer since 2015.
Nicholas R. Jennings (Fellow, IEEE) is the ViceChancellor and the President of Loughborough University. He is an internationally-recognised authority in the areas of AI, autonomous systems, cyber-security, and agent-based computing. He is a member of the U.K. government’s AI Council, the governing body of the Engineering and Physical Sciences Research Council, and the Chair of the Royal Academy of Engineering’s Policy Committee. Before Loughborough, he was the Vice-Provost for Research and Enterprise and a Professor of Artiﬁcial Intelligence with Imperial College London, the U.K.’s ﬁrst Regius Professor of Computer Science (a post bestowed by the monarch to recognise exceptionally high quality research) and the U.K. Government’s ﬁrst Chief Scientiﬁc Advisor for National Security.

Authorized licensed use limited to: KAUST. Downloaded on July 28,2022 at 08:30:36 UTC from IEEE Xplore. Restrictions apply.

