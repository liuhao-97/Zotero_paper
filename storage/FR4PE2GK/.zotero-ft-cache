IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 36, NO. 3, MARCH 2018

587

Task Ofﬂoading for Mobile Edge Computing in Software Deﬁned Ultra-Dense Network
Min Chen, Senior Member, IEEE, and Yixue Hao

Abstract— With the development of recent innovative applications (e.g., augment reality, self-driving, and various cognitive applications), more and more computation-intensive and dataintensive tasks are delay-sensitive. Mobile edge computing in ultra-dense network is expected as an effective solution for meeting the low latency demand. However, the distributed computing resource in edge cloud and energy dynamics in the battery of mobile device makes it challenging to ofﬂoad tasks for users. In this paper, leveraging the idea of software deﬁned network, we investigate the task ofﬂoading problem in ultra-dense network aiming to minimize the delay while saving the battery life of user’s equipment. Speciﬁcally, we formulate the task ofﬂoading problem as a mixed integer non-linear program which is NP-hard. In order to solve it, we transform this optimization problem into two sub-problems, i.e., task placement sub-problem and resource allocation sub-problem. Based on the solution of the two sub-problems, we propose an efﬁcient ofﬂoading scheme. Simulation results prove that the proposed scheme can reduce 20% of the task duration with 30% energy saving, compared with random and uniform task ofﬂoading schemes.
Index Terms— Software deﬁned networking, mobile edge computing, task ofﬂoading, resource allocation.
I. INTRODUCTION
With the development in cloud computing and wireless communication technology, there is an explosive growth in the number of mobile devices accessing wireless networks. It is predicted that by 2020 the total quantity of world-wide devices would be 75 billion, while the volume of mobile trafﬁc would exceed 24.3 exabytes/month [1]. Furthermore, user equipment (UE) will be more and more intelligent while the applications in UEs will require extensive computation power and persistent data processing. These applications include wearable virtual reality (VR) streaming [2], mobile social media [3], vehicular system [4], [5] and self-driving, etc. However, the development of these emerging applications and services is restricted by the computational capacity and battery
Manuscript received September 30, 2017; revised February 5, 2018; accepted February 27, 2018. Date of publication March 12, 2018; date of current version May 21, 2018. This work was supported by the National Natural Science Foundation of China (under Grant No. U1705261), and Director Fund of WNLO. (Corresponding author: Yixue Hao.)
M. Chen is with the School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Wuhan National Laboratory for Optoelectronics, Wuhan 430074, China (e-mail: minchen@ieee.org).
Y. Hao is with the School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail: yixuehao@hust.edu.cn).
Color versions of one or more of the ﬁgures in this paper are available online at http://ieeexplore.ieee.org.
Digital Object Identiﬁer 10.1109/JSAC.2018.2815360

life of UEs. These emerging applications with intense requirements for computational capacity could only rely on advanced computational ofﬂoading and the improved communication infrastructure. Therefore, future communication network not only needs to support wireless content access, but also offers the provisioning of computational ofﬂoading for UEs [6], [7], especially for mobile healthcare [8], smart grid [9], Internet of vehicles [10], intelligent services [11], etc.
Ultra-dense network is proposed as a key technology for 5G to address the above challenging demand on wireless access [12], which includes small cell base stations (BSs) and macro cell BSs. Due to the densiﬁed deployment of small cell BSs, a huge access capacities can be provided by 5G network to users [13], [14]. To address the challenge of timely ofﬂoading computation-intensive task, the mobile edge computing was proposed [15], [16]. It has provided computing services with short delay and high performance to users through edge clouds or fog nodes deployed on the network edge in order to meet the computing requirements of delay-sensitive tasks. There are two major advantages of using the edge cloud [17], [18]: (i) In contrast to the local computing [19], the edge cloud computing can overcome the restrictions of limited computation capacity on mobile terminals; (ii) Compared with the computation ofﬂoading towards remote cloud [20], the edge cloud computing can avoid a large latency caused by ofﬂoading the task contents on the remote cloud. Thus, mobile edge computing exhibits a potential to achieve a better tradeoff for delay-sensitive and computationintensive tasks [21].
In the future communication network, the edge cloud will be deployed in the ultra-dense network and is able to provide computation ofﬂoading services to users [22]. The users can ofﬂoad computation-intensive task to the edge cloud. However, at present, most of the existing work on ultra dense network and mobile edge computing are separate. The effective use of mobile edge computing in ultra-dense network faces the following challenges: (i) In ultra-dense network, the intensive deployment of small cell BSs increases the complexity of network environments. In addition, the computational resources of edge cloud are limited. Thus, how to control these distributed computing resources is a challenging problem; (ii) When users ofﬂoad computing tasks, they have little information about the wireless networks to be accessed, including trafﬁc load of accessed network and computation load of edge clouds. So, how to conduct a task ofﬂoading according to the residual battery capacity of mobile device and network status is challenging. Thus, to ensure the reasonable utilization

0733-8716 © 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

588

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 36, NO. 3, MARCH 2018

of computing resources and make task placement efﬁciently, a reasonable controller is needed.
As a new networking paradigm, software deﬁned networking (SDN) [23] nowadays can achieve logically centralized control on the distributed network nodes and mobile devices. The SDN has been widely studied from the placement of SDN controller [24], [25], the network function placement [26] and the application of SDN (e.g., live stream transcoding [27], [28] and multi-paths routing [28]). However, to the best of our knowledge, there is no exiting work on the task ofﬂoading for mobile edge computing in ultra-dense network. By introducing SDN technology, this paper proposes a task ofﬂoading scheme in a software deﬁned ultra dense network (SD-UDN), as shown in Fig. 1. Based on the separation of control plane and data plane, the major computational and control functionalities are decoupled from the distributed small cell BSs and consolidated in the centralized SD-UDN controller, which resides at macro cell BS. The SD-UDN controller can collect information of mobile device and edge cloud, sense the network status from a global perspective. Based on the decision of SD-UDN controller, the mobile device is advised to perform tasks locally or ofﬂoad part of them to edge cloud for processing.
Furthermore, we formulate the task ofﬂoading scheme into a mixed integer non-linear program problem, and prove its NPhardness. The proposed strategy of task ofﬂoading aims to minimize task duration under the battery energy consumption constraint of UE. To be speciﬁc, our task ofﬂoading scheme includes two parts: (i) Where should the task be processed? That is, decide to process a task locally or in the edge cloud according to the residual battery capacity of mobile device. Furthermore, decide which edge cloud for the task to be placed on according to the availability and load of various edge clouds (i.e., task placement problem); (ii) Decide how much computing resource of edge cloud should be allocated to each task (i.e., resource allocation problem). We then transform the problem into two sub-problems: a convex sub-problem (i.e., computing resource allocation problem) and 0-1 programming sub-problem (i.e., task placement problem). Using alternative optimization techniques, we obtain an efﬁcient solution for computing resource allocation and task placement. The performance of the proposed task ofﬂoading scheme in SD-UDN is evaluated and compared with random and even ofﬂoading schemes. Experimental results demonstrate that our scheme can reduce task duration by 20% and energy cost by 30%. In summary, the main contributions of this paper include:
• We propose an innovative framework of task ofﬂoading for mobile edge computing in SD-UDN. By deploying controller at macro cell BS, the global information about mobile devices, base stations, edge cloud and tasks can be obtained, and thus enabling the optimal task ofﬂoading of mobile devices.
• We present an efﬁcient software deﬁned task ofﬂoading (SDTO) scheme, which not only reduces the task duration but also considers the battery capacity of UE. Speciﬁcally, when ﬁxing ofﬂoading decision, we can demonstrate that computing resource allocation to each

task is convex sub-problem. Based on this, we adopt a task placement algorithm to give the effective task ofﬂoading scheme. • We conduct extensive experiments to evaluate the performance of SDTO scheme. The experimental results validate that our proposed algorithm can reduce 20% of the task duration and save 30% of the energy cost as compared to random and uniform task computation ofﬂoading.
The remainder of this paper is organized as follows. Section II reviews related works. The system model and problem are described in Section III. We propose the efﬁcient task ofﬂoading scheme in Section IV. Our simulation results and discussions are given in Section V. Finally, Section VI concludes this paper.
II. RELATED WORKS
Nowadays, with substantial increase in both quantity and intelligence of mobile devices, more and more mobile applications require a good deal of computational task treatment. However, due to the limited computation and battery capacity of UE, it is quite difﬁcult to handle computing intensive tasks locally. To this end, with the development of mobile cloud computation(e.g., Clonecloud [30], Follow me cloud [31], [32]), mobile devices can ofﬂoad computationintensive tasks to the cloud for processing.
Mobile cloud computing mainly exhibits two advantages [19], [33]: (i) Reduction of the task duration which includes transmission time for mobile device to ofﬂoad task to the cloud, execution time in cloud and transmission time for the cloud to send the task result to mobile device; (ii) Decrease in energy consumption at mobile devices. For the task duration, Barbera et al. [20] proposed that delaysensitive tasks should be executed on the cloudlet, and tasks with loose delay requirements could be executed on the cloud. For the energy consumption problem at UEs, Liu et al. [34] showed that tasks needing transmission of large volumes of data with less requirement on computing resources are suitable for the execution at UE, and computation-intensive tasks are more suitable to be executed in cloud. For system energy consumption, Chen et al. [19] proposed a scheme where task is ofﬂoaded in cloud and mobile cloudlet based on user mobility, thus to reduce system energy consumption. However, task ofﬂoading to the cloud via cellular network would produce a large delay.
In order to overcome this challenge, mobile edge computing is proposed [35]. In mobile edge computing, the task ofﬂoading strategy and resource allocation are the main research points. For the task ofﬂoading, Tong et al. [17] designed a hierarchical edge computing architecture according to the distance between the edge server and users, and proposed an optimal ofﬂoading scheme for minimizing the task duration by using heuristic algorithm. Sun et al. [36] developed a novel usercentric mobility management scheme for mobile edge computing in ultra dense network. Chen et al. [18] designed multi-user task ofﬂoading in mobile edge computing. As for the resource allocation of edge computing, Xiao and Krunz [37] proposed

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

CHEN AND HAO: TASK OFFLOADING FOR MOBILE EDGE COMPUTING

589

Fig. 1. Illustration of task ofﬂoading for mobile edge computing in software deﬁned ultra-dense network.

that the cooperation of edge clouds can not only reduce the processing delay of user tasks, but also reduce the energy consumption. In a word, mobile edge computing can improve the quality of service and energy efﬁciency by optimizing task ofﬂoading and resource allocation policies. Furthermore, some existing works considered both task ofﬂoading and resource allocation in mobile edge computing, Chen et al. [12] considered the task ofﬂoading and resource allocation in mobile edge computing. However, most of the existing works consider a single mobile edge computing server. Multi-server mobile edge computing is only considered in Tran and Pompili [38], but this work does not consider the ultra dense network, it is hard to obtain insights for the design of key parameters.
Taking into account the limitations of existing work, in this paper, we design software deﬁned task ofﬂoading for mobile edge computing in ultra-dense network and propose a efﬁcient task ofﬂoading scheme. Furthermore, in Table. I, a taxonomy of various schemes is provided for a straightforward comparison in terms of computing resource pool, applicability of 5G network, computation capacity, etc.
III. SYSTEM MODEL AND PROBLEM FORMULATION
In this section, we ﬁrst introduce the framework of SD-UDN. Then, we give the task ofﬂoading problem and prove that it is a NP-hard problem.
A. The Architecture of SD-UDN
Fig. 1 shows the framework of task ofﬂoading for mobile edge computing in SD-UDN, which includes three planes, i.e., user plane, data plane and control plane. User plane consists of the users who need ofﬂoading computing tasks. Data plane mainly corresponds to small cell BSs and edge clouds deployed near small cell BSs. Control plane is realized by the SD-UDN controller deployed at macro cell BS. The users are connected to the small cell BSs or macro cell BS

through wireless link while the distributed small cell BSs are connected to the central macro cell BS via high speed fronthaul network.
Although the concept of SDN evolves, its main idea is to decouple the control plane from the data plane by virtualization [42]. Then with air interface separation [43], the control coverage provided by macro cell BS can be further decoupled from the data coverage provided by small cell BSs in SD-UDN. To be speciﬁc, the macro cell BS supports control coverage to the entire macro cell. The major control functionalities like resource allocation and scheduling are centralized at the SD-UDN controller. From a global view of the network states, the SD-UDN controller can collect information of mobile users and the small cell BSs within the macro cell BS. Then, it optimizes the network conﬁgurations on demand.
The SD-UDN controller maintains mobile device information table, BS information table and task information table. The mobile device information table includes data such as the remaining battery capacity and CPU cycle of mobile device. BS information table includes radio access load, computation load of edge cloud, etc. Task information table includes the task type, task data amount and task computation amount. Typically, a user periodically sends the measurement information to the nearest serving BS. Then the BS integrates multiple users’ information and edge cloud information together and periodically transmits to the SD-UDN controller.
Under the framework of SD-UDN, the process of task handing is illustrated as follows. The mobile device selects the nearest BS for task requesting, then the BS transmits the corresponding task request to the SD-UDN controller. When the SD-UDN controller receives the task request information, the SD-UDN controller updates all the information tables, gives the task ofﬂoading policy of mobile device and the resource allocation strategy of edge cloud according to the delay and energy consumption of the task. Since the requesting

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

590

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 36, NO. 3, MARCH 2018

TABLE I COMPARISON OF SEVERAL COMPUTATION OFFLOADING SCHEME

data packet is very small, this paper ignores the delay and energy consumption of sending request from mobile device to the SD-UDN controller.

B. Network Model
We assume that SD-UDN includes n densely deployed BSs, and edge clouds are equipped at each BS. The mobile edge clouds are indexed as B = {b1, b2, · · · , bn}. We denote the set of users in SD-UDN as U = {u1, u2, · · · , um} and consider each mobile device user ui, has a computation task to be executed locally or ofﬂoad to the edge cloud. We adopt a widely used task model (see [16], [18], [44]) to describe task Qi, i.e., Qi = (ωi, si), where ωi stands for computation amount of the task Qi, i.e., the CPU cycles needed in total to complete the task, and si stands for the size of computation task Qi, i.e., the amount of data contents (e.g., the data input and associated processing code) to be delivered toward the edge cloud. Due to the densiﬁcation deployment of the BS, each user can be served by multiple BS. Denote A(ui) as the set of BS that provide services to the user ui. In this paper, we focus on local computing and ofﬂoading the computation task to the edge cloud without further ofﬂoading to the remote cloud.

C. Communication Model

We ﬁrst introduce the communication model. We give the
uplink data rate when user mobile device ofﬂoads task onto
edge cloud. Let hi,j denote the channel gain between the user ui and BS bj, where bj ∈ A(ui). In this paper, we assume that the user mobility is not high during the task ofﬂoading,
so hi,j is a constant. Denote pi as the transmission power of users, thus user uplink data rate of ri,j can be obtained as follows:

ri,j = B log2

1

+

pihi,j σ2 + Ii,j

(1)

where σ2 is noise power of mobile device, B is channel

bandwidth and Ii,j is the inter-cell interference power. Then we can obtain that transmission delay for user ofﬂoading the

task Qi to edge cloud is as follows:

tTi,j

=

si ri,j

(2)

Further we can obtain that the transmission energy consump-

tion for user ofﬂoading the task Qi to edge cloud is as follows:

εEi,j

=

pisi ri,j

(3)

D. Task Ofﬂoading Model

A computation task can be handled locally or be ofﬂoaded

to edge cloud for processing. Next we will discuss the local

computing and mobile edge computing.

1) Local Computing: For local task computing, we deﬁne fil as a CPU computing capability of mobile device user ui. Thus, the local execution time of task Qi can be expressed as
follows:

tLi

=

ωi fil

(4)

Also, we can obtain the energy consumption for local task processing as:

εLi = ρiωi

(5)

where ρi is the power coefﬁcient of energy consumed per CPU

cycle.

2) Mobile Edge Computing: Considering the difference of

computing resource of edge clouds, we denote the computing

resource (CPU cycles per second) of edge cloud as f c =

{f1c, f2c, · · · , fnc}. According to the communication model, the total task duration in edge cloud consists of time consumed

by two procedures, i.e., (i) time consumed when the user

ofﬂoads the task, (ii) time consumed when computation tasks

are processed on the edge cloud. Therefore, the task duration

of task Qi can be obtained as follows:

tEi

=

ωi κγi i fγci

+

si ri,γi

(6)

where γi stands for the edge cloud where task Qi is placed on, i.e., γi ∈ A(ui), and κγi i stands for the proportion of computing resource allocated to task Qi by edge cloud.
Similar to many studies such as [18] and [36], we ignore the transmission delay for edge clouds to sends the task results back to the user. This is because the data size after task processing is generally smaller than it before processing, and downlink rate from BS to mobile device is higher than uplink rate from mobile device to BS.

E. Problem Formulation
In this paper, in term of the limited computation power of edge cloud and the restricted battery capacity of mobile devices, we consider the following two problems:
• Task placement problem: decide mobile user processing locally or in the edge cloud, and which edge cloud task should be place on.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

CHEN AND HAO: TASK OFFLOADING FOR MOBILE EDGE COMPUTING

591

TABLE II NOTATION TABLE

• Resource allocation problem: how much computing resource of edge cloud allocate to each task.
Our aim is to minimize the average task duration with the limited battery capacity. To be speciﬁc, we deﬁned the integer decision variable, xi ∈ {0, 1} that indicates task Qi is processed locally (xi = 1) or in edge cloud (xi = 0). Thus, The variables of task placement are as follows: X = {x1, x2, · · · , xm} and γ = {γ1, γ2, · · · , γm}. The corresponding variable of resource allocation is as follows: κ = {κ1, κ2, · · · , κm}. Table. II shows the notation in this paper. Formally, the task ofﬂoading problem can be formulated as follows:

m

minimize
x,γ,κ

xitLi + (1 − xi)tEi

(7)

i=1

subject to: xiεLi ≤ αiEmi ax ∀i = 1, · · · , m.

(8)

(1 − xi)εEi ≤ αiEmi ax ∀i = 1, · · · , m. (9)

γi ∈ A(ui) ∀i = 1, · · · , m.

(10)

κγi i ≤ 1.

(11)

i∈oγi

The objective function (7) is to minimize the total task
duration. The ﬁrst constraint (8) indicates the local energy
consumption is less than the remainder battery capacity of
mobile device, where αi is the remainder energy consumption relative to the total battery capacity Emi ax. The second constraint (9) states the energy consumption of transmission
the task to edge cloud is limited by the battery of mobile
device. The third constraint (10) indicates that the associated BS are those provide service to the user ui. The last condition (11) indicates the amount of computation assigned to the γi should not exceed its total amount of computation, where oγi denotes the set of computing task placed at edge cloud γi. Without consider the resource allocation, the task duration minimization problem (7) can be proved NP-hard according
to [45].

IV. EFFICIENT TASK OFFLOADING SCHEME

In this section, we demonstrate an efﬁcient task ofﬂoading scheme according to the optimization problem mentioned in (7). We ﬁrst deﬁned the objective function as follows:

m
f (x, κ, λ) =
i=1

xi

ωi fil

+ (1 − xi)

ωi κγi i fγci

+

si ri,γi

(12)

For the sake of simplicity, we deﬁne λ = (x, γ). Let K and

H denote the feasible sets for κ and λ. Problem in (7) is a

mixed integer non-linear optimization problem. In this paper,

we adopt alternative optimization techniques and consider two

sub-problems as follows:

• Computing resource allocation problem: Given λ = λ0 ∈

H, i.e., when xi and γi is ﬁxed, the original optimization problem in (7) is a convex problem with respect to

κ. Then, we adopt the Karush¨CKuhn¨CTucker (KKT)

condition to obtain an optimal solution which is denoted by f (κ∗, λ0). • Task placement problem: Based on the solution κ∗, the sub-problem f (κ∗, λ) is a 0-1 integer programming

problem with respect to λ. We adopt the task placement

algorithm to obtain the solution.

Then, we provide a convergence proof of the problem. In this paper, we call this task ofﬂoading strategy as software deﬁned task ofﬂoading (SDTO).

A. Computing Resource Allocation Problem
Lemma 1: Given λ = λ0 ∈ H, the original optimization problem in (7) with respect to κi is a convex optimization problem.
Proof: From the (7), we can get the resource allocation only when the task is ofﬂoad to the edge cloud, i.e., xi = 0. Given γ = γ0 = (γ10, γ20, · · · , γm0 ) ∈ H, we denote j = γi0, the number of x0i = 1 is l, then the objective function (7) can be converted into the following equation:

f (κ, γ0)

=

l i=1

(

ωi κji fjc

+

si ) ri,j

(13)

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

592

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 36, NO. 3, MARCH 2018

where f (κ, γ0) is a function with respect to {κ1, κ2, · · · , κm}.

Then we can obtain its Hessian matrix as follows:

⎡ ∂2f

H

=

⎢⎢⎢⎢⎢⎢⎢⎢⎣

∂∂22κf1
∂κ2∂κ1 ...
∂2f

∂κm∂κ1

∂2f
∂κ∂12∂fκ2 ∂2κ2 ... ∂2f
∂κm∂κ2

··· ···
···

∂2f ⎤

∂κ∂12∂fκm
∂κ2∂κm ...
∂2f

⎥⎥⎥⎥⎥⎥⎥⎥⎦

.

∂2κm

where each speciﬁc element is:

⎧

∂2f ∂κi∂κj

⎪⎨ 2ωi = ⎪⎩0(κji )3fjc

if i = j otherwise

(14)

The parameters in (14) are all positive numbers, which

indicates

∂2f ∂ κi ∂ κj

≥ 0. Thus, it is concluded that all eigenvalues

of Hessian matrix H are positive numbers, and that H is

a symmetrical positive deﬁnite matrix. In accordance with

Theorems in [46], it is concluded that (7) is convex. Since

constraint is linear, it can be concluded that this problem is a

convex optimization problem.

In accordance with lemma 1, Theorem 1 can be obtained

with the KKT conditions.

Theorem 1: Given γ = γ0 ∈ H, the optimal value with respect to κ can be obtained, as shown in (17).

Proof: According to lemma 1, the Lagrange function of

the original optimization problem about (7) and (8) can be

obtained as follows:

L(κ, ν)

=

l i=1

(

ωi κji fjc

+

si ) + rij

j

νj ( κji − 1)
i∈oj

(15)

By the use of the KKT conditions, if κ˜, ν˜ is any point that satisﬁes the KKT conditions, we can conclude that:

n

∇f (κ˜j1, κ˜j2, · · · , κ˜jn) + ν˜j∇( κ˜ji − 1) = 0

j=1

i∈oj

κ˜ji − 1 = 0
i∈oj

By κ˜ji

solving by:

the

formula

above,

we

can

obtain

the

optimal

κ∗i

=

√

κ∗i =

i∈oωj √i ωi

(16)

Since

l i=1

f

(κ,

γ

0

)

=

n j=1

i∈oj f (κ, γ0), substitute (16)

into (13), we can obtain the optimal value of f (κ∗, γ0) as

follows:

n
f (κ∗, γ0) =
j=1 i⎡∈oj = n ⎢⎣
j=1

√ ωi

i∈oj (√ωi) + si

cj

ri,j

i∈oj √ωi cj

2

⎤

+

i∈oj

si ri,j

⎥⎦

(17)

B. Task Placement Problem
Through the above discussion, given λ = λ0 ∈ H, we can obtain the optimal solution in (17). Based on this, the original optimization problem is converted into integer programming problem with respect to x and γ as follows,

minimize f (x, κ∗, γ)

(18)

x,γ

subject to: xiεLi ≤ αiEmi ax ∀i = 1, 2, · · · , m.

(19)

(1 − xi)εEi ≤ αiEmi ax ∀i = 1, 2 · · · , m. (20)

γi ∈ A(ui) ∀i = 1, 2, · · · , m.

(21)

In this section, we propose a task placement algorithm to solve

this optimization problem.

First, we rewrite this optimization problem and transfer it
into a 0-1 integer programming. Let Z = (zij)m×(n+m), zij ∈ {0, 1} denote the matrix to be solved out. Speciﬁcally, when j = 1, 2, · · · , n, it indicate task is processed on edge cloud; when j = n+1, n+2, · · · , n+m, it indicates that the task Qi is locally processed. zij represents whether task Qi is processed locally, or processed at edge cloud bj. If zij = 0, the task Qi will not be ofﬂoaded on edge cloud and processed locally. Likewise, if zij = 1, the task i will be ofﬂoaded on edge cloud or processed locally. Here, Z is analogous to γ and x,

i.e., aiming at the same task placement problem. Furthermore,

we denoted variables as follows:

√√

√

W = ( ω1, ω2, · · · , ωm)

S = (s1, s2, · · · , sm)

P

=

⎡(p1,

p2 1

,

·

·

·

, pm)

C = ⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

f1c 0
... 0

0 ··· 1
··· f2c ... 0 ···

0

0 ···

⎡

r11 · · · r1n 0

R

=

⎢⎢⎢⎣

r21 ...

··· ...

r2n ...

0 ...

0
0 ... 1 fml −1 0
⎤ ··· 0 · · · 0 ⎥⎥⎥⎦

⎤

0
0 ... 0 1

⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦

fml

rm1 · · · rmn 0 · · · 0 m×(n+m)

Therefore, we can rewrite the optimization problem in (18) with respect to γ and x into optimization problem as follows:

minimize
Z

(W ZC)T

2 2

+

SZR

(22)

subject to xij ∈ {0, 1}

(23)

n+1

xij = 1, i = 1, 2, · · · , m. (24)

j=1

The objective function with respect to variable Z aims to reduce the task duration The constraint is that each task is placed on edge cloud or process locally. As for this problem,

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

CHEN AND HAO: TASK OFFLOADING FOR MOBILE EDGE COMPUTING

593

assume there are n tasks to be processed, then there are 2n+1 choices to place task on, which is NP-hard.
In order to solve this problem, we deﬁne a continuous normal variable yij, which satisﬁes the following conditions:

n+1

yij ≥ 0,

yij = 1, i = 1, 2, · · · , m.

j=1

Based on the variable yij, we denote a linear function as

φ(yij )

=

yij yitj−1 +

,

where

is a quite small regularization

constant and t is the number of iterations. Similar with the

work in [47], we utilize linear function φ(yij ) to substitute X in the (22). Then, similar with Theorem 1, it is concluded that

the modiﬁed objective function of (22) is a convex function.

The speciﬁc solving algorithm is shown in Algorithm 1.

obtain φtij (yi∗j ) as follows:

φtij (yi∗j )

=

yi∗j yitj−1 +

≈

1 if yi,j > 0 0 if yij = 0

Therefore, we can obtain that φtij (yi∗j ) is approximately equal to Z, i.e., the solution of the modiﬁed optimization problem is
approximately equal to the solution of the original problem.
Secondly, the solution to the two sub-problems is also
applicable for the original optimization problem. f (κ, λ) is the original optimization function. Given λ = λ0 ∈ H, based on the discussion in Section V(A), f (κ, γ0) is convex in κ. Thus, ∃ κ∗ ∈ K, and the following inequality holds

f (κ∗, λ0) ≤ f (κ, λ0)

Algorithm 1 Task Placement Algorithm

Input: Give initial task placement, yi0j; Give a quite small error bound, δ;

Output:

Task placement, φ;

1: t := 0. yi0j := 1 − , where is a quite small regularization constant;

2: t := t + 1;

3:

Assume φtij (yij )

the iterative = , i yij
yitj−1 +

result above = 1, 2, · · · ,

is given m, j =

as {yitj−1}, 1, 2, · · · , n

deﬁne + 1;

4: Substitute the variable φtij (yij) obtained above for X in

optimization problem, and {yitj} can be obtained through

solving the modiﬁed optimization problem of Eq.(16).

5: If |yitj − yitj−1| < δ, we can obtain yi∗j = yitj; else, go to

step 2;

Given κ = κ∗ ∈ K, according to the discussion in Section V(B), f (κ∗, λ) is 0-1 integer programming with respect to λ. Based on Algorithm 1, for ∃ λ∗ ∈ H, the following inequality can be obtained
f (κ∗, λ∗) ≤ f (κ∗, λ)
Based on above two inequalities, for ∀κ ∈ K and λ ∈ H, the following inequality holds
f (κ∗, λ∗) ≤ f (κ, λ∗) ≤ f (κ, λ)
Thus, f (κ∗, λ∗) can be obtained through solving the above two sub-problems, and also serves as the efﬁcient solution for the original optimization problem.
V. PERFORMANCE ANALYSIS

The key step in algorithm above is step 4. As for each

iteration

in

step

4,

we

substitute

function

φtij (yij )

=

yij yitj−1 +

for variable xij in the objective function of (22) and replace

function yij for xij in the condition of (23) and (24). As dis-

cussed above, we can conclude that the modiﬁed objective

function is a convex, and that modiﬁed condition are linear.

Thus, the modiﬁed problem is a convex optimization problem

which can be solved.

In this section, a simulation experiment is provided concerning task ofﬂoading for mobile computing in SD-UDN. The experimental results are divided into three parts: (i) we compare the proposed SDTO with several task ofﬂoading schemes in terms of task duration and energy cost; (ii) we study the impact of task computation amount on the evaluated metrics; (iii) we investigate the impact of task data size on the performance of task ofﬂoading.

C. Convergence Analysis

In this section, the convergence of Algorithm 1 will be analyzed. Based on the step 4 at Algorithm 1, we can obtain

yitj

=

argminf
yij

(

yij yitj−1 +

) δ

According to the global convergence theorem in [48], Algorithm 1 is converged. However, there is a question: why the solution of the modiﬁed optimization problem in Algorithm 1 is approximately equal to the solution of the problem of (16). Now, we give proof that function φtij (yij) is equal to variable xij if |yitj − yitj−1| < δ. Since δ is a minimal positive number, we can obtain that yitj−1 ≈ yitj = yi∗j. Thus, we can

A. Experiment Setup
For task Qi, we assume computation amount ωi and data size si are generated by a probability distribution. The total computing resource of edge cloud is 25 GHz, while the total computing resource of mobile device is 10 GHz. Then, the processing time is 1/20 second when the computation task is processed by edge cloud and 1/10 second when the computation task is processed by mobile device. To mimic a ultra-dense network environment, we simulate a 500 m × 500 m square area with 15 BSs. The users can connect with BSs within 100m. Similar as the work in [36], we model the channel gain as follows: 127 + 30 × log d, the other settings of the simulation parameters are given in Table III.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

594

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 36, NO. 3, MARCH 2018

Fig. 2. Impact of computation amount on task duration.

Fig. 3. Impact of computation amount on energy cost.

TABLE III SIMULATION PARAMETERS

processing and the other part is local processing. (ii) Resource allocation, similar to random ofﬂoading scheme, based on the uniform task placement strategy, the resource allocation is given by using the (17).
For the three methods above, we evaluate ofﬂoading performance in terms of task duration and energy cost. We ﬁrst give the average utilization rate of the above three kinds of ofﬂoading schemes, the resource utilization rate of the random ofﬂoading scheme, uniform ofﬂoading scheme and the SDTO scheme are 75%, 80% and 92%, respectively.

B. Comparison With Other Methods
The SDTO, proposed in this paper, is compared with two different ofﬂoading strategies: random ofﬂoading scheme and uniform ofﬂoading scheme.
• Random ofﬂoading scheme: (i) Task placement, the computation tasks are ofﬂoaded to edge cloud for processing or processed locally randomly. We set up a random generator that can generate the number 0 and 1 with equal probability, and then we ofﬂoad computation tasks to be processed onto edge cloud or process locally randomly according to the random generator. (ii) Resource allocation, based on the random task placement strategy, the resource allocation is given by using the (17).
• Uniform ofﬂoading scheme: (i) Task placement, we divide all the tasks into two parts according the user’s battery capacity, one part in the edge cloud

C. Impact of Computation Amount on Ofﬂoading Performance
We ﬁrst consider the impact of computation amount on ofﬂoading performance. The data size of task follows a normal distribution with mean value of 5 MB. As for the computation amount, three kinds of distribution are utilized, i.e., uniform distribution, normal distribution and Pareto distribution.
As shown in Fig. 2 and Fig. 3, we can conclude that the larger the computation amount of a task, the longer task duration is caused with more energy cost. Furthermore, our proposed SDTO exhibits shorter task duration and lower energy cost than random ofﬂoading scheme and uniform ofﬂoading scheme. This is because the efﬁcient ofﬂoading scheme is obtained by comprehensively considering the computation amount and data size of task content, so as to minimize task duration and energy cost.
In Fig. 2(a) and Fig. 3(a), when the computation amount follows normal distribution, compared with random ofﬂoading

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

CHEN AND HAO: TASK OFFLOADING FOR MOBILE EDGE COMPUTING

595

Fig. 4. Impact of data size on task duration.

Fig. 5. Impact of data size on energy cost.

scheme, it is shown that our proposed SDTO can reduce 30% task duration and 10% energy cost. And compared with uniform ofﬂoading scheme, our scheme can reduce 41% of the task duration and 11% of the energy cost. As shown in Fig. 2(b) and Fig. 3(b), when the computation amount follows uniform distribution, the results are similar with the case based on normal distribution. In Fig. 2(c) and Fig. 3(c), when the computation amount follows Pareto distribution, it is observed the curve trend is not as smooth as that in normal distribution and uniform distribution, which is because the Pareto distribution has the long tail effect, and we set the interval as 0.1 when we generate the Pareto distribution.
D. Impact of Data Size on Computation Ofﬂoading
In this section, we consider the impact of data size on computation ofﬂoading. The computation amount of task follows a normal distribution with mean value of 1 Gigacycle. For data size, three kinds of distributions are utilized, i.e., uniform distribution, normal distribution and Pareto distribution.
As shown in Fig. 4 and Fig. 5, we can conclude that the larger the data size of the task, the longer task duration and the more energy cost. We can further conclude that our proposed ofﬂoading scheme exhibits shorter task duration and lower energy cost than random ofﬂoading scheme and uniform ofﬂoading scheme.
In Fig. 4(a) and Fig. 5(a), when computation amount follows normal distribution, compared with random ofﬂoading scheme, it is shown that our proposed ofﬂoading scheme can reduce 30% of the task duration and 5% of the energy cost. And compared with uniform ofﬂoading scheme, our scheme can reduce 28% of the task duration and 5% of the energy cost.

As shown in Fig. 4(b) and Fig. 5(b), when computation amount follows uniform distribution, the results are similar with the case of normal distribution. In Fig. 4(c) and Fig. 5(c), when computation amount follows Pareto distribution, we see that the curve trend is not as smooth as that in normal distribution and uniform distribution, which is because the Pareto distribution has the long tail effect, and we set the interval at 0.5 when we generate the Pareto distribution. Throughout the above analysis, we can also conclude that the effect of data size on task duration and energy cost is lower than that of computation amount.
VI. CONCLUSION
In this paper, we ﬁrst propose the architecture of software deﬁned ultra dense network (SD-UDN). Then, we propose a scheme to ofﬂoad task on edge cloud or process locally. In order to minimize the task duration, computing resource is optimally allocated to each task. To the best of our knowledge, this is the ﬁrst study of task ofﬂoading for mobile edge computing in SD-UDN. Simulation results have shown that our proposed scheme is more efﬁcient compared to the random and uniform computation ofﬂoading schemes. In future work, we will consider task ofﬂoading in more complicate deployment with users mobility.
REFERENCES
[1] Cisco Visual Networking Index: Global Mobile Data Trafﬁc Forecast Update 2016–2021 White Paper, Feb. 2017. [Online]. Available: http://www.cisco.com/c/en/us/solutions/collateral/serviceprovider/visual-networking-index-vni/mobile-white-paper-c11520862.pdf

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

596

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 36, NO. 3, MARCH 2018

[2] Z. Chen et al., “An empirical study of latency in an emerging class of edge computing applications for wearable cognitive assistance,” in Proc. 2nd ACM/IEEE Symp. Edge Comput., Oct. 2017, pp. 1–14.
[3] T. Taleb, A. Ksentini, M. Chen, and R. Jantti, “Coping with emerging mobile social media applications through dynamic service function chaining,” IEEE Trans. Wireless Commun., vol. 15, no. 4, pp. 2859–2871, Apr. 2016.
[4] D. Tian, J. Zhou, Z. Sheng, and V. C. Leung, “Robust energy-efﬁcient MIMO transmission for cognitive vehicular networks,” IEEE Trans. Veh. Technol., vol. 65, no. 6, pp. 3845–3859, Jun. 2016.
[5] D. Tian, J. Zhou, Z. Sheng, M. Chen, Q. Ni, and V. C. M. Leung, “Self-organized relay selection for cooperative transmission in vehicular ad-hoc networks,” IEEE Trans. Veh. Technol., vol. 66, no. 10, pp. 9534–9549, Oct. 2017.
[6] Y. Li, D. Jin, P. Hui, and Z. Han, “Optimal base station scheduling for device-to-device communication underlaying cellular networks,” IEEE J. Sel. Areas Commun., vol. 34, no. 1, pp. 27–40, Jan. 2016.
[7] H. Wang, F. Xu, Y. Li, P. Zhang, and D. Jin, “Understanding mobile trafﬁc patterns of large scale cellular towers in urban environment,” in Proc. ACM Conf. Internet Meas. Conf., 2015, pp. 225–238.
[8] Y. Zhang, M. Qiu, C.-W. Tsai, M. M. Hassan, and A. Alamri, “HealthCPS: Healthcare cyber-physical system assisted by cloud and big data,” IEEE Syst. J., vol. 11, no. 1, pp. 88–95, Mar. 2017.
[9] Y. Zhang, R. Yu, M. Nekovee, Y. Liu, S. Xie, and S. Gjessing, “Cognitive machine-to-machine communications: Visions and potentials for the smart grid,” IEEE Netw., vol. 26, no. 3, pp. 6–13, May/Jun. 2012.
[10] Y. Zhang, M. Chen, N. Guizani, D. Wu, and V. C. Leung, “SOVCAN: Safety-oriented vehicular controller area network,” IEEE Commun. Mag., vol. 55, no. 8, pp. 94–99, Aug. 2017.
[11] Y. Zhang, Z. Tu, and Q. Wang, “TempoRec: Temporal-topic based recommender for social network services,” Mobile Netw. Appl., vol. 22, no. 6, pp. 1182–1191, 2017.
[12] M. Chen, Y. Hao, M. Qiu, J. Song, D. Wu, and I. Humar, “Mobilityaware caching and computation ofﬂoading in 5G ultra-dense cellular networks,” Sensors, vol. 16, no. 7, p. 974, 2016.
[13] T. Taleb, A. Ksentini, and R. Jantti, “‘Anything as a service’ for 5G mobile systems,” IEEE Netw., vol. 30, no. 6, pp. 84–91, Nov. 2016.
[14] M. Chen, Y. Zhang, L. Hu, T. Taleb, and Z. Sheng, “Cloud-based wireless network: Virtualized, reconﬁgurable, smart wireless network to enable 5G technologies,” Mobile Netw. Appl., vol. 20, no. 6, pp. 704–712, Dec. 2015.
[15] T. Taleb, K. Samdanis, B. Mada, H. Flinck, S. Dutta, and D. Sabella, “On multi-access edge computing: A survey of the emerging 5G network edge cloud architecture and orchestration,” IEEE Commun. Surveys Tuts., vol. 19, no. 3, pp. 1657–1681, 3rd Quart., 2017.
[16] S. Zhang, N. Zhang, S. Zhou, J. Gong, Z. Niu, and X. Shen, “Energyaware trafﬁc ofﬂoading for green heterogeneous networks,” IEEE J. Sel. Areas Commun., vol. 34, no. 5, pp. 1116–1129, May 2016.
[17] L. Tong, Y. Li, and W. Gao, “A hierarchical edge cloud architecture for mobile computing,” in Proc. 35th IEEE Conf. Comput. Commun., Apr. 2016, pp. 1–9.
[18] X. Chen, L. Jiao, W. Li, and X. Fu, “Efﬁcient multi-user computation ofﬂoading for mobile-edge cloud computing,” IEEE/ACM Trans. Netw., vol. 24, no. 5, pp. 2795–2808, Oct. 2016.
[19] M. Chen, Y. Hao, Y. Li, C.-F. Lai, and D. Wu, “On the computation ofﬂoading at ad hoc cloudlet: Architecture and service modes,” IEEE Commun. Mag., vol. 53, no. 6, pp. 18–24, Jun. 2015.
[20] M. Barbera, S. Kosta, A. Mei, and J. Stefa, “To ofﬂoad or not to ofﬂoad? The bandwidth and energy costs of mobile cloud computing,” in Proc. IEEE INFOCOM, Apr. 2013, pp. 1285–1293.
[21] X. Hou, Y. Li, M. Chen, D. Wu, D. Jin, and S. Chen, “Vehicular fog computing: A viewpoint of vehicles as the infrastructures,” IEEE Trans. Veh. Technol., vol. 65, no. 6, pp. 3860–3873, Jun. 2016.
[22] C. Gao, Y. Li, Y. Zhao, and S. Chen, “A two-level game theory approach for joint relay selection and resource allocation in network coding assisted D2D communications,” IEEE Trans. Mobile Comput., vol. 16, no. 10, pp. 2697–2711, Oct. 2017.
[23] D. Kreutz, F. Ramos, P. E. Veríssimo, C. E. Rothenberg, S. Azodolmolky, and S. Uhlig, “Software-deﬁned networking: A comprehensive survey,” Proc. IEEE, vol. 103, no. 1, pp. 14–76, Jan. 2015.
[24] A. Ksentini, M. Bagaa, and T. Taleb, “On using SDN in 5G: The controller placement problem,” in Proc. IEEE Global Commun. Conf. (GLOBECOM), Dec. 2016, pp. 1–6.

[25] A. Ksentini, M. Bagaa, T. Taleb, and I. Balasingham, “On using bargaining game for optimal placement of SDN controllers,” in Proc. IEEE Int. Conf. Commun. (ICC), May 2016, pp. 1–6.
[26] M. Bagaa, T. Taleb, and A. Ksentini, “Service-aware network function placement for efﬁcient trafﬁc handling in carrier cloud,” in Proc. IEEE Wireless Commun. Netw. Conf. (WCNC), Apr. 2014, pp. 2402–2407.
[27] B. E. Mada, M. Bagaa, and T. Taleb, “Efﬁcient transcoding and streaming mechanism in multiple cloud domains,” in Proc. IEEE Global Commun. Conf. GLOBECOM, Dec. 2017, pp. 1–6.
[28] I. Benkacem, T. Taleb, M. Bagaa, and H. Flinck, “Performance benchmark of transcoding as a virtual network function in CDN as a service slicing,” in Proc. IEEE WCNC, Barcelona, Spain, Apr. 2018, pp. 1–6.
[29] D. L. C. Dutra, M. Bagaa, T. Taleb, and K. Samdanis, “Ensuring end-to-end QoS based on multi-paths routing using SDN technology,” in Proc. IEEE GLOBECOM, Singapore, Dec. 2017, pp. 1–6.
[30] B.-G. Chun, S. Ihm, P. Maniatis, M. Naik, and A. Patti, “Clonecloud: Elastic execution between mobile device and cloud,” in Proc. 6th Conf. Comput. Syst., 2011, pp. 301–314.
[31] A. Ksentini, T. Taleb, and M. Chen, “A Markov decision process-based service migration procedure for follow me cloud,” in Proc. IEEE Int. Conf. Commun. (ICC), Jun. 2014, pp. 1350–1354.
[32] T. Taleb and A. Ksentini, “An analytical model for follow me cloud,” in Proc. IEEE Global Commun. Conf. (GLOBECOM), Dec. 2013, pp. 1291–1296.
[33] M. Chen, Y. Hao, L. Hu, K. Huang, V. Lau, “Green and mobilityaware caching in 5G networks,” IEEE Trans. Wireless Commun., vol. 16, no. 12, pp. 8347–8361, 2017.
[34] Y. Liu, M. J. Lee, and Y. Zheng, “Adaptive multi-resource allocation for cloudlet-based mobile cloud computing system,” IEEE Trans. Mobile Comput., vol. 15, no. 10, pp. 2398–2410, Oct. 2016.
[35] T. Taleb, S. Dutta, A. Ksentini, M. Iqbal, and H. Flinck, “Mobile edge computing potential in making cities smarter,” IEEE Commun. Mag., vol. 55, no. 3, pp. 38–43, Mar. 2017.
[36] Y. Sun, S. Zhou, and J. Xu, “EMM: Energy-aware mobility management for mobile edge computing in ultra dense networks,” IEEE J. Sel. Areas Commun., vol. 35, no. 11, pp. 2637–2646, Nov. 2017.
[37] Y. Xiao and M. Krunz, “QoE and power efﬁciency tradeoff for fog computing networks with fog node cooperation,” in Proc. IEEE Conf. Comput. Commun. (INFOCOM), May 2017, pp. 1–9.
[38] T. X. Tran and D. Pompili. (2017). “Joint task ofﬂoading and resource allocation for multi-server mobile-edge computing networks.” [Online]. Available: https://arxiv.org/abs/1705.00704
[39] Y. Li and W. Wang, “Can mobile cloudlets support mobile applications?” in Proc. IEEE INFOCOM, Apr. 2014, pp. 1060–1068.
[40] C. Wang, Y. Li, and D. Jin, “Mobility-assisted opportunistic computation ofﬂoading,” IEEE Commun. Lett., vol. 18, no. 10, pp. 1779–1782, Oct. 2014.
[41] T. Truong-Huu, C.-K. Tham, and D. Niyato, “A stochastic workload distribution approach for an ad hoc mobile cloud,” in Proc. IEEE 6th Int. Conf. Cloud Comput. Technol. Sci. (CloudCom), Dec. 2014, pp. 174–181.
[42] R. Jain and S. Paul, “Network virtualization and software deﬁned networking for cloud computing: A survey,” IEEE Commun. Mag., vol. 51, no. 11, pp. 24–31, Nov. 2013.
[43] S. Retal, M. Bagaa, T. Taleb, and H. Flinck, “Content delivery network slicing: QoE and cost awareness,” in Proc. IEEE Int. Conf. Commun. (ICC), May 2017, pp. 1–6.
[44] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey on mobile edge computing: The communication perspective,” IEEE Commun. Surveys Tuts., vol. 19, no. 4, pp. 2322–2358, 4th Quart., 2017.
[45] Y. Pochet, L. A. Wolsey, Production Planning by Mixed Integer Programming. Berlin, Germany: Springer, 2006.
[46] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge, U.K.: Cambridge Univ. Press, 2004.
[47] Y. Liu, D. Niu, and B. Li, “Delay-optimized video trafﬁc routing in software-deﬁned interdatacenter networks,” IEEE Trans. Multimedia, vol. 18, no. 5, pp. 865–878, May 2016.
[48] D. G. Luenberger, Introduction to Linear and Nonlinear Programming, vol. 28. Reading, MA, USA: Addison-Wesley, 1973.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

CHEN AND HAO: TASK OFFLOADING FOR MOBILE EDGE COMPUTING
Min Chen (SM’09) was an Assistant Professor with the School of Computer Science and Engineering, Seoul National University (SNU). He was a PostDoctoral Fellow with the Department of Electrical and Computer Engineering, University of British Columbia for three years and also with SNU for one and a half years. He has been a Full Professor with the School of Computer Science and Technology, Huazhong University of Science and Technology since 2012, where he is currently the Director of the Embedded and Pervasive Computing Lab. He has authored over 300 papers, including over 200 SCI papers, over 80 IEEE Transactions/journal papers, 16 ISI highly cited papers, and eight hot papers. He has authored four books: OPNET IoT Simulation (HUST Press, 2015), Big Data Inspiration (HUST Press, 2015), 5G Software Deﬁned Networks (HUST Press, 2016), and Introduction to Cognitive Computing (HUST Press, 2017), a book on big data: Big Data Related Technologies (2014), and a book on 5G: Cloud Based 5G Wireless Networks (2016) with Springer Series in computer science. His latest book (co-authored with Prof. K. Hwang) on Big Data Analytics for Cloud/IoT and Cognitive Computing (U.K.: Wiley, 2017). His Google Scholars Citations reached over 11 800 with an h-index of 53. His top paper was cited over 1200 times. His research interests include cyber physical systems, IoT sensing, 5G networks, mobile cloud computing, SDN, healthcare big data, medica cloud privacy and security, body area networks, emotion communications, and robotics. He received the IEEE Communications Society Fred W. Ellersick Prize in 2017. He received the Best Paper Award from QShine 2008, the IEEE ICC 2012, ICST IndustrialIoT 2016, and the IEEE IWCMC 2016. He is the Chair of the IEEE Computer Society Special Technical Communities on Big Data. He is the Co-Chair of the IEEE ICC 2012-Communications Theory Symposium and the IEEE ICC 2013-Wireless Networks Symposium. He is the General Co-Chair for the IEEE CIT-2012, Tridentcom 2014, Mobimedia 2015, and Tridentcom 2017. He is a Keynote Speaker for CyberC 2012, Mobiquitous 2012, Cloudcomp 2015, IndustrialIoT 2016, and The 7th Brainstorming Workshop on 5G Wireless. He serves as an Editor or Associate Editor for the Information Sciences, Information Fusion, and the IEEE ACCESS. He is a Guest Editor for the IEEE NETWORK, the IEEE WIRELESS COMMUNICATIONS, and the IEEE TRANSACTIONS ON SERVICE COMPUTING.

597
Yixue Hao received the B.E. degree from Henan University, China, and the Ph.D. degree in computer science from the Huazhong University of Science and Technology, China, in 2017. He is currently a Post-Doctoral Scholar with the School of Computer Science and Technology, Huazhong University of Science and Technology. His research interests include 5G network, Internet of Things, edge caching, and mobile edge computing.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:07:20 UTC from IEEE Xplore. Restrictions apply.

