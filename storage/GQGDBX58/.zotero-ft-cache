4942

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019

HetMEC: Latency-Optimal Task Assignment and Resource Allocation for Heterogeneous
Multi-Layer Mobile Edge Computing
Pengfei Wang , Student Member, IEEE, Zijie Zheng , Student Member, IEEE, Boya Di , Member, IEEE, and Lingyang Song , Fellow, IEEE

Abstract‚Äî Driven by great demands on low-latency services of the edge devices (EDs), mobile edge computing (MEC) has been proposed to enable the computing capacities at the edge of the radio access network. However, conventional MEC servers suffer some disadvantages such as limited computing capacity, preventing and computation-intensive tasks to be processed on time. To relief this issue, we propose the heterogeneous multi-layer MEC (HetMEC) where data that cannot be timely processed at the edge are allowed to be ofÔ¨Çoaded to the upperlayer MEC servers, and Ô¨Ånally to the cloud center (CC) with more powerful computing capacity. We aim to minimize the system latency, i.e., the total computing and transmission time on all layers for the data generated by the EDs. We design the latency minimization algorithm by jointly coordinating the task assignment, computing, and transmission resources among the EDs, multi-layer MEC servers, and the CC. The simulation results indicate that our proposed algorithm can achieve a lower latency and higher processing rate than the conventional MEC scheme.
Index Terms‚Äî Heterogeneous multi-layer mobile edge computing (MEC), task assignment, resource allocation.
I. INTRODUCTION
W ITH the rise of the Internet of Things (IoT), namely a network including interconnected devices capable of exchanging information [1], [2], huge amount of data are generated and transmitted throughout the communication networks [3]. However, the computing capacities of the current communication networks are not sufÔ¨Åcient to satisfy users‚Äô increasing demands on high data rates [4]. Traditionally, cloud computing has been proposed as an effective solution for such data explosion by making use of the strong computing capacity of the data center [5]. As a centralized paradigm, cloud computing can provide a wide range of services and massive computing resources supported by a large group of
Manuscript received January 16, 2019; revised May 12, 2019 and July 16, 2019; accepted July 22, 2019. Date of publication August 6, 2019; date of current version October 9, 2019. This work was supported by the National Nature Science Foundation of China under Grant 61625101. The associate editor coordinating the review of this article and approving it for publication was Z. Dawy. (Corresponding author: Lingyang Song.)
The authors are with the Department of Electronics, Peking University, Beijing 100871, China (e-mail: wangpengfei13@pku.edu.cn; zijie.zheng@pku.edu.cn; diboya@pku.edu.cn; lingyang.song@pku.edu.cn).
Color versions of one or more of the Ô¨Ågures in this article are available online at http://ieeexplore.ieee.org.
Digital Object IdentiÔ¨Åer 10.1109/TWC.2019.2931315

computers in the data center. However, the data transmission from the edge of the network to the remote cloud center usually induces high latency, which is unacceptable for the latency-sensitive applications [6], [7].
To deal with the dilemma of cloud computing, mobile edge computing (MEC) has been investigated, which enables the computation to be performed at the mobile devices and the access points (APs)1 within the radio access networks [8], [9]. The MEC servers that possess the computing resources, e.g., the APs, offer rich services in close proximity to the end users, also known as the edge devices (EDs) [10]. When these EDs generate computation tasks at the edge of the communication networks, they can ofÔ¨Çoad tasks to the MEC servers nearby rather than the remote cloud center [11]. Therefore, the MEC provides the low-latency and highefÔ¨Åcient data processing due to the proximity of the computing resources [12], [13]. However, most works only consider the MEC servers that directly communicate with the EDs via wireless links to offer the in-proximity services [14]‚Äì[16]. Due to the limited computing capacities of these MEC servers, it would be desirable that the data that cannot be processed at the MEC servers can be further ofÔ¨Çoaded to the upper-layer MEC servers, until to the cloud center (CC).
In this paper, we consider heterogeneous multi-layer MEC (HetMEC) for uplink communications to reduce the overall system latency, i.e., the total computing and transmission time of all layers of MEC servers and the CC. In the HetMEC network, EDs divide and ofÔ¨Çoad the computational intensive tasks to multi-layer MEC servers and the CC for latency performance improvement [6]. ClassiÔ¨Åed by the locations in the wired-wireless networks, various function nodes with certain computing capacities serve as the MEC servers on different layers, that is, the APs, switches, network gateways, and small data centers from the bottom up [17]. The data Ô¨Çow of each ED Ô¨Årst transits in the radio access networks via a wireless ED-AP link. The received data of each AP are then partially processed and delivered to the wired core network, passing through the switches, network gateways, and the small data centers sequentially [18]. Locating at bottom-up layers, these MEC servers provide increasing computing capacity for
1Base stations are the typical APs in the radio access networks.

1536-1276 ¬© 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: HetMEC: LATENCY-OPTIMAL TASK ASSIGNMENT AND RESOURCE ALLOCATION FOR HetMEC

4943

data processing and Ô¨Ånally send the data from the bottom layers to the remote CC.2 Based on such a HetMEC structure, the computing resources of multi-layer MEC servers and the CC can be fully exploited to support computation-intensive and latency-sensitive tasks of the EDs with strong robustness.
A number of challenges induced by the heterogeneous nature of the multi-layer MEC networks still remain to be solved. First, since the data of each task can be divided and partially processed by multiple MEC servers on different layers, the task assignments among these servers are coupled with each other by the limited resources of their own. In other words, the amount of ofÔ¨Çoaded data in one MEC layer is correlated with that in all the other layers, which is different from that in the traditional MEC networks.3 Second, the transmission resource allocation in both the wireless and wired network need to be considered, which are closely related with the task assignment among multiple layers of MEC servers. To be speciÔ¨Åc, the allocated wired transmission resources directly restrict the data transmission rate between adjacent layers of MEC servers. Third, due to the limited computing capacity of each MEC server, the robustness of the HetMEC network should be considered and evaluated in response to various data generation speed at the EDs for different applications.
In the literature, the above challenges induced by the HetMEC architecture have not been fully addressed [20]‚Äì[22]. Most existing works either do not consider the task assignment, computing and transmission resource allocation jointly [23]‚Äì[27], or fail to depict the relations between multiple layers in the HetMEC network [28], [29]. In [23], an efÔ¨Åcient k-out-of-n task assignment scheme is proposed to minimize the execution time on multiple processor nodes and save energy consumption. In [24], the transmission resource allocation is studied for multi-user mobile edge computational ofÔ¨Çoading constrained by the computation latency. Authors in [26] analyze the transmission latency and computation latency separately, taking the task assignment and computing rate control into account. In [28], the traditional MEC networks are discussed, where the MEC computing resource allocation and uplink power allocation are studied along with the binary4 task ofÔ¨Çoading. In [29], the computation ofÔ¨Çoading and interference management are performed in the wireless cellular networks with a single MEC server. Unfortunately, joint task assignment among multi-layer MEC servers in the HetMEC network has not been taken into account together with the computing and transmission resource allocation.
The main contributions of our paper are summarized as follows.
‚Ä¢ We study the HetMEC network consisting of the EDs, multiple layer of MEC servers and the CC. The uplink transmission is considered where the data generated at
2It is worth noting that the switches, network gateways or small data centers are not all necessary in the wired networks. The APs are possible to connect with the network gateways directly, and the network gateways may also connect with the remote cloud center.
3In the traditional MEC networks, EDs can ofÔ¨Çoad data to only one layer of MEC servers, i.e., the APs.
4The binary task ofÔ¨Çoading means that the task is impartible and is processed at either the edge device or the MEC server.

Fig. 1. The architecture of the HetMEC network.
the EDs are processed at multiple layers of MEC servers and Ô¨Ånally aggregated at the CC. ‚Ä¢ In order to improve the latency performance of the HetMEC network, we jointly consider the task assignment, computing and transmission resource allocation among multiple layers. To minimize the sum of the computing and transmission time on all layers, a latency minimization algorithm (LMA) is developed to achieve the global-optimal system latency. ‚Ä¢ Simulations are performed in the considered HetMEC networks with different numbers of layers, and the results show that our algorithm LMA achieves a lower latency and higher processing rate than the previous schemes. The inÔ¨Çuence of the number of MEC layers on the robustness performance has been discussed. The rest of the paper is organized as follows. In Section II we describe the system model of the HetMEC network. In Section III we discuss the system constraints of the HetMEC network and formulate the system latency minimization problem. To solve this problem, we design the algorithm LMA and analyze the inÔ¨Çuence of the number of MEC layers on the network robustness in Section IV. Simulation results are given in Section V. Finally the conclusions are drawn in Section VI.
II. SYSTEM MODEL
As shown in Fig. 1, we consider a HetMEC network consisting of the EDs, N layers of MEC servers, and a CC. Each ED accesses the network by the AP through the wireless links between them. The uploaded data received by the EDs can then be forwarded to the MEC servers on the upper layers, connecting to the CC via wired links.5 The number
5Though wireless technologies are studied to be potential for the backhual design [30], in our paper, we only consider the traditional backhuals where MEC servers and the CC are connected via wired links, i.e., optical Ô¨Åber.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

4944

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019
TABLE I SUMMARY OF KEY NOTATION

of devices on each layer n is denoted by Mn, 1 ‚â§ n ‚â§ N . In such a tree structure, each node (ED or MEC server) connects with at most one parent node in the upper layer. The number of the child nodes6 connected with the parent node i on layer n is denoted by Qin, and the set of the child nodes is denoted by Qin. Each node has a different computing capacity.7 To communicate with its child nodes, each MEC server and the CC possesses a certain amount of wireless or wired transmission resources.8 We assume that all nodes access the wireless or wired channel via time division multiple access (TDMA) technology, implying that the frequency bands occupied by any two APs are orthogonal.
For a typical uplink MEC application, where the raw data are generated at the EDs and the results of the data processing need to be aggregated at the CC. The task generated at the ED is divided into multiple parts, and the ED, each MEC server on different layers or the CC only processes a part of it.9 After processing its own part, the processing results and the remaining raw data are delivered to the upper layer. The percentage of the data to be processed at each node is adjustable. Moreover, once the data are processed at the edge of the network, i.e., at the ED or MEC servers, the output results, which are then forwarded to the CC, usually have a much smaller size than the raw data. The computing and transmitting at different devices are performed in parallel. The processing results and the raw data do not need to be transmitted simultaneously, i.e., the device can Ô¨Årst transmit the raw data to the upper layers so that they can start their computation instead of waiting for the lower layer to Ô¨Ånish processing its part.
We consider the data generated in one time period at the EDs. For computing, the computing capacity of a device is

√à 6That is to say,

Mn‚àí1 i=1

Qni ‚àí1

=

Mn.

7The computing capacity can be described by cycles per second.

8Among the MEC servers, the APs possess the wireless transmission

resources, while the others possess the wired transmission resources.

9The EDs, MEC servers and the CC all can process the raw data.

represented by the amount of data processed in one period. For transmitting, the transmission capacity of a device can be reÔ¨Çected by the total amount of the data that can be transmitted in that time period. When multiple devices transmit the data to the same MEC server or CC via the TDMA manner, the MEC server or CC will allocate the time resources to those devices according to the proportion of their transmitted data amount in the total received data. Therefore, we utilize the data transmission amount in each period to reÔ¨Çect the transmission resource.
The mathematical models of data processing and transmitting at the ED, MEC server and CC are listed below.

A. Edge Device
The EDs, including the cars, smartwatches, cameras, etc., are on the bottom of the HetMEC networks, and usually responsible for generating the raw data. For convenience, we refer to the EDs as layer N + 1. Each ED processes part of the raw data, and delivers the results of the raw data together with the rest raw data to the node (AP) on the N -th layer via wireless link. Let siN+1 represent the task division percentage of ED i, which satisÔ¨Åes that

0 ‚â§ siN+1 ‚â§ 1.

(1)

Let ŒªiN+1 denotes the data generation speed of ED i, and biN+1 denotes the required number of CPU cycles for processing these data in each time period. For the same kind of tasks,
the data format and the processing procedure are same. There-
fore, the required number of CPU cycles are proportional to the amount of raw data, and the proportion coefÔ¨Åcient is denoted by Œº, representing the average required number of CPU cycles for processing each bit of raw data. The compression ratio after the data processing is denoted by œÅ. The computing capacity and the wireless transmitting capacity of ED i connected with AP j on the upper layer per period of time is denoted by Œ∏Ni +1 and œÜjN,i+1, respectively. The computing data volume is

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: HetMEC: LATENCY-OPTIMAL TASK ASSIGNMENT AND RESOURCE ALLOCATION FOR HetMEC

4945

limited by its computing capacity.

biN+1siN+1 ‚â§ Œ∏Ni +1,

(2)

and the maximum computing capacity that ED i can offer is denoted by Œ∏Ni,u+1, and thus,

Œ∏Ni +1 ‚â§ Œ∏Ni,u+1.

(3)

The transmitting data volume is restricted by the wireless transmitting capacity of ED i, which is closely related with the wireless transmission resources allocated by AP j.

œÅŒªiN+1siN+1 + ŒªiN+1(1 ‚àí siN+1) ‚â§ œÜjN,i+1,

(4)

where œÅŒªiN+1siN+1 is the processing results, and ŒªiN+1(1 ‚àí siN+1) represents the remaining raw data to transmit to AP j. The total transmitting data volume of all EDs connected

with AP j is linearly constrained by the wireless transmission resources of node j on the N -th layer, denoted by œÜjN , which can be expressed by



œÜjN,i+1 ‚â§ œÜjN .

(5)

i‚ààQjN

Remark 1: The constraints in (5) can describe such wireless resources which inÔ¨Çuence the wireless data rate in a linear manner, e.g., the spectrum and time resources. The power and the antenna resources cannot be modeled in the similar way [31], which are left for the future works.

B. Mobile Edge Computing (MEC) Server
The MEC servers share the computing pressure of the EDs. Being the bottom layer of the MEC servers, the APs connect with EDs via wireless links and enable the EDs to access the wired networks. Other MEC servers, e.g., the switches and network gateways, receive the raw data and the processing results from APs. After processing part of the receiving raw data, the MEC server forwards the rest raw data together with the processing results to its parent node (upper-layer MEC server or CC).
When multiple MEC servers connect to the same upperlayer MEC server or belong to the same switch or bridge, the upper-layer MEC server can coordinate the connected MEC servers and allocate the transmission resources in a centralized way. Then transmission resources, e.g., the bandwidth or time, can be divided linearly to the multiple nodes [33].
As shown in Fig. 2, we consider the node j on the layer n, 1 ‚â§ n ‚â§ N , which is connected with the node k (MEC server or CC) on the layer n ‚àí 1.
The raw data arrival speed from its child node i on the (n + 1)-th layer can be expressed by

Œªjn,i

=

œÜjn,+i 1

¬∑

(1

‚àí

(1 ‚àí sin+1)Œªin+1 sin+1 + œÅsin+1)Œªin+1

+

Œ≤ni +1 ,

(6)

where œÜjn,+i 1 is the total data arrival speed to node j from node i on the lower layer, and only part of it is the raw data
arrival speed. The raw data volume transmitted to node j from its child node i is Œªin+1(1 ‚àí sin+1), and the processed data volume is Œªin+1œÅsin+1 + Œ≤ni +1, where sin+1 is the equivalent

Fig. 2. The data processing and transmitting between two adjacent MEC layers of the HetMEC network.

task division percentage10 of node i and Œ≤ni +1 represents the volume of the processed data under the (n + 1)-th layer. Since

the required number of CPU cycles are proportional to the

amount of raw data for the same kind of tasks, the required

number of CPU cycles of node j on layer n for processing

the data from its child node i is expressed by bjn,i = ŒºŒªjn,i. Hence, the equivalent raw data arrival speed at node j on the

n-th layer is denoted by



Œªjn =

Œªjn,i.

(7)

i‚ààQjn

The required number of CPU cycles of node j on the n-th
layer is denoted by bjn = ŒºŒªjn. Accordingly, the total volume of the processed data received by node j on the n-th layer can

be expressed by

Œ≤nj =  Nj Œ≤ni +1 + œÅ ¬∑ sin+1Œªin+1 .

(8)

i=1

Let sjn,i denotes the task division percentage of node j for the data delivered from node i on the (n + 1)-th layer, which
satisÔ¨Åes that

0 ‚â§ sjn,i ‚â§ 1, i ‚àà Qjn.

(9)

The computing capacity of node j is denoted by Œ∏nj . The total CPU cycles required per second at node j, denoted

by Cnj , is limited by its computing capacity, which can be

expressed by



Cnj =

sjn,ibjn,i ‚â§ Œ∏nj .

(10)

i‚ààQjn

Constrained by the limited computing resources, the maximum
computing capacity that node j on the n layer can offer is denoted by Œ∏nj,u, and thus,

Œ∏nj ‚â§ Œ∏nj,u.

(11)

Let œÜkn,j denote the wired transmitting capacity of node j to node k. The transmitting data volume of node j is limited by

10When the node i is not at the bottom layer, i.e., it is not an ED, it may receives raw data from multiple links. sin+1 is the percentage of the total raw data volume to be processed at node i in its total received raw data volume.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

4946

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019

its wired transmitting capacity, which is closely related with the wired transmission resources allocated by its parent node k on the upper layer.

œÅŒªjnsjn + Œªjn(1 ‚àí sjn) + Œ≤nj ‚â§ œÜkn,j .

(12)

The data to be transmitted to node k on the upper layer

includes three parts. œÅŒªjnsjn is the processed data of node j, and Œªjn(1 ‚àí sjn) is the remaining raw data to transmit, and Œ≤nj is the processed data delivered from the lower layer. All the

three parts need to be transmitted to the upper layer, which
is limited by the allocated wired transmitting capacity œÜkn,j of node j. Moreover, the total transmitting data volume of all

nodes on the n layer connected with the node k is limited

by the wired transmission resources of the node k, denoted

by œÜkn‚àí1, which can be expressed by



œÜkn,j ‚â§ œÜkn‚àí1.

(13)

j‚ààQkn‚àí1

C. Cloud Center

The CC collects the data from the MEC servers via wired links. All raw data delivered to the CC is processed and the whole results are forwarded to the user who generates the task. For convenience, we refer to the CC as layer 0.
The equivalent raw data arrival speed at the CC can be calculated by

Œª10

=

 M01  œÜ11,i
i=1

¬∑

(1

‚àí

(1 ‚àí si1)Œªi1 si1 + œÅsi1)Œªi1

+

 Œ≤1i ,

(14)

and the required number of CPU cycles of the CC is represented by b10 = ŒºŒª10. The arriving data at the CC includes three part: the remaining raw data, the processing results
of the MEC servers and the processing results of the EDs.
The raw data arrival speed is proportional to the remaining
raw data volume percentage in the arriving data. Moreover, the computing capacity of the CC is denoted by Œ∏01, and the maximum computing capacity the CC can offer is denoted by Œ∏01,u.
During the processing and transmitting from the EDs to the
CC, the task assignment strategy s, the computing capacity of each MEC server j on the n-th layer Œ∏nj , the computing capacity of the CC Œ∏01, the wireless transmission resources allocation œÜjN,i+1 and the wired transmission resources allocation of the n-th layer, œÜkn,j , need to be optimized, which will be discussed in Section III.

III. PROBLEM FORMULATION
In this section, we Ô¨Årst analyze the system constraints of the considered HetMEC network, and then formulate the system latency minimization problem given these constraints.

A. System Constraints
We Ô¨Årst describe when and why a HetMEC network can be out of function due to the trafÔ¨Åc congestion. The total computing capacity of each node, the total wireless transmission resources of each AP, and the total wired transmission

Fig. 3. An illustration of the congestion.
resources of each MEC server or the CC in our framework are Ô¨Ånite, however, the data generation speed is Ô¨Çuctuant and timevarying. As shown in Fig. 3, when the data generation speed of the EDs exceeds a certain bound, the HetMEC network cannot follow up the data generation speed due to lack of available computing or transmission resources, and thus, the data will accumulate in the buffer.11 As the raw data keep accumulating, the waiting time in the buffer increase, eventually leading to a congested network.
We then derive the system constraints of the HetMEC network under which the above congestion does not happen. SpeciÔ¨Åcally, the data accumulation does not appear on each layer of the HetMEC network. In the N -layer HetMEC network, i.e., the HetMEC network with N layers of MEC servers, the execution of tasks is related to the computing of the EDs, N layers of MEC servers and the CC, as well as the transmitting of the EDs and N layers of MEC servers.
1) Constraints of the n-th Layer: We consider the n-th layer,12 1 ‚â§ n ‚â§ N + 1. After receiving the raw data and the results, the nodes on the n-th layer need to process a part of the raw data, and transmit the rest raw data together with the processing results to the upper layer. It is worth noting that the transmission resource allocated to each node on the n-th layer is determined by its parent node on the (n ‚àí 1)-th layer. We consider the case that all nodes on the n-th layer fully use their computing capacity, which is the case when the equality holds in the following constraint.
binsin ‚â§ Œ∏ni ‚â§ Œ∏ni,u, ‚àÄ1 ‚â§ i ‚â§ Mn, 1 ‚â§ n ‚â§ N + 1, (15)
which implies that the transmission pressure of the n layer is minimum. Under the aforementioned circumstance, for each parent node j on the (n ‚àí 1)-th layer, the total volume of the data to transmit from the n-th layer to the parent node j cannot surpasses the total transmission capacity of the parent node j. Hence, when n = N + 1 (the EDs), the constraints for transmitting are described in (4) and (5). When 1 ‚â§ n ‚â§ N (the MEC servers), the constraints for transmitting are described in (12) and (13).
11The space of the buffer in each node is viewed as inÔ¨Ånite, that is, the data only accumulates in the buffer and no data loss happens when facing the congestion.
12This layer may consist of the EDs or MEC servers. The constraints of them are similar.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: HetMEC: LATENCY-OPTIMAL TASK ASSIGNMENT AND RESOURCE ALLOCATION FOR HetMEC

4947

2) Constraints of the CC: The CC needs to process all the remaining raw data delivered from the lower layer, and does not need to transmit. The volume of the arrived raw data at the CC per second should not surpass its computing capacity. Hence, the constraint of the CC is expressed by

b10 ‚â§ Œ∏01.

(16)

Summarizing the constraints for all the layers of the HetMEC network, we have Proposition 1 to clarity the system constraints.
Proposition 1: The system constraints of the HetMEC network can be described by the constraints of each layer in the HetMEC network, i.e., the constraints that (1), (4), (5), (9), (12), (13), (15) and (16) are all satisÔ¨Åed.

B. Latency Minimization Problem Formulation

We aim to minimize the system latency of the HetMEC

network, which is a general objective in the MEC

networks [8], [15], [16], [26]. We Ô¨Årst deÔ¨Åne the system

latency in the HetMEC network and formulate the latency

minimization problem in this subsection.

The latency of a task is deÔ¨Åned as the total computing

time and transmitting time from the ED to the CC. Consider the n-th layer where nodes receive the tasks from the lower

layer. The nodes need to process the assigned raw data from

the lower layer, and deliver the processing results as well

as unprocessed data to the upper layer. Therefore, the total latency of all nodes on the n-th layer can be expressed by

Ln

=

 Mn‚àí1   sinbin

j=1 i‚ààQjn‚àí1

Œ∏ni

+

œÅsinŒªin

+ (1 ‚àí sin)Œªin œÜjn,i

+ Œ≤ni  ,

(17)

where sinbin/Œ∏ni represents the processing time for the ofÔ¨Çoaded raw data, and [œÅsinŒªin + (1 ‚àí sin)Œªin + Œ≤ni ]/œÜjn,i implies the transmitting time of the node i on the n-th layer.
We then deÔ¨Åne the system latency as below. DeÔ¨Ånition 1: From the perspective of data processing, the system latency is the total computing and transmission
time of the EDs, all layers of MEC servers and the CC. Therefore, the system latency can be expressed as

L

=

b10 Œ∏01

N+1 + Ln,
n=1

(18)

where b10/Œ∏01 represents the computing time of the CC. Hence, the total latency minimization problem in the

HetMEC network can be formulated as below.

min L, (1), (4), (5), (9), (12), (13), (15), (16). (19)
s,Œ∏,œÜ

IV. LATENCY MINIMIZATION ALGORITHM DESIGN
In this section, we propose a latency minimization algorithm (LMA) to solve problem (19) via joint task assignment, computing and transmission resource allocation. We then analyze the inÔ¨Çuence of the number of MEC layers on the network robustness.

A. Algorithm Design
The system latency minimization problem described in (19) is nonconvex, in which the task assignment strategy s, computing capacity allocation Œ∏ and transmission resources allocation œÜ are coupled. By utilizing the Cauchy-Schwarz inequality [34], we can obtain the following inequations.

L(s, Œ∏, œÜ)

= √óŒ∏b1001+sinŒ∏Nn nib=in+11+M‚é° j=œÅn‚àís1in1iŒª‚àà inQjn+‚àí1(1œÜ‚àíjn,isin)Œªin + Œ≤ni 

‚é§

‚â•

Lmin

(s)

=

‚é¢‚é£

b10 Œ∏01,u

N+1  Mn‚àí1  +
n=1 j=1 i‚ààQjn‚àí1

sinbin Œ∏ni,u

‚é•‚é¶





2

N+1  Mn‚àí1 +
n=1 j=1

i‚ààQjn‚àí1

œÅsinŒªin + (1 ‚àí sin)Œªin + Œ≤ni œÜjn‚àí1

,

(20)

where Œ∏ni,u and œÜjn‚àí1 are the boundary of the computing and transmitting capacity.

Proposition 2: The task assignment strategy and resource

allocation optimization can be separated in the proportional

optimization problem (19) by utilizing the Cauchy-Schwarz

inequality.

Proof: See Appendix A.

Proposition 3: The optimal computing capacity division

and transmission resources allocation can be derived by the

following relations.



œÜjn,i œÜjn,i

=

 œÅsinŒªin + (1 ‚àí sin)Œªin œÅsin Œªin + (1 ‚àí sin )Œªin

+ Œ≤ni , + Œ≤ni

Œ∏01 = Œ∏01,u, Œ∏ni = Œ∏ni,u,

‚àÄ1 ‚â§ n ‚â§ N +1, 1 ‚â§ j ‚â§ Mn, i, i ‚àà Qjn‚àí1. (21)

Proof: According to (20), the system latency L(s, Œ∏, œÜ)

achieves a minimum Lmin(s) when the equality holds. Based on the Cauchy-Schwarz inequality [34], the equality holds

if and only if the equations in (21) are satisÔ¨Åed, implying

that the computing capacity division Œ∏ and transmission

resources allocation œÜ can be derived from the task assignment

percentage s.

Proposition 4: The objective function Lmin(s) in the task assignment problem (22) is concave, and the optimal results s‚àó

are at the vertex of the feasible set bounded by the constraints.

min
s

Lmin(s),

s.t. (1), (4), (5), (9), (12), (13), (15), (16), (21). (22)

Proof: See Appendix B

According to the aforementioned propositions, we can

obtain the optimal results of the latency minimization problem

by searching all the vertices of the feasible set bounded by the

constraints. The latency minimization algorithm is summarized

in Algorithm 1.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

4948

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019

Algorithm 1 Latency Minimization Algorithm

Input: Computing capacity Œ∏ni , upper bound of the transmission resource of each node œÜin,0, data generation speed Œª.
Output: Task assignment strategy s‚àó, resources allocation scheme Œ∏‚àó, œÜ‚àó.

1: for all Vertex of the feasible set do

2: Obtain the corresponding task assignment strategy s.

3: Obtain the resource allocation scheme Œ∏, œÜ according to

s and (21) in Proposition 3.

4: if Lmin(s) < Lmin(s‚àó) then

5:

Lmin(s‚àó) = Lmin(s).

6:

Update the optimal s‚àó, Œ∏‚àó and œÜ‚àó with s‚àó = s, Œ∏‚àó =

Œ∏, œÜ‚àó = œÜ.

The network robustness is reÔ¨Çected by the network processing capacity, which is deÔ¨Åned by the maximum data generation speed at the ED supported by the non-congested HetMEC networks. The ED can start processing the new arrival task once it Ô¨Ånishes processing its own part of the previous task, without waiting it to be processed completely and transmitted to the CC. Intuitively, a network is more robust when more resources are available brought by a newly added layer. However, this may only be true when the added layer is selected properly, as will be analyzed in both computing and transmission resource shortage cases as below.
1) Computing Resource Shortage Case: As shown in Fig. 4, the bottleneck of the network processing capacity lies in the limited computing resources, which can be expressed by

We Ô¨Årst convert the proportional optimization problem in (19) into the task assignment problem in (20) given Proposition 3 by utilizing Cauchy-Schwarz inequality. Since the converted task assignment problem is proved concave according to Proposition 4, we calculate the system latency at each vertex of the feasible set bounded by the non-congested constraints, i.e., Lmin(s), where s is determined by the constraints associated with the discussing vertex. The computing and transmission resource allocation are also determined once the task assignment strategy s is Ô¨Åxed. After considering all the vertices, the minimum system latency together with the optimal task assignment strategy and resource allocation can be obtained.
Remark 2: Assuming the number of devices in the whole network is denoted by M , the complexity of the latency minimization algorithm is proportional to the number of the vertices of the feasible set. The maximum number of the vertices of the feasible set is in the square magnitude of the number of system constraints, i.e., O(M 2).
Proof: See Appendix C. We then elaborate on the implementation of our approaches in practice. To perform the LMA in the HetMEC network, the EDs and MEC servers need to register to the CC and upload the node information (i.e., the location, the amount of computing and transmission resource, the data generation speed). Based on the registration information, the CC then establish the logical graph of the HetMEC network. After the CC obtains the optimal task assignment and resource allocation scheme by performing our LMA algorithm, the CC needs to broadcast the scheme to all devices corresponding to the task. For the HetMEC network with more layers of MEC servers, the overhead of the registration and scheme broadcasting is larger, which is proportional to the number of devices. The network robustness is improved at the expense of the overhead for communication.
B. Network Robustness Analysis
In this subsection, we discuss the relation between the network robustness and the number of MEC layers of the HetMEC network, inÔ¨Çuenced by the amount of computing and transmission resources.

bin sin

=

Œ∏ni,u , œÅŒªjn

‚àÄ1 sjn +

‚â§ n ‚â§ N, 1 Œªjn(1 ‚àí sjn)

‚â§i‚â§ + Œ≤nj 

Mn, < œÜkn‚àí1,

(23)

j‚ààQkn‚àí1

‚àÄ2 ‚â§ n ‚â§ N, 1 ‚â§ k ‚â§ Mn‚àí1.

(24)

In this case, the computing resources of all layers are fully utilized, while there still remains the idle transmission resources in the HetMEC network. The network will be in congestion if the data generation speed Œª continues to increase.
When adding a layer of MEC servers between the (n0 ‚àí 1)-th and n0-th layer of the initial network,13 in order to increase the network robustness, the computing and transmission resources of the new added layer should satisfy that

Œ∏ni ,0u >0, ‚àÄ1 ‚â§ i ‚â§ Mn0 ,

(25) 

œÅŒªjn0+1sjn0+1 + Œªjn0+1(1 ‚àí sjn0+1)+Œ≤nj 0+1 < œÜin0 ,

j‚ààQin0

‚àÄ1 ‚â§ i ‚â§ Mn0 ,

(26)

where each node on the added layer possesses the computing
resources, and the transmission resources of each node on the
added layer are sufÔ¨Åcient enough to transmit all the data from the lower layer (i.e., (n0 + 1)-th layer in the (N + 1)-layer network). Therefore, the added layer can relieve the processing
pressure of the other layers. As the data generation speed Œª continues to increase, the task division percentage sin, 1 ‚â§ i ‚â§ Mn, on any other layer, n = n0, can be reduced, and the task division percentage sin0, 1 ‚â§ i ‚â§ Mn0 , increases until the following conditions are satisÔ¨Åed.

bin0 sin0 Œ∏ni 0

=

bjnsjn Œ∏nj

,

‚àÄn = n0, 1 ‚â§ i ‚â§ Mn0 , 1 ‚â§ j ‚â§ Mn, (27)



Œªin0 sin0 ‚â§ Œ∏ni,0u, ‚àÄ1 ‚â§ i ‚â§ Mn0 , œÅŒªjnsjn + Œªjn(1 ‚àí sjn) + Œ≤nj  < œÜkn‚àí1,

j‚ààQkn‚àí1

(28)

‚àÄ2 ‚â§ n ‚â§ N + 1, 1 ‚â§ k ‚â§ Mn‚àí1.

(29)

13The added layer becomes the n0-th layer, and the initial n0-th layer becomes the (n0 + 1)-th layer.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: HetMEC: LATENCY-OPTIMAL TASK ASSIGNMENT AND RESOURCE ALLOCATION FOR HetMEC

4949

Fig. 4. The computing resource shortage case.

Fig. 5. The transmission resource shortage case.

The computing resources of the whole HetMEC network are then fully utilized where the processing time on all layers are equal and limited by the non-congested computing constraint.
2) Transmission Resource Shortage Case: As shown in Fig. 5, the bottleneck of the network processing capacity lies in the transmission resources of one layer n0, and the layer is determined by the conditions described in (4), (5), (12) and (13). The transmission resources of the n0-th layer have been fully utilized for the data transmission from the (n0 + 1)-th layer to the n0-th layer, which can be expressed by

binsin < Œ∏ni,u, ‚àÄ0 ‚â§ n ‚â§ N + 1, 1 ‚â§ i ‚â§ Mn,

(30)





œÅŒªjn0+1sjn0+1 +Œªjn0+1(1‚àísjn0+1)+Œ≤nj 0+1 = œÜkn0 ,

j‚ààQkn0

‚àÄ1 ‚â§ k ‚â§ Mn0+1.

(31)

The network will be congested between the (n0 + 1)-th layer and the n0-th layer if the data generation speed Œª continues to increase.
The robustness can be enhanced only when adding a layer of MEC servers between the (n0+1)-th layer and the n0-th layer, or below the (n0 + 1)-th layer. It does not make any contribution to the robustness enhancement to add a layer when the layer number is smaller than n0 (i.e., the added layer is above the n0-th layer). This is because the transmission resources are allocated by the parent node on the upper adjacent layer,
and the operation of adding a layer of MEC servers above the n0-th layer cannot increase the transmission resources of the n0-th layer or reduce the amount of data transmitted from the (n0 + 1)-th layer.
When adding a layer of MEC servers below the initial n0-th layer, denoted by the n-th layer,14 in order to
14The added layer becomes the n-th layer, and the initial n-th layer becomes the (n + 1)-th layer, and n > n0.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

4950

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019

increase the network robustness, the computing and transmission resources of the added layer should satisfy that

TABLE II HETMEC NETWORK PARAMETERS

Œ∏ ni,u >0, ‚àÄ1 ‚â§ i ‚â§ Mn ,

 (32)

œÅŒªjn+1sjn+1 + Œªjn+1(1 ‚àí sjn+1) + Œ≤nj +1 < œÜin ,

j‚ààQin

‚àÄ1 ‚â§ i ‚â§ Mn ,

(33)

where each node on the added layer possesses the computing

resources, and the transmission resources are sufÔ¨Åcient enough

to transmit all the data from the lower layer.

Tasks with a larger data generation speed can be processed

since condition (31) has changed to the condition that the

amount of the transmitted data from the (n0 + 1)-th layer

is strictly smaller than the transmission resources. Therefore,

the network can remain non-congested when the data genera-

tion speed Œª continues to increase. Condition (31) changes in

two cases:

‚Ä¢ If a layer is added between the (n0 + 1)-th layer and
the n0-th layer, condition (31) changes because the transmission resources are more abundant.15 Therefore,

the amount of data to be transmitted from the (n0 + 1)-th

layer satisÔ¨Åes that





œÅŒªjn0+1sjn0+1+Œªjn0+1(1‚àísjn0+1)+Œ≤nj 0+1 < œÜkn0+1.

j‚ààQkn0

‚Ä¢ If a layer is added below the (n0 + 1)-th layer, condition

(31) changes because the amount of data to transmit

is reduced.16 We assume that Œª0 volume of data that

originally being processed on the (n0 + 1)-th layer are

ofÔ¨Çoaded to the added layer. The amount of data to be

transmitted from the (n0 + 1)-th layer is reduced and

satisÔ¨Åes that





œÅŒªjn0+1sjn0+1 + Œªjn0+1(1 ‚àí sjn0+1) + Œ≤nj 0+1

j‚ààQkn0





‚àí

(1 ‚àí œÅ)(1 ‚àí sjn0+1)Œª0 < œÜkn0+1.

j‚ààQkn0

We summarize the relation between the network robustness and the number of MEC layers inÔ¨Çuenced by the amount of computing and transmission resources. In the computing resource shortage case, the network robustness can be enhanced if the MEC servers which can provide the computing capacity on the new added layer satisÔ¨Åes (25) and (26). In the transmission resource shortage case, the network robustness can be enhanced only if a layer of MEC servers satisfying (32) and (33) are added below the initial transmission resource constrained MEC layer. When additional layers of MEC servers are added, to support a larger data generation speed at the EDs, the locations of these MEC servers need to be determined according to the current resource states of the network. Moreover, the trade-off between the latency and cost needs to be considered. Furthermore, due to the changed topology of considered devices, the task assignment, computing and

15This is to say, the right side of (31) becomes larger. 16This is to say, the left side of (31) becomes smaller.

transmission resource allocation among different layers need to be updated according to our proposed algorithm LMA.
We then evaluate the incurred overhead of considering more MEC layers. Assume that the amount of information that each device reports to the CC (e.g., the location, the amount of computing and transmission resources, the data generation speed) is a1, and the amount of CC broadcast information (task assignment and resource allocation scheme) is a2. Adding a layer of MEC servers implies that this MEC layer is considered in the data processing, and the physical connections of the CC-MEC network remains the same.
When Mn MEC servers are added on layer n, they need to register the node information to the CC through (n ‚àí 1) layers of MEC servers. Since the registration information are delivered to the CC layer by layer, the added overhead during the node registration is O1 = a1 ¬∑ Mn ¬∑ n. After performing the LMA at the CC, the CC need to broadcast the adjusted task assignment and resource allocation scheme to the other devices. The added overhead during the CC broadcasting is O1 = a2 ¬∑ Mn. Therefore, the incurred overhead of adding Mn MEC servers on layer n is expressed by
O(n, Mn) = O1 + O2 = (a1 ¬∑ n + a2) ¬∑ Mn.
The network robustness is improved at the expense of the signaling overhead. The trade-off between the robustness and overhead will be discussed for future works. In our paper, we focus on deriving the exact conditions of improving the network robustness by adding more layers of MEC servers.
V. SIMULATION RESULTS
In this section, we evaluate the system latency and the processing rate in the HetMEC network performing our algorithm LMA and other task assignment schemes. The robustness in the HetMEC network with different number of layers is also investigated.
A. Parameters Setting In our simulation, the parameters about the data processing
are presented in Table II. The EDs transmit the Ô¨Åle of size 60 Kbits in a period of 1s. We assume that one CPU cycle is required to process each bit of raw data, i.e., Œº = 1 cycles/bit. The compression ratio of the raw data after processing is set as 10%. The computing capacity is represented by the maximum CPU cycles per second, and the transmission resources are reÔ¨Çected by the transmission bandwidth. We consider four cases in our simulation, i.e., the cloud-only network, 1-layer, 2-layer and 3-layer HetMEC networks, as shown in Table III. In different cases, the network topology is Ô¨Åxed yet we consider the task assignment among different number of MEC

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: HetMEC: LATENCY-OPTIMAL TASK ASSIGNMENT AND RESOURCE ALLOCATION FOR HetMEC
TABLE III NETWORK ARCHITECTURE OF THE HETMEC NETWORK WITH DIFFERENT NUMBER OF MEC LAYERS

4951

TABLE IV COMPUTING CAPACITY AND TRANSMISSION RESOURCE SETTING OF THE HETMEC NETWORK

layers. The computing capacity and transmission resource settings of the three cases are presented in Table IV. In all cases, the data generated at the EDs need to be aggregated at the CC through multiple layers of MEC servers, while the task assignment strategy can be performed among the EDs, all considered MEC layers and the CC.
B. Network Performance Evaluation
The network performance is evaluated based on the following metrics:
‚Ä¢ System Latency: The total latency of all tasks generated at the EDs per second.
‚Ä¢ Processing Rate: The average volume of data processed by the HetMEC network per second viewed by each ED.
‚Ä¢ Network Robustness: The network robustness is represented by the maximum data generation speed supported by the non-congested HetMEC network.
We compare the LMA with the following task assignment schemes on these metrics.
‚Ä¢ Cloud computing: The cloud computing scheme indicates that all the data are processed at the CC.
‚Ä¢ Local computing: The local computing scheme indicates that all the data are processed at the ED without being ofÔ¨Çoaded to the MEC servers or CC.
‚Ä¢ Conventional MEC: The conventional MEC scheme indicates that the data are totally ofÔ¨Çoaded to the APs for processing, yet the CC, EDs and upper layer MEC servers do not provide the computing services.
‚Ä¢ JCORA Algorithm [29]: The computation ofÔ¨Çoading between the APs as well as the EDs and the resource allocation scheme are adjusted iteratively in the joint computation ofÔ¨Çoading and resource allocation (JCORA) algorithm.
1) System Latency Evaluation: Fig. 6 presents the system latency versus the data generation speed Œª at the ED in different cases. In the one-layer HetMEC network, as shown in

Fig. 6(a), the system latency of all schemes increases with the data generation speed, since more data need to be processed, resulting in larger system latency. By performing our proposed algorithm LMA, the system latency remains the lowest given different data generation speed. When the data generation speed Œª > 6, the slop of the line segment of LMA becomes larger, reÔ¨Çecting that the average latency increases. When the data generation speed is small, the latency is smallest when the data are processed at the uppermost layer. When the data generation speed is large, the data need to be ofÔ¨Çoaded to other layers due to the limited computing capacity of the uppermost layer, which induces the increase of the average latency.
In the two-layer HetMEC network, as shown in Fig. 6(b), the system latency of the LMA also remains the lowest in different cases given different data generation speeds, which reÔ¨Çects the advantages of the LMA in the HetMEC network. Compared with other schemes, the LMA jointly utilizes the computing capacity and transmission resources of all devices, and thus, its latency remains low with the data generation speed increasing. At the data generation speed Œª = 11, the new generated data can be processed in real time when performing our algorithm LMA, showing the robustness of our scheme. Given the same data generation speed, the system latency of the two-layer HetMEC network performing the LMA is not larger than that of the one-layer HetMEC network, and the robustness of the two-layer HetMEC network performing the LMA is stronger than that of the one-layer HetMEC network.
2) Processing Rate Evaluation: As shown in Fig. 7, we analyze the processing rate given different data generation speed in both cases. As presented in Fig. 7(a) and (b), both in the one-layer HetMEC network and two-layer HetMEC network, the processing rate of different schemes is nondecreasing as the data generation speed increases. Other schemes, e.g., JCORA algorithm, conventional MEC scheme, the cloud and local computing, reach the saturated point when

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

4952

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019

Fig. 6. The system latency vs. the data generation speed in the different Fig. 7. The processing rate with the increase of the data generation speed

cases.

in the HetMEC network.

the data generation speed surpasses the respective thresholds, reÔ¨Çecting the bottlenecks of the network processing rate utilizing these schemes. After reaching the bottleneck, the network cannot offer more computing resources for the new generated data, and the processing rate stops increasing. The LMA gains relatively high processing rate, especially when the data generation speed is large. Since the LMA jointly utilizes the computing and transmission resources of the whole HetMEC network, it achieves the highest bottleneck of the processing rate.
Fig. 8 compares the processing rate in the one-layer and two-layer HetMEC networks by performing LMA. When the HetMEC network is congested, no more resources can be utilized for data processing, and thus, the processing rate reaches saturation and stop grows with the data generation speed. Compared with the one-layer HetMEC network, the processing rate of the two-layer HetMEC network is higher given the same data generation speed, especially when the data generation speed is large. The computing and transmission resources are enriched in the two-layer HetMEC network. By jointly utilizing the computing resources of different layers

Fig. 8. The processing rate vs. the data generation speed in the HetMEC network with different number of layers.
and properly scheduling the data transmission among layers in the HetMEC network, more computing resources contributes to higher processing rate as the number of layers grows.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: HetMEC: LATENCY-OPTIMAL TASK ASSIGNMENT AND RESOURCE ALLOCATION FOR HetMEC
TABLE V COMPUTING CAPACITY AND TRANSMISSION RESOURCE SETTING IN DIFFERENT CASES

4953

Fig. 9. The network robustness with different number of MEC layers in the HetMEC network.

In case 2, as the number of MEC layers grows, the network robustness becomes stronger when the number of MEC layers N ‚â§ 2, and then remains the same when N ‚â• 2. Since the transmission resources between the APs and the EDs become more abundant, the HetMEC network can process the tasks with larger data generation speed, and thus, the robustness is enhanced in the two-layer HetMEC network. However, the transmission resources between the APs and the EDs still constrain the enhancement of the robustness, and the robustness remains unchanged when N ‚â• 2. The network robustness is improved only when the computing and transmission resources of the added layer satisfy the conditions analyzed in Section IV.
In case 3, the network robustness becomes stronger as the number of MEC layers grows. The transmission resources of all MEC layers are abundant, and the computing resources constrain the improvement of the robustness. As analyzed in Section IV, in the computing resource shortage case, it can improve the network robustness to induce new layers of MEC servers satisfying (25) and (26).

3) Network Robustness Evaluation: Fig. 9 shows the maximum data generation speed of the HetMEC network in the cloud-only network, one-layer, two-layer and three-layer HetMEC networks in different cases, the settings of which are presented in Table V. The maximum data generation speed of the non-congested HetMEC network reÔ¨Çects the robustness of the network, as analyzed in Section IV. Case 1 and case 2 show the performance of robustness in the transmission resource shortage case of the HetMEC network, and case 3 shows the performance of robustness in the computing resource shortage case of the HetMEC network.
In case 1, as the number of the MEC layers increases, the network robustness Ô¨Årst becomes stronger when the number of MEC layers N ‚â§ 1, and then remains the same when N ‚â• 1. When N ‚â§ 1, the main constraint of the robustness is the computing resources in the whole network. Therefore, the robustness of the HetMEC network become stronger when inducing more layers of MEC servers into the task assignment and processing. When N ‚â• 1, it is the transmission resources between the APs and EDs that constrains the network robustness. As analyzed in Section IV, it cannot contribute to the robustness enhancement to add a layer of MEC servers above the APs, and thus, the network robustness does not increase anymore.

VI. CONCLUSION
In this paper, we have studied a HetMEC network in order to provide low-latency data services. We have considered a typical uplink MEC application, where the raw data are generated at the EDs and the results of the data processing need to be aggregated at the CC through multiple layers of MEC servers. The tasks are optimally divided and assigned to the nodes on multiple layers, including the CC, MEC servers and EDs. Through jointly considering the task assignment, computing and transmission resource allocation, we have proposed the LMA for latency minimization in the HetMEC network. Simulation results have showed that our proposed algorithm LMA can signiÔ¨Åcantly reduce the system latency and increase the processing rate as well as the network robustness. Based on both theoretical and numerical analysis, we conclude that the relation between the network robustness and the number of layers of the HetMEC network is inÔ¨Çuenced by the amount of the computing and transmission resources. In the computing resource shortage case, the robustness can be improved when inducing the MEC servers above any layer. In contract, in the transmission resource shortage case, it cannot contribute to the enhancement of the robustness when inducing more layers of MEC servers above the initial transmission resource constrained layer.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

4954

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019

APPENDIX A PROOF OF PROPOSITION 2

In the proportional optimization problem (19), the task assignment strategy s, computing capacity allocation Œ∏ and transmission resources allocation œÜ are coupled, expressed as

L(s, Œ∏, œÜ)

=

Œª10 Œ∏01

+

N+1  Mn‚àí1   sinŒªin

n=1 j=1 i‚ààQjn‚àí1

Œ∏ni

+

œÅsinŒªin

+ (1 ‚àí sin)Œªin œÜjn,i

+ Œ≤ni 

(34)

However, it is worth noting that the transmission resources of each node that allocated to its child nodes are limited, as described in (13), and the upperbound of the computing capacity of each node is Ô¨Åxed. We consider that no spare computing capacity or transmission resource is left, i.e., equality occurs for (2) and (10). Hence, by utilizing the Cauchy-Schwarz inequality [34], we can obtain the following inequation.

L(s, Œ∏, œÜ)

‚â• ‚é°Lmin(s)

‚é§

=

‚é¢‚é£

Œª10 Œ∏01,u

+

N+1M n‚àí1  sinŒªin

n=1

Œ∏i,u
j=1 i‚ààQjn‚àí1 n

‚é•‚é¶





2

N+1M n‚àí1 +
n=1 j=1

i‚ààQjn‚àí1

œÅsinŒªin +(1‚àísin)Œªin +Œ≤ni œÜjn‚àí1

,

(35)

where Œ∏ni,u and œÜjn‚àí1 are the boundary of the computing and transmitting capacity. The proportional optimization problem (19) is converted into a pure task assignment problem.
Once the equation conditions of the Cauchy-Schwarz
inequality are satisÔ¨Åed, the task assignment problem is completely equivalent to the latency minimization problem min L(s, Œ∏, œÜ). Therefore, we can obtain the optimal solution of min L(s, Œ∏, œÜ) by solving min Lmin(s).

APPENDIX B PROOF OF THE PROPOSITION 4

We analyze the network with one parent node and M child

nodes. Let si and Œªi denotes the task assignment percentage and raw data arriving rate at child node i. The maximum

computing capacity of child node i is denoted by Œ∏iu, and the computing capacity of the parent node is denoted by Œ∏u.

The total transmission resource of the parent node is expressed

by œÜ.

The latency Lmin can be expressed by

Lmin

=

 M
i=1

siŒªi Œ∏iu

+

M
i=1

(1

‚àí

si)Œªi

Œ∏u

M
i=1

 (1

‚àí

si)Œªi

+

2 œÅsiŒªi

+

œÜ

.

The Hessian matrix of the system latency with M child nodes

can be expressed by

‚é°

h1,1

HM

=

‚é¢‚é¢‚é£

h2,1 ...

‚é§

h1,2 . . . h1,M

h2,2 ...

...

h2,M ...

‚é•‚é•‚é¶

‚é°h‚àÇM 2 L,1minhM,‚àÇ22

...
Lmin

=

‚é¢‚é¢‚é¢‚é£

‚àÇ ‚àÇ2
‚àÇ

s1 s1 Lmin
s2 s1
...

‚àÇ ‚àÇ2

s1 s2 Lmin

‚àÇs2 s2

...

‚àÇ2 Lmin ‚àÇsM s1

‚àÇ2 Lmin ‚àÇsM s2

hM,M ... ...

‚é§ ‚àÇ2 Lmin

‚àÇ‚àÇ2s1Lm sMin ‚àÇs2 sM
...

‚é•‚é•‚é•‚é¶

...

‚àÇ2 Lmin ‚àÇsM sM

We can obtain the second partial derivative as follows

hi,i

=

‚àÇ 2 Lmin ‚àÇs2i

=

‚àíZ

Œª2i

(M j=1 Aj A3i

)

‚àí

Ai

,

(36)

hi,j

=

‚àÇ 2 Lmin ‚àÇsisj

=

Z

ŒªiŒªj

1 AiAj

,

(37)

where

Z

=

(1 ‚àí œÅ)2  2œÜ

‚â•

0,

(38)

Ai = (1 ‚àí si)Œªi + œÅsiŒªi ‚â• 0.

(39)

Considering a normal vector x = [x1 x2 . . . xM ]T , we obtain the following polynomial

 M  M

XM (x) = xT HM x =

hi,j xixj .

(40)

i=1 j=1

We then prove that XM (x) ‚â§ 0 for any natural number M by

mathematical induction.

‚Ä¢ When M = 1: X1(x) = 0 ‚â§ 0

‚Ä¢

When

M

=

2:

X2(x)

=

‚àíZ (A21Œª2‚àíA22Œª2)2
M13 M23

‚â§ 0.

‚Ä¢ We assume that when M = m ‚àí 1, Xm‚àí1(x) =

xT Hm‚àí1x ‚â§ 0.

‚Ä¢ Hence, when M = m, we have

 m  m

Xm(x) = xT Hmx =

hi,j xixj

i=1 j=1

=

Xm‚àí1 ‚àí

Z A3m

m‚àí1 (A2mŒªi ‚àí A2i Œªm)2

i‚àí1

A3i

‚â§ 0.

Since XM (x) ‚â§ 0 for any natural number M , the Hessian matrix HM is a seminegative deÔ¨Ånite matrix, implying that the function Lmin is concave [35].
Moreover, the non-congested constraints are linear based on
the Proposition 1. Hence, the minimum value of a concave
function is obtained at the vertex of the feasible set bounded
by the non-congested constraints.

APPENDIX C PROOF OF REMARK 2

We consider the worst case, that the number of child nodes

connected

with

each

parent

node

is

Q

=

max
0‚â§n‚â§N,1‚â§i‚â§Mn

Qin.

In this case, the number of nodes in the whole network can

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: HetMEC: LATENCY-OPTIMAL TASK ASSIGNMENT AND RESOURCE ALLOCATION FOR HetMEC

4955

be calculated as below.

M

=

N+1 Qn
n=0

=

QN +2 Q‚àí

‚àí 1

1

.

(41)

The complexity of the latency minimization algorithm is proportional to the number of feasible vertices, which is proportional to the square of the number of the constraints and closely related to the complexity of Ô¨Ånding the vertices. The non-congested constraints derive from the computing capacity limitation of each node and the transmission resources limitation of each parent node. The number of the computing capacity constraints equals that of all nodes:

Kc

=

M

=

N+1 Qn

=

QN+2 ‚àí Q‚àí1

1.

(42)

n=0

The number of the transmission resource constraints equals the number of the parent nodes in the whole network, which can be expressed by

Kt

=

 N Qn

=

QN+1 ‚àí Q‚àí1

1.

(43)

n=0

The number of the constraints is

K

=

Kc

+ Kt

=

QN +2

+ QN+1 Q‚àí1

‚àí 2.

(44)

The maximum number of the vertices of the feasible set is

O(K 2 )

=

O(Q2N +4 ) O(Q2)

=

O(M 2).

(45)

REFERENCES
[1] L. Atzori, A. Iera, and G. Morabito, ‚ÄúThe Internet of Things: A survey,‚Äù Comput. Netw., vol. 54, no. 15, pp. 2787‚Äì2805, Oct. 2010.
[2] D. Miorandi, S. Sicari, F. De Pellegrini, and I. Chlamtac, ‚ÄúInternet of Things: Vision, applications and research challenges,‚Äù Ad Hoc Netw., vol. 10, no. 7, pp. 1497‚Äì1516, Sep. 2012.
[3] D. Evans, ‚ÄúThe Internet of Things: How the next evolution of the Internet is changing everything,‚Äù CISCO, San Jose, CA, USA, White Paper, Jan. 2011, vol. 1, pp. 1‚Äì11.
[4] A. Papageorgiou, B. Cheng, and E. Kovacs, ‚ÄúReal-time data reduction at the network edge of Internet-of-Things systems,‚Äù in Proc. CNSM, Barcelona, Spain, Nov. 2015, pp. 284‚Äì291.
[5] M. Armbrust et al., ‚ÄúA view of cloud computing,‚Äù Commun. ACM, vol. 53, no. 4, pp. 50‚Äì58, 2010.
[6] Y. C. Hu, M. Patel, D. Sabella, N. Sprecher, and V. Young, ‚ÄúMobile edge computing‚ÄîA key technology towards 5G,‚Äù ETSI, Sophia Antipolis, France, White Paper 11, Sep. 2015.
[7] P. Wang, B. Di, H. Zhang, K. Bian, and L. Song, ‚ÄúCellular V2X communications in unlicensed spectrum: Harmonious ooexistence with VANET in 5G systems,‚Äù IEEE Trans. Wireless Commun., vol. 17, no. 8, pp. 5212‚Äì5224, Aug. 2018.
[8] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, ‚ÄúA survey on mobile edge computing: The communication perspective,‚Äù IEEE Commun. Surveys Tuts., vol. 19, no. 4, pp. 2322‚Äì2358, 4th Quart., 2017.
[9] H. T. Dinh, C. Lee, D. Niyato, and P. Wang, ‚ÄúA survey of mobile cloud computing: Architecture, applications, and approaches,‚Äù Wireless Commun. Mobile Comput., vol. 13, no. 18, pp. 1587‚Äì1611, Oct. 2011.
[10] M. Satyanarayanan, P. Bahl, R. Caceres, and N. Davies, ‚ÄúThe case for VM-based cloudlets in mobile computing,‚Äù IEEE Pervasive Comput., vol. 8, no. 4, pp. 14‚Äì23, Oct. 2009.

[11] M. Chiang and T. Zhang, ‚ÄúFog and IoT: An overview of research opportunities,‚Äù IEEE Internet Things J., vol. 3, no. 6, pp. 854‚Äì864, Dec. 2016.
[12] W. Shi, J. Cao, Q. Zhang, Y. Li, and L. Xu, ‚ÄúEdge computing: Vision and challenges,‚Äù IEEE Internet Things J., vol. 3, no. 5, pp. 637‚Äì646, Oct. 2016.
[13] S. Wang, X. Zhang, Y. Zhang, L. Wang, J. Yang, and W. Wang, ‚ÄúA survey on mobile edge networks: Convergence of computing, caching and communications,‚Äù IEEE Access, vol. 5, pp. 6757‚Äì6779, 2017.
[14] L. Yang, J. Cao, H. Cheng, and Y. Ji, ‚ÄúMulti-user computation partitioning for latency sensitive mobile cloud applications,‚Äù IEEE Trans. Comput., vol. 64, no. 8, pp. 2253‚Äì2266, Aug. 2015.
[15] X. Chen, L. Jiao, W. Li, and X. Fu, ‚ÄúEfÔ¨Åcient multi-user computation ofÔ¨Çoading for mobile-edge cloud computing,‚Äù IEEE/ACM Trans. Netw., vol. 24, no. 5, pp. 2795‚Äì2808, Oct. 2016.
[16] F. Wang, J. Xu, X. Wang, and S. Cui, ‚ÄúJoint ofÔ¨Çoading and computing optimization in wireless powered mobile-edge computing systems,‚Äù IEEE Trans. Wireless Commun., vol. 17, no. 3, pp. 1784‚Äì1797, Mar. 2018.
[17] Network Architecture, document 3GPP TS 23.002, Jun. 2003. [18] A. S. Tanenbaum and D. Wetherall, Computer Networks. Upper Saddle
River, NJ, USA: Prentice-Hall, 1996. [19] F. Bonomi, R. Milito, P. Natarajan, and J. Zhu, ‚ÄúFog computing:
A platform for Internet of Things and analytics,‚Äù in Big Data and Internet of Things: A Roadmap for Smart Environments, vol. 546. Cham, Switzerland: Springer, Mar. 2014, pp. 169‚Äì186. [20] L. Tong, Y. Li, and W. Gao, ‚ÄúA hierarchical edge cloud architecture for mobile computing,‚Äù in Proc. IEEE INFOCOM, San Francisco, CA, USA, Apr. 2016, pp. 1‚Äì9. [21] A. Kiani and N. Ansari, ‚ÄúToward hierarchical mobile edge computing: An auction-based proÔ¨Åt maximization approach,‚Äù IEEE Internet Things J., vol. 4, no. 6, pp. 2082‚Äì2091, Dec. 2017. [22] P. Yang, N. Zhang, Y. Bi, L. Yu, and X. S. Shen, ‚ÄúCatalyzing cloudfog interoperation in 5G wireless networks: An SDN approach,‚Äù IEEE Netw., vol. 31, no. 5, pp. 14‚Äì20, Sep. 2017. [23] C.-A. Chen, M. Won, R. Stoleru, and G. G. Xie, ‚ÄúEnergy-efÔ¨Åcient faulttolerant data storage and processing in mobile cloud,‚Äù IEEE Trans. Cloud Comput., vol. 3, no. 1, pp. 28‚Äì41, Jul. 2015. [24] C. You, K. Huang, H. Chae, and B.-H. Kim, ‚ÄúEnergy-efÔ¨Åcient resource allocation for mobile-edge computation ofÔ¨Çoading,‚Äù IEEE Trans. Wireless Commun., vol. 16, no. 3, pp. 1397‚Äì1411, Mar. 2017. [25] C. Wang, C. Liang, F. R. Yu, Q. Chen, and L. Tang, ‚ÄúComputation ofÔ¨Çoading and resource allocation in wireless cellular networks with mobile edge computing,‚Äù IEEE Trans. Wireless Commun., vol. 16, no. 8, pp. 4924‚Äì4938, Aug. 2017. [26] S. Ko, K. Han, and K. Huang, ‚ÄúWireless networks for mobile edge computing: Spatial modeling and latency analysis,‚Äù IEEE Trans. Wireless Commun., vol. 17, no. 8, pp. 5225‚Äì5240, Aug. 2018. [27] X. Lyu, H. Tian, C. Sengul, and P. Zhang, ‚ÄúMultiuser joint task ofÔ¨Çoading and resource optimization in proximate clouds,‚Äù IEEE Trans. Veh. Technol., vol. 66, no. 4, pp. 3435‚Äì3447, Apr. 2017. [28] T. X. Tran and D. Pompili, ‚ÄúJoint task ofÔ¨Çoading and resource allocation for multi-server mobile-edge computing networks,‚Äù IEEE Trans. Veh. Technol., vol. 68, no. 1, pp. 856‚Äì868, Jan. 2018. doi: 10.1109/TVT.2018.2881191. [29] C. Wang, F. R. Yu, C. Liang, Q. Chen, and L. Tang, ‚ÄúJoint computation ofÔ¨Çoading and interference management in wireless cellular networks with mobile edge computing,‚Äù IEEE Trans. Veh. Technol., vol. 66, no. 8, pp. 7432‚Äì7445, Aug. 2017. [30] H. Dahrouj, A. Douik, F. Rayal, T. Y. Al-Naffouri, and M.-S. Alouini, ‚ÄúCost-effective hybrid RF/FSO backhaul solution for next generation wireless systems,‚Äù IEEE Wireless Commun., vol. 22, no. 5, pp. 98‚Äì104, Oct. 2015. [31] D. Tse and P. Viswanath, Fundamentals of Wireless Communication. Cambridge, U.K.: Cambridge Univ. Press, 2005. [32] T. S. Rappaport, Wireless Communications: Principles and Practice, vol. 2. Upper Saddle River, NJ, USA: Prentice-Hall, 1996. [33] M. Al-Fares, A. Loukissas, and A. Vahdat, ‚ÄúA scalable, commodity data center network architecture,‚Äù ACM SIGCOMM Comput. Commun. Rev., vol. 38, no. 4, pp. 63‚Äì74, 2008. [34] J. Michael Steele, The Cauchy‚ÄìSchwarz Master Class: An Introduction to the Art of Mathematical Inequalities Cambridge, U.K.: Cambridge Univ. Press, 2004. [35] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge, U.K.: Cambridge Univ. Press, 2004.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

4956

IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, VOL. 18, NO. 10, OCTOBER 2019

Pengfei Wang (S‚Äô18) received the B.S. degree in electronics engineering from Peking University, Beijing, China, in 2017, where he is currently pursuing the master‚Äôs degree with the Department of Electronics. His current research interests include wireless communications, vehicular networks, and edge computing.

Boya Di (S‚Äô17‚ÄìM‚Äô19) received the B.S. degree in electronic engineering from Peking University, China, in 2014, and the Ph.D. degree from the Department of Electronics, Peking University in 2019. Her current research interests include edge computing, vehicular networks, non-orthogonal multiple access, and 5G wireless networks. So far she has contributed as the Ô¨Årst author for nine journal articles and one of her journal papers is currently listed as ESI highly cited papers. She has also served as a TPC member in GlobeCom 2016, ICCC 2017, ICC 2016, ICC 2018, and VTC 2019.

Zijie Zheng (S‚Äô14) received the Ph.D. degree in signal processing from the Department of Electronics, Peking University, China, in 2019. His current research interests include game theory and optimization in 5G networks, wireless powered networks, mobile social networks, and wireless big data.

Lingyang Song (S‚Äô03‚ÄìM‚Äô06‚ÄìSM‚Äô12‚ÄìF‚Äô19) received the Ph.D. degree from the University of York, U.K., in 2007, where he received the K. M. Stott Prize for excellent research. He was a Research Fellow with the University of Oslo, Norway, until rejoining Philips Research U.K. in March 2008. In May 2009, he joined the Department of Electronics, School of Electronics Engineering and Computer Science, Peking University, and is currently a Boya Distinguished Professor. His main research interests include wireless communication and networks, signal processing, and machine learning. He was a recipient of the IEEE Leonard G. Abraham Prize in 2016 and the IEEE Asia‚ÄìPaciÔ¨Åc (AP) Young Researcher Award in 2012. He has been an IEEE Distinguished Lecturer since 2015.

Authorized licensed use limited to: KAUST. Downloaded on August 21,2022 at 05:28:22 UTC from IEEE Xplore. Restrictions apply.

