22nd International Conference on Telecommunications (ICT 2015)
Energy-Optimal Resource Scheduling and Computation Ofﬂoading in Small Cell Networks

Wael Labidi, Mireille Sarkiss and Mohamed Kamoun
CEA, LIST, Communicating Systems Laboratory BC 173, 91191 Gif-sur-Yvette, France
{wael.labidi, mireille.sarkiss, mohamed.kamoun}@cea.fr

Abstract—This paper provides a joint optimization framework of radio resource scheduling and computation ofﬂoading in small cell LTE based networks. We consider that mobile users are served by nearby small cell base stations which can be endowed with some computational capabilities. The objective is to minimize the average energy consumption at the user terminal to run its mobile applications, either locally or remotely, while satisfying average delay constraints tolerated by these applications. For this problem, we investigate ofﬂine dynamic programming approaches and we devise two solutions: deterministic and randomized, to ﬁnd the optimal radio scheduling-ofﬂoading policy. We show that the dynamic ofﬂine strategies are able of achieving optimal energy efﬁciency at the mobile terminals. Indeed, they can adapt the processing decisions between: local processing, ofﬂoading, and staying idle, by exploiting their knowledge on the channel conditions and the application properties.
I. INTRODUCTION
Small Cells technology has gained recently tremendous attention in wireless communities and has become an essential component to improve cell coverage and boost network capacity for future Long Term Evolution (LTE) standards. Deployed closer to mobile users, small cell base stations, known as Small Cell enhanced Node B (SCeNBs), are expected to provide new services at high data rates, reduced energy and low cost, thus improving cellular applications for homes, enterprises, as well as for metropolitan and rural areas [1].
Parallel to the fast small cell deployments, resource-hungry applications have been continuously gaining popularity, driven by the development of smart devices, such as smartphones and tablets. Besides increasing users’ demands for high-volume multimedia data, such mobile applications are typically demanding intensive computation and high energy consumption. Mobile devices, however, are still facing resource-constraints in terms of computation, storage and, in particular, energy due to their limited battery capacity. Recently, mobile cloud computing has emerged as a promising solution to extend these mobile terminals capabilities [2], [3]. By providing users ondemand wireless access to cloud infrastructures and exploiting cloud virtualization, computation ofﬂoading is enabled from mobile devices to resourcefull remote servers. The mobile users can execute remotely parts of their sophisticated applications and hence, prolong their battery lifetime by reducing locally the energy consumption.
In order to take advantage of improvements of both small cells and cloud computing technologies, the European research project TROPIC has proposed lately the new concept of femtocloud computing [4]. In this framework, the online cloud

services are available at proximity to the mobile users by equipping the SCeNBs in LTE based networks with some computational and storage resources. Therefore, the users can beneﬁt from computation ofﬂoading and distributed storage services to nearby SCeNBs in the small cell cloud with reduced energy and latency. At the same time, they can experience better quality of service on the LTE radio links and higher capacity offered by the cooperating small cells.
Computation ofﬂoading has been signiﬁcantly studied during the past decade to improve performance or save energy of mobile devices by analyzing radio and computation resources including bandwidths, available memory, server speeds and loads, and the amount of data exchanged between the mobile users and the cloud, c.f. [3], [5] and references therein. In [5], an efﬁcient ofﬂoading policy is proposed by jointly conﬁguring the clock frequency in the mobile device and scheduling the data transmission across stochastic wireless channel to minimize the energy consumption. In [6], mobile computation ofﬂoading and mobile data backup communication costs are evaluated in terms of bandwidth and energy consumption by realistic measurements on real devices. Considering a small cell cloud context, [7] addressed the tradeoff between latency and energy consumption in application ofﬂoading and derived an optimal communication strategy assuming multiple antennas and the optimal distribution of computational load between a terminal and the serving cells. Moreover, [8] proposed a centralized dynamic application partitioning for computation ofﬂoading to jointly optimize communication and computation resource allocations under latency constraints.
Similarly to the previous works, we consider in this paper, a small cell dynamic environment experiencing time-varying fading channels and dynamic trafﬁc loads at the mobile terminals through variable rate applications. In this scenario, we investigate joint dynamic optimization of radio resource scheduling and computation ofﬂoading to minimize the energy consumed at the user to process its applications while satisfying the application delay requirements. Unlike the approach of [8] which resolves the optimization problem for instantaneous channel realization and under instantaneous delay constraint, we consider here a time-averaged optimization. Therefore, the scheduling and processing decisions can adapt to the timevarying channel states and user buffer states to reduce the average energy consumption under average delay constraints. We formulate this problem as a Constrained Markov Decision Problem (CMDP). Then, using dynamic programming tools, we investigate ofﬂine solutions to ﬁnd the optimal schedulingofﬂoading strategies based on prior knowledge of the channel distribution and the application arrival rates.

978-1-4A7u9th9o-r8iz0e7d8li-c9e/n1s5e/d$u3s1e.0li0mi©te2d0to1:5KIAEUESET. Downloaded on M3ay1237,2022 at 12:34:44 UTC from IEEE Xplore. Restrictions apply.

22nd International Conference on Telecommunications (ICT 2015)

The remainder of the paper is organized as follows. In section II, we describe the system model from communication and computation perspectives and we derive the energy consumed to process the application data according to different possible decisions. In section III, we formulate the optimization problem and in section IV, we present the proposed ofﬂine dynamic programming strategies. Numerical results are analyzed in section V and ﬁnally conclusions are given in section VI.

II. SYSTEM MODEL

A. Communication Model

We consider a small-cell cloud scenario where mobile users can be served by one or multiple nearby SCeNBs that are endowed with some cloud resources. We focus in the sequel on a point-to-point communication between a given User Equipement (UE) and its serving SCeNB cloud enabled (SCeNBce). Whenever the UE has intensive and delay sensitive applications to run, the main concern is to minimize the energy consumed by the execution of such applications in order to save UE battery. Therefore, it can be envisioned that the UE sends an ofﬂoading request to an entity playing the role of Small Cell Cloud Manager (SCM), aware of all radio and computation resources at UEs and SCeNBsce. Then, this SCM makes a decision and sends it back to the UE whether to process the application locally at the mobile terminal or to exploit the available SCeNBce resources by ofﬂoading totally or partially the computation. These processing decisions depend on the transmission channel states, the computation resources at both sides and the latency imposed by the applications.

We assume that the processing decisions are performed

at successive time slots of duration T . These periods can be

aligned with the frame duration in LTE networks and with the

instants where radio scheduling messages are executed. The

communication channel between the UE and the SCeNBce is

considered as Rayleigh fading channel with complex fading

gain h. The channel remains constant during T and changes

in an independent and identically distributed (i.i.d.) manner

across time slots. Let z = |h|2 denote the channel state,

it is a continuous exponentially distributed random variable

with probability density function p(z) =

1 τ

e−

z τ

with mean τ .

For practical considerations, only quantized channel state x

is considered and thus x takes discrete values from a ﬁnite

channel state space X , corresponding to a sequence of fading

power quantization thresholds [9]. Without loss of generality,

we assume in our model the same communication channel

for uplink (UL) and downlink (DL) transmissions between the

UE and the SCeNB, and we consider that both transmissions

undergo the same white Gaussian noise with zero mean and

variance N0.

B. Computation model
At the user side, the mobile application proﬁle can be deﬁned with two parameters: the input data size, i.e., the number of data bits to be processed in the application and the completion deadline i.e., the delay before which the application should be completed [5]. In our model, the input data is deﬁned in terms of data packets of equal size, l bits. The packets’ arrival follows a Poisson distribution with an average arrival rate of γ packets and these arrivals are i.i.d. The data packets

are queued in the UE buffer until they are scheduled, either for local execution or for remote processing on the SCeNBce. The user buffer has a ﬁnite size of B packets. Let q denote the queue length in the buffer at a given time slot. Then, the buffer state q can take values from a set Q = [0, 1, . . . , B] with cardinality |Q| = (1 + B). In addition, we consider that buffer overﬂow can occur when the queued packets exceed the buffer size, thus leading to packets loss. This event is deﬁned with a probability of buffer overﬂow that should be kept under a predeﬁned threshold δO.

The described Buffer State Information (QSI) and Channel State Information (CSI) deﬁne our system state as s = (q, x). Then, the discrete ﬁnite space S of states s has cardinality |S| = |Q| × |X |. We assume that the state information is sent by the UE to the SCeNBce through channel quality indicators and buffer status reports as in LTE standards. Based on these status reports and on the available computation resources, the small cell manager SCM performs decisions upon user ofﬂoading requests to minimize the energy consumption at the UE terminal. Thus, at each time slot duration T , three scheduling decisions are possible: Processing of u queued packets (u ≤ q) either by (1) local processing at the UE or by (2) computation ofﬂoading at the SCeNBce, and (3) idle mode i.e., waiting until the next time slot to process. These decisions can generate different costs in terms of energy consumption and latency. They are discussed in the sequel.

1- Local processing: The mobile user executes u packets

of its application data locally on its terminal. Let Ml denote the maximal number of packets that can be processed locally

within a time period T . Then, u ∈ [1, . . . , Ml]. Assuming that

the UE terminal consumes a power Pu per packet processed

locally, the energy consumption to process u packets during

T is given by

E = u × Pu × T.

(1)

2- Ofﬂoading: For computation ofﬂoading, the mobile
user transmits u packets for execution at the SCeNbce within a time period T . Let Mo denote the maximal number of ofﬂoaded packets that can be processed remotely within T . Then, u ∈ [1, . . . , Mo]. In this case, the UE would incur an extra overhead in terms of energy for transmitting the data packets to be processed at the SCeNBce. Once the remote processing is completed, the SCeNBce will send back the resulting data to the UE. Accordingly, the energy consumed at the mobile terminal will include the energy spent for: data transmission, data reception and waiting the remote processing completion. It is derived as

E=

uLULPt

+

uLDLPr

WUL log2

1

+

Pt x WUL N0

WDL log2

1

+

Pt x WDL N0

+ uTwPw,

(2)

where Pt is the power used at the UE to transmit UL data, Pt ∈ ]0, . . . , Pmax], Pmax being the maximum transmission power of the UE. Pr is the power consumed by the UE to receive DL data. Pt is the transmission power used at the cloud enabled SCeNB to send the processed result to the UE.
The transmitted data packets have equal size of LUL = l bits and the received processed packets have equal size of LDL bits. WUL and WDL are respectively the bandwidths allocated for these UL and DL transmissions. Pw is the power consumed

Authorized licensed use limited to: KAUST. Downloaded on M3ay1247,2022 at 12:34:44 UTC from IEEE Xplore. Restrictions apply.

22nd International Conference on Telecommunications (ICT 2015)

by the UE while waiting for the processing at the SCeNBce and Tw is the corresponding time spent by the SCeNBce to execute 1 ofﬂoaded packet. Note that for simplicity, only radiated power is considered in the power consumption in (2).

As aforementioned, processing decisions occur at ﬁxed
time instants with slot duration T . Thus, the ofﬂoading decision can be possible only if there exists Pt ∈ ]0, . . . , Pmax] to transmit the ofﬂoaded packets u ≤ q such that the processing at the SCeNBce is achieved within a time T . This condition can be expressed by

uLUL

WULlog2

1

+

Pt x WUL N0

+

uLDL

WDLlog2

1

+

Pt x WDL N0

+uTw ≤ T. (3)

Satisfying the equality allows to compute the transmit power

Pt at the UE and deﬁne the maximal number of ofﬂoaded

packets Mo with respect to the channel conditions.

3- Idle: The mobile user stays in an idle state without processing neither locally, nor remotely, and waits the next processing decision time, u = 0. Though no data is processed, the UE transmission circuitry is switched on and hence it spends energy equal to

E = Pidle × T.

(4)

III. PROBLEM FORMULATION

According to the described system model and deﬁned system states s = (q, x), the main objective of the SCM is to make decisions by ﬁnding the optimal scheduling-ofﬂoading strategy that minimizes the energy consumption at the user terminal subject to delay constraints tolerated by the application. Let μ denote this optimal policy. It is a sequence of control decisions (actions) that specify at each time slot the number of packets u to be processed based on the past history of the system states and the past decisions. Given the statistical knowledge of this history, the system state in the next time slot depends only on the current state and the current control decision, making thus the random state process {s} a discrete time Markov chain. Therefore, the scheduling-ofﬂoading optimization problem can be formulated as a constrained Markov decison process CMDP characterized by the following parameters [10], [11]:

- State space: The state space S is the set of system states s = (q, x) composed of buffer and channel states. It is a discrete ﬁnite space with |S| = |Q| × |X |.

- Action space: The action space U corresponds to the space deﬁning the control actions u given by the three different decisions of local processing, ofﬂoading or staying idle. The action space is also a discrete ﬁnite space and has cardinality |U | = Ml +Mo +1. Ml and Mo are respectively the maximum number of packets that can be processed locally or remotely within time T as described in the previous section.

- Transition Probability: The state transition probability of the MDP is deﬁned by p (s |s, u), the probability to go from state s = (q, x) to the next state s = (q , x ) when action u ∈ U is processed. Assuming that the buffer state (queue length) and the channel state (channel fading) are independent of each other and that the channel states are not correlated, the probability of state transition is deﬁned by

p (s |s, u) = p(q |q, u)p(x ) = p(a)p(x ),

(5)

where the next buffer state q is deﬁned according to the current

buffer state q, the number of data packets’ arrivals a and the

number of processed packets u at state s as q = q−u+a. p(x )

is the probability distribution of the quantized channel states

and p(a) is the probability distribution of the packet arrivals.

Given that the packets’ arrival follows a Poisson distribution

with average arrival rate γ, the probability of generating a

packets

is

p(a)

=

e−γ

γa a!

.

Then,

the

transition

probability

is

expressed as

p

(s

|s,

u)

=

p(x

)e−γ

γ(q −q+u) (q − q + u)!

.

(6)

For this CMDP, the optimal scheduling-ofﬂoading policy μ is then a mapping function from the state space S to the action space U . It is a stationary policy that does not depend on the time at which the decision is made. In an inﬁnite horizon, the control policy μ aims at minimizing the average consumed energy at the UE side while satisfying quality of service (QoS) requirements in terms of average delay experienced by the UE packets before being processed and average buffer overﬂow constraint. The cost function and the constraint functions of this inﬁnite horizon CMDP problem are deﬁned in the following.

The average energy cost under the strategy μ is given by

E¯μ = lim 1 Eμ N→∞ N

N
CE(sn, un)
n=1

,

(7)

where Eμ is the expectation with respect to μ. At a given
time slot n, n = [1, . . . , N ], the system state is denoted sn and μ(sn) = un is the action deciding the number un of packets to be processed. Then, CE(sn, un) is the instantaneous energy cost when the action un is performed at state sn. This instantaneous average cost is given by CE(sn, un) = E as derived in (1), (2) or (4) according to the three possible actions.

The average delay constraint under strategy μ can be
formulated by Little’s Law as an average queue length of the
user buffer [9]. Let CQ(sn, un) be the instantaneous delay cost experienced by the UE packets at state sn under action un. It is deﬁned by CQ(sn, un) = CQ(sn) = qn, and hence the time averaged delay constraint is given by

Q¯μ = lim 1 Eμ N→∞ N

N
CQ(sn, un)
n=1

= lim 1 Eμ N→∞ N

N
qn
n=1

(8)

The average buffer overﬂow constraint is deﬁned according
to an overﬂow probability of the buffer overﬂow events as
mentioned in the computation model. Let CO(sn, un) be the instantaneous buffer overﬂow cost at state sn under action un. The overﬂow probability is given by

O¯μ = lim 1 Eμ N →∞N

N

CO(sn, un)

= lim 1 Eμ N→∞ N

N
1(qn >B )

n=1

n=1

(9)

Then, the scheduler objective is to ﬁnd the optimal strategy

which resolves the constrained problem by minimizing the av-

erage energy consumed at the UE while satisfying an average

delay on the processed packets, i.e., a queue length below a

Authorized licensed use limited to: KAUST. Downloaded on M3ay1257,2022 at 12:34:44 UTC from IEEE Xplore. Restrictions apply.

22nd International Conference on Telecommunications (ICT 2015)

certain value δQ, and a buffer overﬂow probability under a ﬁxed threshold δO. The optimization problem can be stated as

μ∗ = min E¯μ
μ

s.t. Q¯μ ≤ δQ and O¯μ ≤ δO.

(10)

IV. OFFLINE DYNAMIC PROGRAMMING STRATEGIES
Two main approaches have been proposed to resolve an inﬁnite horizon average cost problem [9]–[11]: ofﬂine and online dynamic programming strategies. The online approach is based on learning from past to ﬁnd a policy that can cope with unknown environment [9]. In [12], we have studied the online learning approach for our problem and have shown that it is suboptimal in terms of energy consumption due to its imperfect knowledge on the data arrival and the channel state distributions. In this paper, we investigate the ofﬂine approach that requires a priori knowledge of the channel statistics and the application properties. This knowledge can be acquired in advance or estimated over sufﬁciently long period before running the application. Then, the pre-calculated ofﬂine strategy can provide an accurate modelling of the state transition probabilities of the constrained problem, leading thus to optimality. Two ofﬂine solutions are proposed in the sequel, namely: deterministic ofﬂine strategy and randomized ofﬂine strategy.

A. Deterministic Ofﬂine Strategy

The deterministic ofﬂine policy consists in a deterministic mapping from the state space S to the action space U , associating for each state s a unique action u that is performed when this state is visited. This scheduling-ofﬂoading policy, denoted
μ, determines the number un of packets to be processed as un = μ(sn) ∀n ∈ N.

In order to ﬁnd the optimal deterministic policy μ∗, the CMDP problem can be converted into an unconstrained problem using Lagrangian approach as

L(μ, λ1, λ2) = E¯μ + λ1(Q¯μ − δQ) + λ2(O¯μ − δO)

=

limN →∞

1 N

Eμ

[

N n=1

CE (sn ,

un)

+

λ1(qn

−

δQ)

+λ2(1(qn>B) − δO)],

(11)

where λ1 and λ2 are the Lagrange multipliers corresponding to the delay and overﬂow constraints, and an instantaneous cost
per stage is deﬁned as

CL(sn, un, λ1, λ2) = CE(sn, un) + λ1(qn − δQ)

+ λ2(1(qn>B) − δO).

(12)

Satisfying in addition the saddle point optimality condition [9], the problem of (10) can be reformulated as

(μ∗, λ∗1, λ∗2) = argmax argmin L(μ, λ1, λ2),

(13)

λ1≥0,λ2≥0 μ

where the policy μ∗ is optimal for the constrained problem for

given values λ1 and λ2 multipliers and (μ∗, λ∗1,

.λλ∗2 )∗1

and λ∗2 are the optimal Lagrange is the saddle point that minimizes

the Lagrangian.

The minimization problem is handled by solving dynamic programming equations, known as Bellman optimality equations using Relative Value Iteration Algorithm (RVIA) [11].

For ﬁxed values of Lagrange multipliers λ1 and λ2, the RVIA

computes the optimal value s ∈ S iteratively by satisfying

function Vλ∗1 the Bellman

,λ2 (s) for a equation as

state

Vλ1

,λ2

(s)=min
u

CL(s, u, λ1, λ2)+

p (s |s, u)Vλ1,λ2 (s )−β

s ∈S

(14)

where β is the optimal cost per stage [11].

Then, for ﬁxed values of λ1, λ2, the optimal policy μ∗λ1,λ2 can be obtained using policy iteration approach based on two steps executed simultaneously:

1- Policy evaluation: Given the policy μiλ1,λ2 , and starting from an initial state s0, compute the corresponding cost to go (value function) from all the states s on the inﬁnite horizon. This can be achieved by using iteratively the RVIA algorithm
to ﬁnd: - the average cost per stage βλi 1,λ2 for which Vλi1,λ2 (s0) = 0 - the average cost to go for each state s = s0 as

Vλi1,λ2 (s) = CL(s, μiλ1,λ2 (s), λ1, λ2)

+

p s |s, μiλ1,λ2 (s) Vλi1,λ2 (s ) − βλi 1,λ2

s ∈S

2- Policy improvement: Obtain a new policy μiλ+1,1λ2 allowing a better average cost

μiλ+1,1λ2(s) =

argmin
μ

CL(s,

μ,

λ1,

λ2)+
s

p
∈S

(s

|s,

μ)Vλi1,λ2 (s

)

The policy iteration algorithm iterates until satisfying: μiλ1,λ2 = μiλ+1,1λ2 = μ∗λ1,λ2 and thus the optimal policy for a ﬁxed pair (λ1, λ2) is given by

μ∗λ1 ,λ2

=

argmin L(μ, λ1, λ2).
μ

(15)

In order to ﬁnd now the optimal Lagrange multipliers λ∗1, λ∗2, an iterative gradient descent technique is used in an outer loop to update these parameters as

λn1 +1 = λn1 + ζ1 Q¯μn∗λn1 ,λn2 − δQ

(16)

λn2 +1 = λn2 + ζ2 O¯nμ∗λn1 ,λn2 − δO

(17)

wanhderO¯e μζ∗λ11,,ζλ22

are are

decreasing increment coefﬁcients and Q¯μ∗λ1,λ2 the average delay cost and the average buffer

overﬂow cost, respectively, according to the optimal policy

μ∗λ1,λ2 . Under with respect to

this policy, these average a state distribution ρμ∗λ1,λ2

costs (s) as

are

evaluated

Q¯ μ∗λ1 ,λ2 O¯ μ∗λ1 ,λ2

=

ρμ∗λ1,λ2 (s)CQ(s, μ∗λ1,λ2 (s))

s∈S

=

ρμ∗λ1,λ2 (s)CO(s, μ∗λ1,λ2 (s))

s∈S

(18) (19)

with the state distribution deﬁned as function of the state

transition probability ∀s ∈ S as

under

policy

μ∗λ1 ,λ2

and

is

expressed

ρμ∗λ1,λ2 (s) =

ρμ∗λ1,λ2 (s )p s|s , μ∗λ1,λ2 (s) .

s ∈S

(20)

Authorized licensed use limited to: KAUST. Downloaded on M3ay1267,2022 at 12:34:44 UTC from IEEE Xplore. Restrictions apply.

22nd International Conference on Telecommunications (ICT 2015)

B. Randomized Ofﬂine Strategy

The randomized ofﬂine policy consists in a probabilistic mapping from the state space S to the action space U , associating for each state s an action u = μ(s) that is a random variable with a probability distribution uniquely associated to the visited state. Therefore, the ofﬂine randomized strategy μ relies on weighting each (state s, action u) pair with a given probability called the occupation measure. This measure represents the probability to visit each (s, u) pair according to the devised strategy [10].

Let p0 be the probability distribution of the initial state s0. For an inﬁnite length trajectory, the occupation measure ρμ(s, u) of a state-action pair (s, u) when the policy μ is employed corresponds to the fraction of time slots where the state s is visited and the action u = μ(s) is performed under the condition that the initial state s0 of the trajectory is drawn according to p0. It is deﬁned by

ρμ(s, u) = lim 1 Eμ N→∞ N

N
1(sn =s,μ(sn )=un )

n=1

(21)

The optimal occupation measure can be obtained by formulating the CMDP optimization problem (10) as a linear programming problem [10] as

ρ∗ = argmin

ρ(s, u)CE(s, u)

μ s∈S,u∈U

s.t.

ρ(s, u)q ≤ δQ ,

ρ(s, u) ≤ δO

s∈S ,u∈U

s∈S,u∈U |q>B

ρ(s , u) 1(s =s) − p(s|s , u) = 0 ∀s ∈ S (22)
s ∈S,u∈U

where the last line results from the Markov property of the process (sn, un). An optimal randomized policy can be then obtained from ρ∗ the solution of the above problem by choosing a random action u at a given state s according to the following probability

ps(u) =

ρ∗(s, u) u ∈U ρ∗(s, u ) .

(23)

V. NUMERICAL RESULTS
In this section, we evaluate by numerical results the deterministic and randomized ofﬂine strategies devised for the scheduling-computation ofﬂoading problem. We consider the single cell single user scenario described in section II with the following characteristics. The allocated bandwidths for UL and DL transmissions are equal to WUL = 500KHz and WDL = 5MHz and the time slot duration is T = 2 ms. For the communication channel model, the channel state z follows an exponential distribution with mean τ = 0.47 and the quantized channel state x can take 8 possible values from the ﬁnite space X = [−13, −8.47, −5.41, −3.28, −1.59, −0.08, 1.42, 3.18] dB. All the powers are normalized by the signal to noise ratio experienced by the SCeNB when unitary power signal is sent at the UE side. This is equivalent to normalizing by W N0/α where α is the path-loss of the channel between the UE and the SCeNB without fading. The numerical values of these powers at the user are given by: Pu = 0.7, Pmax = 6, Pr = 0.5, Pidle = 0, Pw = 0.2. At the SCeNBce, the transmission

power is Pt = 20 and the time spent to process one packet is Tw = 0.1ms.
For the application model, the data arrival follows a Poisson distribution with an average rate γ bits/sec and packets’ size equal to l = 500 bits while the user’s buffer is of size B = 50 packets. Then, the packets to be processed have equal size LUL = l = 500 bits and the resulting packets of remote processing of the ofﬂoaded ones have size LDL = 5000 bits. We assume that, within a time slot T , the maximum number of packets that can be processed locally is Ml = 1 and the maximum number of ofﬂoaded packets that can be processed remotely is Mo = 5. For the system constraints, we consider an application latency that corresponds to an average queue constraint of δQ = 10 packets and we tolerate an overﬂow probability of δO = 10−5.
In Figure 1, we illustrate the average consumed energy as function of the data arrival rates for different ofﬂine strategies. We compare the deterministic dynamic programming policy denoted “Dynamic programming policy” and the randomized dynamic programming policy denoted “Linear programming policy” to three other policies that maintain the same average queue length. The “Only ofﬂoading dynamic policy” is based on the deterministic dynamic programming policy but takes only ofﬂoading decisions to process the packets remotely at the SCeNBce. The “Only local processing” and “Immediate scheduling” policies are however static policies. The former one consist in processing locally at the UE all the packets that exceed the average queue constraint δQ. The latter one decides to process u packets when the queue length exceeds δQ according to: u = max (min(q + a − δQ, Mo), 0). If u = Ml = 1, it can choose either to process locally or to ofﬂoad depending on the action that minimizes the instantaneous consumed energy. On the other side, if u > Ml, it performs only ofﬂoading.
Fig. 1. Average Energy Consumption for different policies
We can observe that the deterministic dynamic programming strategy achieves the optimal performance of the randomized linear programming strategy and gives the lowest energy consumption. Indeed, for these strategies, the system has perfect knowledge of the states transitions. It can adapt its processing decisions according to the arrival rate and the channel conditions while satisfying the imposed delay constraints. Thus, more packets can be ofﬂoaded in good channel states whereas transmission is limited and local processing or

Authorized licensed use limited to: KAUST. Downloaded on M3ay1277,2022 at 12:34:44 UTC from IEEE Xplore. Restrictions apply.

22nd International Conference on Telecommunications (ICT 2015)

idle mode are decided in case of bad channel states. The only ofﬂoading dynamic policy has close performance to the latter strategies for low and moderate arrival rates but consumes more energy for high arrival rates. This is due to the fact that the packets are ofﬂoaded for remote processing even when the channel is in bad conditions since local processing decisions are not possible. We can notice also that both static policies consume much more energy than dynamic ones since they do not exploit the radio link quality. Idle mode is not allowed in case of high arrival rates and bad channel states.

is decided whenever the channel is in bad states and ofﬂoading decisions are made when the channel conditions allow for better energy saving, limiting thus the energy-consuming local processing.
VI. CONCLUSION
In this paper, we have addressed computation ofﬂoading problem from a mobile user to its serving resourcefull cloud enabled SCeNB. We have proposed to jointly optimize the radio resource scheduling and ofﬂoading in order to minimize the average energy consumed by the mobile terminal to process its application under average delay constraints. Both deterministic and randomized ofﬂine policies based dynamic programming have been studied. The ofﬂine dynamic strategies can beneﬁt from their prior knowledge on the application rates and the channel statistics to perform ofﬂoading decisions in good channel states and local processing or staying idle under bad channel conditions. Hence, they have shown through numerical results optimal energy saving gains compared to only ofﬂoading and static processing strategies.

Fig. 2. CDF of the processed packets per slot
Fig. 3. Percentage of processing decisions for different arrival rates
Figure 2 shows the cumulative distribution function CDF of the number of processed packets per slot for different average arrival rates under the ofﬂine dynamic programming policy. It can be seen that more packets are processed for higher arrival rates. This result is also observed in Figure 3 that presents the processing decisions distribution for different arrival rates. For high arrival rates (2 packets/slot), we can notice that ofﬂoading decisions are favoured for most of the time. Indeed, the arrival rate approaches, in this case, the maximal rate of ofﬂoading (2.5 packets/slot) according to the considered channel distribution. Therefore, under delay and overﬂow constraints, the ofﬂine strategy makes decisions to process the queued packets while taking beneﬁt of the channel conditions. The packets are then ofﬂoaded when channel states are good and processed locally under bad channel conditions, limiting hence the idle mode. On the other hand, for low and moderate arrival rates (0.5, 1 and 1.5 packets/slot), Idle mode

ACKNOWLEDGMENT
This work was supported by the European Commission 7th Framework Program Project TROPIC, under grant Nr. 318784.
REFERENCES
[1] V. Chandrasekhar and J. Andrews, “Femtocell Networks: A Survey,” IEEE Communication Magazine, vol. 46, no. 9, pp. 59–67, Sept. 2008.
[2] K. Kumar and Y.-H. Lu, “Cloud Computing for Mobile Users: Can Ofﬂoading Computation Save Energy,” IEEE Computer, vol. 43, no. 4, pp. 51–56, Apr. 2010.
[3] K. Kumar, J. Liu, Y.-H. Lu, and B. Bhargava, “A Survey of Computation Ofﬂoading for Mobile Systems,” Mobile Networks and Applications, Springer Science, vol. 18, no. 1, p. 129140, Feb. 2013.
[4] “TROPIC: Distributed computing, storage and radio resource allocation over cooperative femtocells,” http://www.ict-tropic.eu.
[5] W. Zhang, Y. Wen, K. Guan, D. Kilper, H. Luo, and D. Wu, “EnergyOptimal Mobile Cloud Computing under Stochastic Wireless Channel,” IEEE Trans. Wireless Communications, vol. 12, no. 9, p. 45694581, Sept. 2013.
[6] M. V. Barbera, S. Kosta, A. Mei, V. C. Perta, and J. Stefa, “To ofﬂoad or not to ofﬂoad? the bandwidth and energy costs of mobile cloud computing,” Proc. IEEE International Conference on Computer Communications (INFOCOM13), Apr. 2013.
[7] O. Munoz, A. P.-Iserte, and J. Vidal, “Optimization of Radio and Computational Resources for Energy Efﬁciency in Latency-Constarined Application Ofﬂoading,” IEEE Trans. on Vehicular Technology, no. 99, Nov 2014.
[8] S. Barbarossa, S. Sardellitti, and P. Di Lorenzo, “Communicating While Computing: Distributed mobile cloud computing over 5G heterogeneous networks,” IEEE Signal Processing Magazine, vol. 31, no. 6, pp. 45–55, Nov. 2014.
[9] N. Salodkar, A. Bhorkar, A. Karandikar, and V.S. Borkar., “An online learning algorithm for energy efﬁcient delay constrained scheduling over a fading channel,” IEEE Journal on Selected Areas in Communications, vol. 26, no. 4, p. 732742, May 2008.
[10] E. Altman, Dynamic Programming and Optimal Control. Chapman and Hall/CRC.
[11] D. P. Bertsekas, Dynamic Programming and Optimal Control. Athena Scientiﬁc, 4th Edition, 2005.
[12] M. Kamoun, W. Labidi, and M. Sarkiss, “Joint Resource Allocation and Ofﬂoading Strategies in Cloud Enabled Cellular Networks,” IEEE
International Conference on Communications (ICC) 2015.

Authorized licensed use limited to: KAUST. Downloaded on M3ay1287,2022 at 12:34:44 UTC from IEEE Xplore. Restrictions apply.

