856

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 1, JANUARY 2019

Joint Task Ofﬂoading and Resource Allocation for Multi-Server Mobile-Edge Computing Networks
Tuyen X. Tran , Member, IEEE, and Dario Pompili, Senior Member, IEEE

Abstract—Mobile-edge computing (MEC) is an emerging paradigm that provides a capillary distribution of cloud computing capabilities to the edge of the wireless access network, enabling rich services and applications in close proximity to the end users. In this paper, an MEC enabled multi-cell wireless network is considered where each base station (BS) is equipped with a MEC server that assists mobile users in executing computation-intensive tasks via task ofﬂoading. The problem of joint task ofﬂoading and resource allocation is studied in order to maximize the users’ task ofﬂoading gains, which is measured by a weighted sum of reductions in task completion time and energy consumption. The considered problem is formulated as a mixed integer nonlinear program (MINLP) that involves jointly optimizing the task ofﬂoading decision, uplink transmission power of mobile users, and computing resource allocation at the MEC servers. Due to the combinatorial nature of this problem, solving for optimal solution is difﬁcult and impractical for a large-scale network. To overcome this drawback, we propose to decompose the original problem into a resource allocation (RA) problem with ﬁxed task ofﬂoading decision and a task ofﬂoading (TO) problem that optimizes the optimal-value function corresponding to the RA problem. We address the RA problem using convex and quasi-convex optimization techniques, and propose a novel heuristic algorithm to the TO problem that achieves a suboptimal solution in polynomial time. Simulation results show that our algorithm performs closely to the optimal solution and that it signiﬁcantly improves the users’ ofﬂoading utility over traditional approaches.
Index Terms—Mobile edge computing, computation ofﬂoading, multi-server resource allocation, distributed systems.
I. INTRODUCTION
T HE rapid growth of mobile applications and the Internet of Things (IoTs) have placed severe demands on cloud infrastructure and wireless access networks such as ultra-low latency, user experience continuity, and high reliability. These stringent requirements are driving the need for highly localized services at the network edge in close proximity to the end
Manuscript received September 16, 2017; revised March 7, 2018, May 14, 2018, and September 22, 2018; accepted October 27, 2018. Date of publication November 13, 2018; date of current version January 15, 2019. This work was supported in part by the National Science Foundation under Grant CNS1319945. The work of Tuyen X. Tran was done while he was a Ph.D. student at Rutgers University. The review of this paper was coordinated by Prof. Y. Cheng. (Corresponding author: Tuyen Xuan Tran.)
T. X. Tran is with the AT&T Labs–Research, Bedminster, NJ, USA (e-mail:, tuyen.tran@rutgers.edu).
D. Pompili is with the Department of Electrical and Computer Engineering, Rutgers University–New Brunswick, NJ 08901-8554 USA (e-mail:, pompili@rutgers.edu).
Color versions of one or more of the ﬁgures in this paper are available online at http://ieeexplore.ieee.org.
Digital Object Identiﬁer 10.1109/TVT.2018.2881191

users. In light of this, the Mobile-Edge Computing (MEC) [1] concept has emerged, which aims at uniting telco, IT, and cloud computing to deliver cloud services directly from the network edge. Differently from traditional cloud computing systems where remote public clouds are utilized, MEC servers are owned by the network operator and are implemented directly at the cellular Base Stations (BSs) or at the local wireless Access Points (APs) using a generic-computing platform. With this position, MEC allows for the execution of applications in close proximity to end users, substantially reducing end-to-end (e2e) delay and releasing the burden on backhaul networks [2].
With the emergence of MEC, the ability of resourceconstrained mobile devices to ofﬂoad computation tasks to the MEC servers is expected to support a myriad of new services and applications such as augmented reality, IoTs, autonomous vehicles and image processing [3]. Example applications such as face detection and recognition for airport security and surveillance [4], video crowd-sourcing that reconstructs multi-view live videos of an event [5], or real-time healthcare data analytics [6] can highly beneﬁt from the collaboration between mobile devices and MEC platform. In the former case, a central authority such as the Federal Bureau of Investigation (FBI) would extend their Amber alerts such that all available cell phones in the area where a missing child was last seen that opt-in to the alert would actively capture images. In the latter case, the MEC servers collect individual input videos (views) captured for the same event from multiple attendees and combine them into multi-view videos, allowing viewers to watch the event from various angles. In both applications, the user devices only provide input data (images, videos) and the computation-intensive tasks (face recognition, multi-view video construction) are then performed at the MEC servers.
Task ofﬂoading, however, incurs extra overheads in terms of delay and energy consumption due to the communication required between the devices and the MEC server in the uplink wireless channels. Additionally, in a system with a large number of ofﬂoading users, the ﬁnite computing resources at the MEC servers considerably affect the task execution delay [7]. Therefore, ofﬂoading decisions and performing resource allocation become a critical problem toward enabling efﬁcient computation ofﬂoading. Previously, this problem has been partially addressed by optimizing either the ofﬂoading decision [7], [8], communication resources [9], [10], or computing resources [11], [12]. Recently, Sardellitti et al. [13] addressed the joint allocation of radio and computing resources, while the authors in [14] considered the joint task ofﬂoading and resources optimization

0018-9545 © 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

TRAN AND POMPILI: JOINT TASK OFFLOADING AND RESOURCE ALLOCATION FOR MULTI-SERVER MEC NETWORKS

857

in a multi-user system. Both of these works, however, only concentrate on a system with a single MEC server.
Our Vision: Unlike the traditional approaches mentioned above, our objective is to design a holistic solution for joint task ofﬂoading and resource allocation in a multi-server MECassisted network so as to maximize the users’ ofﬂoading gains. Speciﬁcally, we consider a multi-cell ultra-dense network where each BS is equipped with a MEC server to provide computation ofﬂoading services to the mobile users. The distributed deployment of the MEC servers along with the densiﬁcation of (small cell) BSs—as foreseen in the 5G standardization roadmap [15]—will pave the way for real proximity, ultra-low latency access to cloud functionalities. Additionally, the beneﬁts brought by a multi-server MEC system over the single-server MEC (aka single-cloud) system are multi-fold: (i) ﬁrstly, as each MEC server may be overloaded when serving a large number of ofﬂoading users, one can release the burdens on that server by directing some users to ofﬂoad to the neighboring servers from the nearby BSs, thus preventing the limited resources on each MEC server from becoming the bottle neck; (ii) secondly, each user can choose to ofﬂoad its task to the BS with more favorable uplink channel condition, thus saving transmission energy consumption; (iii) ﬁnally, coordination of resource allocation to ofﬂoad users across multiple neighboring BSs can help mitigate the effect of interference and resource contention among the users and hence, improve ofﬂoading gains when multiple users ofﬂoad their tasks simultaneously.
The envisioned scheme requires global knowledge about the computation tasks at the users, the computational resources at the MEC servers, and the wireless channel condition between users and BSs. The mechanism to gather such information can be done similarly as in the Coordinated Multi-Point (CoMP) transmission systems [16] where the BSs exchange their channel information with each other using the logical X2 interface. Alternatively, in the emerging Cloud Radio Access Network (CRAN) [17], where all the BSs are connected to the same Base Band Unit (BBU) via high-capacity backhaul links, the global system state can be easily accessible at the BBU. Hence, the proposed scheme can be implemented at a central entity, which might be located at an aggregation point in the traditional RAN hierarchy [1] or at the BBU pool in C-RAN. Similarly to the system that performs centralized joint transmission for interference management [16] and/or joint user scheduling [18], our proposed scheme comes with the cost of increased demand on backhaul due to additional signaling overhead. However, it is anticipated that this issue can be overcome when different BSs are connected together like in a C-RAN architecture.
Challenges and Contributions: To exploit in full the beneﬁts of computation ofﬂoading in the considered multi-cell, multiserver MEC network, there are several key challenges that need to be addressed. Firstly, the radio resource allocation is much more challenging than the special cases studied in the literature (cf. [14]) due to the presence of inter-cell interference that introduces the coupling among the achievable data rate of different users, which makes the problem nonconvex. Secondly, the complexity of the task-ofﬂoading decision is high as, for each user, one needs to decide not only whether it should ofﬂoad the

computation task but also which BS/server to ofﬂoad the task to. Thirdly, the optimization model should take into account the inherent heterogeneity in terms of mobile devices’ computing capabilities, computation task requirements, and availability of computing resources at different MEC servers. In this context, the main contributions of this article are summarized as follows.
1) We model the ofﬂoading utility of each user as the weighted-sum of the improvement in task-completion time and device energy consumption; we formulate the problem of Joint Task Ofﬂoading and Resource Allocation (JTORA) as a Mixed Integer Non-linear Program (MINLP) that jointly optimizes the task ofﬂoading decisions, users’ uplink transmit power, and computing resource allocation to ofﬂoaded users at the MEC servers, so as to maximize the system ofﬂoading utility.
2) While the JTORA problem is very challenging, we propose to decompose the problem into (i) a Resource Allocation (RA) problem with ﬁxed task ofﬂoading decision and (ii) a Task Ofﬂoading (TO) problem that optimizes the optimal-value function corresponding to the RA problem.
3) We further show that the RA problem can be decoupled into two independent problems, namely the Uplink Power Allocation (UPA) problem and the Computing Resource Allocation (CRA) problem; the resulting UPA and CRA problems are addressed using quasi-convex and convex optimization techniques, respectively.
4) We propose a novel low-complexity heuristic algorithm to tackle the TO problem and show that it achieves a suboptimal solution in polynomial time.
5) We carry out extensive numerical simulations to evaluate the performance of the proposed solution, which is shown to be near-optimal and to improve signiﬁcantly the users’ ofﬂoading utility over traditional approaches.
Article Organization: The remainder of this article is organized as follows. In Section II, we review the related works. In Section III, we present the system model. The joint task ofﬂoading and resource allocation problem is formulated in Section IV, followed by the decomposition of the problem itself. We present our proposed solution in Section V and numerical results in Section VI. Finally, in Section VII we conclude the article.
II. RELATED WORKS
The MEC paradigm has attracted considerable attention in both academia and industry over the past several years. In 2013, Nokia Networks introduced the very ﬁrst real-world MEC platform [19], in which the computing platform—Radio Applications Cloud Servers (RACS)—is fully integrated with the Flexi Multiradio BS. Saguna also introduced their fully virtualized MEC platform, so called Open-RAN [20], that can provide an open environment for running third-party MEC applications. Recently, a MEC Industry Speciﬁcations Group (ISG) was formed to standardize and moderate the adoption of MEC within the RAN [1].
A number of solutions have also been proposed to exploit the potential beneﬁts of MEC in the context of the IoTs and 5G. For instance, our previous work in [2] proposed to explore the

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

858

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 1, JANUARY 2019

synergies among the connected entities in the MEC network and presented three representative use-cases to illustrate the beneﬁts of MEC collaboration in 5G networks. In [21], we proposed a collaborative caching and processing framework in a MEC network whereby the MEC servers can perform both caching and transcoding so as to facilitate Adaptive Bit-Rate (ABR) video streaming. Similar approach was also considered in [22] which combined the traditional client-driven dynamic adaptation scheme, DASH, with network-assisted adaptation capabilities. In addition, MEC is also seen as a key enabling technique for connected vehicles by adding computation and geo-distributed services to the roadside BSs so as to analyze the data from proximate vehicles and roadside sensors and to propagate messages to the drivers in very low latency [23].
Recently, several works have focused on exploiting the beneﬁts of computation ofﬂoading in MEC network [24]. Note that similar problems have been investigated in conventional Mobile Cloud Computing (MCC) systems [25]. However, a large body of existing works on MCC assumed an inﬁnite amount of computing resources available in the cloudlets, where the ofﬂoaded tasks can be executed with negligible delay [26]–[28]. The problem of ofﬂoading scheduling was then reduced to radio resource allocation in [9] where the competition for radio resources is modeled as a congestion game of selﬁsh mobile users. In the context of MEC, the problem of joint task ofﬂoading and resource allocation was studied in a single-user system with energy harvesting devices [29], and in a multi-cell multi-user systems [13]; however the congestion of computing resources at the MEC server was omitted. Similar problem is studied in [14] considering the limited edge computing resources in a singleserver MEC system.
Computation ofﬂoading in MEC can also utilize the heterogeneous resource pool constituted by the end-user devices. In our previous work [2], a novel resource management framework was envisioned to orchestrate both the horizontal collaboration at the end-user layer and at the MEC layer as well as the vertical collaboration among end-users, edge nodes, and cloud nodes. Along this line, Chen et al. [30] proposed a Deviceto-Device (D2D) Crowd framework where a massive crowd of devices at the network edge leverage network-assisted D2D collaboration for computation and communication resource sharing. Using a game-theoretic approach, the work in [31] considered a computation ofﬂoading problem that involves selﬁsh mobile users that want to maximize their individual performance. However, the difference between [30], [31] and our work is multi-fold. Firstly, the focus of [30], [30] is on the task assignment problem in which the data rates of the wireless links are considered as constants, whereas our work considers the joint design of task assignment and resource allocation policy for which the varying wireless channels and multi-user interference are taken into account when calculating the data rates. Secondly, the objective in [30] is to minimize the total energy consumption on mobile devices while we consider a parameterized objective function that can be tuned to optimize both the energy consumption and task execution time. Thirdly, it is assumed in [31] that the users always use a constant transmit power while our approach optimizes users’ transmit power.

Fig. 1. Example of a cellular system with MEC servers deployed at the BSs.

In summary, most of the existing works did not consider a holistic approach that jointly determines the task ofﬂoading decision and the radio and computing resource allocation in a multi-cell, multi-server system as considered in this article.

III. SYSTEM MODEL
We consider a multi-cell, multi-server MEC system as illustrated in Fig. 1, in which each BS is equipped with a MEC server to provide computation ofﬂoading services to the resourceconstrained mobile users such as smart phones, tablets, and wearable devices. In general, each MEC server can be either a physical server or a virtual machine with moderate computing capabilities provisioned by the network operator and can communicate with the mobile devices through wireless channels provided by the corresponding BS. Each mobile user can choose to ofﬂoad computation tasks to a MEC server from one of the nearby BSs it can connect to. We denote the set of users and MEC servers in the mobile system as U = {1, 2, . . . , U } and S = {1, 2, . . . , S}, respectively. For ease of presentation, we will refer to the MEC server s and BS s interchangeably. The modeling of user computation tasks, task uploading transmissions, MEC computation resources, and ofﬂoading utility are presented here below. For ease of reference, the key notations used in the article are summarized in Table I.

A. User Computation Tasks

We consider that each user u ∈ U has one computation task

at a time, denoted as Tu , that is atomic and cannot be divided

into subtasks. Each computation task Tu is characterized by a tuple of two parameters, du , cu , in which du [bits] speci-

ﬁes the amount of input data necessary to transfer the program

execution (including system settings, program codes, and in-

put parameters) from the local device to the MEC server, and

cu [cycles] speciﬁes the workload, i.e., the amount of compu-

tation to accomplish the task. The values of du and cu can be

obtained through carefully proﬁling of the task execution [7],

[32]. Each task can be performed locally on the user device or

ofﬂoaded to a MEC server. By ofﬂoading the computation task

to the MEC server, the mobile user would save its energy for

task execution; however, it would consume additional time and

energy for sending the task input in the uplink.

Let ful > 0 denote the local computing capability of user u

in terms of CPU cycles/s. Hence, if user u executes its task

locally,

the

task

completion

time

is

tlu

=

cu

f

l u

[seconds]. To

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

TRAN AND POMPILI: JOINT TASK OFFLOADING AND RESOURCE ALLOCATION FOR MULTI-SERVER MEC NETWORKS

859

TABLE I SUMMARY OF KEY NOTATIONS

calculate the energy consumption of a user device when ex-
ecuting its task locally, we use the widely adopted model of the energy consumption per computing cycle as E = κf 2 [9], [33], where κ is the energy coefﬁcient depending on the chip
architecture and f is the CPU frequency. Thus, the energy consumption, Eul [J], of user u when executing its task Tu locally, is calculated as,

Eul = κ ful 2cu .

(1)

B. Task Uploading
In case user u ofﬂoads its task Tu to one of the MEC servers, the incurred delay comprises: (i) the time tuup [s] to transmit the input to the MEC server on the uplink, (ii) the time tuexe [s] to execute the task at the MEC server, and (iii) the time to transmit the output from the MEC server back to the user on the downlink. Since the size of the output is generally much smaller than the input, plus the downlink data rate is much higher than that of the uplink, we omit the delay of transferring the output in our computation, as also considered in [9], [14], [31]. Note that, when the delay of the downlink transmission of output data is non-negligible, our proposed algorithm can still be directly applied for a given downlink rate allocation scheme and known output data size.
In this work, we consider the system with OFDMA as the multiple access scheme in the uplink [34], in which the operational frequency band B is divided into N equal sub-bands of size W = B/N [Hz]. To ensure the orthogonality of up-

link transmissions among users associated with the same BS,
each user is assigned to one sub-band. Thus, each BS can serve
at most N users at the same time. Let N = {1, . . . , N } be
the set of available sub-band at each BS. We deﬁne the task
ofﬂoading variables, which also incorporate the uplink subband scheduling, as xjus , u ∈ U , s ∈ S, j ∈ N , where xjus = 1 indicates that task Tu from user u is ofﬂoaded to BS s on sub-band j, and xjus = 0 otherwise. We deﬁne the ground set G that contains all the task ofﬂoading variables as G =
xjus |u ∈ U , s ∈ S, j ∈ N and the task ofﬂoading policy X expressed as X = xjus ∈ G xjus = 1 . As each task can be either executed locally or ofﬂoaded to at most one MEC server,
a feasible ofﬂoading policy must satisfy the constraint below,

xjus ≤ 1, ∀u ∈ U .

(2)

s∈S j ∈N

Additionally, we denote Us = {u ∈ U | j∈N xjus = 1} as the set of users ofﬂoading their tasks to server s, and Uoﬀ = s∈S Us as the set of users that ofﬂoad their tasks.
Furthermore, we consider that each user and BS have a single antenna for uplink transmissions (as also considered in [14], [35]). Extension to the case where each BS uses multiple antennas for receiving uplink signals will be addressed in a future work. Denote hjus as the uplink channel gain between user u and BS s on sub-band j, which captures the effect of path-loss, shadowing, and antenna gain. Note that the user-BS association usually takes place in a large time scale (duration of an ofﬂoading session) that is much larger than the time scale of small-scale fading. Hence, similar to [18], we consider that the effect of fast-fading is averaged out during the association. Let P = {pu |0 < pu ≤ Pu , u ∈ Uoﬀ } denote the users’ transmission power, where pu [W] is the transmission power of user u when uploading its task’s input du to the BS, subject to a maximum budget Pu . Note that pu = 0, ∀u ∈/ Uoﬀ . As the users transmitting to the same BS use different sub-bands, the uplink intra-cell interference is well mitigated; still, these users suffer from the inter-cell interference. In this case, the Signalto-Interference-plus-Noise Ratio (SINR) from user u to BS s on sub-band j is given by,

γuj s =

r ∈S\{s}

pu hjus k ∈Ur xjk r pk hjk s

+

σ2

,

∀u ∈ U, s ∈ S, j ∈ N ,

(3)

where σ2 is the background noise variance and the ﬁrst term at the denominator is the accumulated intra-cell interference from all the users associated with other BSs on the same sub-band j. Since each user only transmits on one sub-band, the achievable rate [bits/s] of user u when sending data to BS s is given as,

Rus (X , P) = W log2 (1 + γus ) ,

(4)

where γus = j∈N γuj s . Moreover, let xus = j∈N xjus , ∀u ∈ U, s ∈ S. Hence, the transmission time of user u when sending its task input du in the uplink can be calculated as,

tuup

=

s∈S

xus du Rus (X , P

)

,

∀u

∈

U.

(5)

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

860

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 1, JANUARY 2019

C. MEC Computing Resources
The MEC server at each BS is able to provide computation ofﬂoading service to multiple users concurrently. The computing resources made available by each MEC server to be shared among the associating users are quantiﬁed by the computational rate fs, expressed in terms of number of CPU cycles/s. After receiving the ofﬂoaded task from a user, the server will execute the task on behalf of the user and, upon completion, will return the output result back to the user. We deﬁne the computing resource allocation policy as F = {fus |u ∈ U , s ∈ S }, in which fus [cycles/s] > 0 is the amount of computing resource that BS s allocates to task Tu ofﬂoaded from user u ∈ Us . Hence, clearly fus = 0, ∀u ∈/ Us . In addition, a feasible computing resource allocation policy must satisfy the computing resource constraint, expressed as,

fus ≤ fs , ∀s ∈ S.

(6)

u ∈U

Given the computing resource assignment {fus , s ∈ S}, the ex-

ecution time of task Tu at the MEC servers is,

tuexe

=

s∈S

xus cu fu s

, ∀u

∈

U.

(7)

D. User Ofﬂoading Utility
Given the ofﬂoading policy X , the transmission power pu , and the computing resource allocation fus ’s, the total delay experienced by user u when ofﬂoading its task is given by,

tu = tuup + tuexe =

xu s

s∈S

Ru s

du (X ,

P)

+

cu fu s

, ∀u ∈ U. (8)

The energy consumption of user u, Eu [J], due to uploading

transmission

is

calculated

as

Eu

=

pu

t

u u

p

ξu

, ∀u

∈

U,

where

ξu

is the power ampliﬁer efﬁciency of user u. Without loss of

generality, we assume that ξu = 1, ∀u ∈ U. Thus, the uplink

energy consumption of user u simpliﬁes to,

Eu

=

pu tuup

=

pu du

s∈S

Ru

xu s s (X

,

P

)

,

∀u

∈

U.

(9)

In a mobile cloud computing system, the users’ QoE is mainly

characterized by their task completion time and energy con-

sumption. In the considered scenario, the relative improvement

in task completion time and energy consumption are charac-

terized

by

t

l u

−t u

t lu

and

E

l u

−E

u

E

l u

,

respectively

[14].

Therefore,

we

deﬁne the ofﬂoading utility of user u as,

Ju =

βut

tlu

− tlu

tu

+

βue

Eul

− Eul

Eu

xus , ∀u ∈ U , (10)
s∈S

in which βut , βue ∈ [0, 1], with βut + βue = 1, ∀u ∈ U , specify user u’s preference on task completion time and energy con-
sumption, respectively. For example, a user u with short battery life can increase βue and decrease βut so as to save more energy at the expense of longer task completion time. In practice, the value of βue can be set by the mobile user through different

power saving modes; for instance, βue = 1 at “extreme power saving” mode and βue = 0 at “maximum performance” mode. Alternatively, βut can be set proportionally to the battery percentage level of the device. Note that ofﬂoading too many tasks to the MEC servers will cause excessive delay due to the limited bandwidth and computing resources at the MEC servers, and consequently degrade some users’ QoE compared to executing their tasks locally. Hence, clearly user u should not ofﬂoad its task to the MEC servers if Ju ≤ 0.
The expressions of the task completion time and energy consumption in (10) clearly show the interplay between radio access and computational aspects, which motivates a joint optimization of ofﬂoading scheduling, radio, and computing resources so as to optimize users’ ofﬂoading utility.

IV. PROBLEM FORMULATION
We formulate here the problem of joint task ofﬂoading and resource allocation, followed by the outline of our decomposition approach.

A. Joint Task Ofﬂoading and Resource Allocation Problem
For a given ofﬂoading decision X , uplink power allocation P, and computing resource allocation F, we deﬁne the system utility as the weighted-sum of all the users’ ofﬂoading utilities,

J (X , P, F ) = λu Ju ,

(11)

u ∈U

with Ju given in (10) and λu ∈ (0, 1] specifying the resource provider’s preference towards user u, ∀u ∈ U. For instance, depending on the payments offered by the users, the resource provider could prioritize users with higher revenues for ofﬂoading by increasing their corresponding preferences. Additionally, λu can also be set based on user type and criticality of the computation task. For example, computation tasks from mobile devices involved in public safety operations (e.g., devices carried by police ofﬁcers and ﬁrst responders) should be prioritized with high value of λu . We now formulate the Joint Task Ofﬂoading and Resource Allocation (JTORA) problem as a system utility maximization problem, i.e.,

max J (X , P, F )
X ,P,F
s.t. xjus ∈ {0, 1} , ∀u ∈ U , s ∈ S, j ∈ N ,
xjus ≤ 1, ∀u ∈ U ,
s∈S j ∈N

(12a) (12b) (12c)

xjus ≤ 1, ∀s ∈ S, j ∈ N ,
u ∈U
0 < pu ≤ Pu , ∀u ∈ Uoﬀ ,
fus > 0, ∀u ∈ Us , s ∈ S,

(12d)
(12e) (12f)

u∈U fus ≤ fs , ∀s ∈ S.

(12g)

The constraints in the formulation above can be explained as

follows: constraints (12b) and (12c) imply that each task can be either executed locally or ofﬂoaded to at most one server on

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

TRAN AND POMPILI: JOINT TASK OFFLOADING AND RESOURCE ALLOCATION FOR MULTI-SERVER MEC NETWORKS

861

one sub-band; constraint (12d) implies that each BS can serve at most one user per sub-band; constraint (12e) speciﬁes the transmission power budget of each user; ﬁnally, constraints (12f) and (12g) state that each MEC server must allocate a positive computing resource to each user associated with it and that the total computing resources allocated to all the associated users must not excess the server’s computing capacity. The JTORA problem in (12) is a Mixed Integer Nonlinear Program (MINLP) and ﬁnding the optimal solution usually requires exponential time complexity [36]. Given the large number of variables that scale linearly with the number of users, MEC servers, and sub-bands, our goal is to design a low-complexity, suboptimal solution that achieves competitive performance while being practical to implement.

B. Problem Decomposition
By exploiting the structure of the objective function and constraints in the formulation of JTORA problem in (12), we observe that by temporarily ﬁxing the binary variables {xus }, problem (12) can be decomposed into multiple subproblems with separated objective and constraints. Leveraging this characteristic and motivated by the approach in [37], we can employ the Tammer decomposition method [38] to transform the original problem with high complexity into an equivalent master problem and a set of subproblems with lower complexity. Firstly, we rewrite the JTORA problem in (12) as,

max max J (X , P, F )

X

P,F

(13a)

s.t. (12b)–(12g).

(13b)

Note that the constraints on the ofﬂoading decision, X , in (12b), (12c), (12d), and the RA policies, P, F, in (12e), (12f), (12g), are decoupled from each other; therefore, solving the problem in (13) is equivalent to solving the following Task Ofﬂoading (TO) problem,

max J∗ (X )
X

(14a)

s.t. (12b), (12c), (12d),

(14b)

in which J∗ (X ) is the optimal-value function corresponding to the RA problem, written as,

J∗ (X ) = max J (X , P, F )
P,F

(15a)

s.t. (12e), (12f), (12g),

(15b)

Note that the decomposition from problem (12) to problems (14) and (15) does not change the optimality of the solution [38]. In the next section, we will present our solutions to both the RA problem and the TO problem so as to ﬁnally obtain the solution to the original JTORA problem.

V. LOW-COMPLEXITY ALGORITHM FOR JOINT TASK OFFLOADING AND RESOURCE ALLOCATION
We present now our low-complexity approach to solve the JTORA problem by solving ﬁrst the RA problem in (15) and

then using its solution to derive the solution of the TO problem in (14).
Firstly, given a feasible task ofﬂoading decision X that satisﬁes constraints (12b), (12c), and (12d), and using the expression of Ju in (10), the objective function in (15a) can be rewritten as,

J (X , P, F) =

λu βut + βue − V (X , P, F ) ,

s∈S u ∈Us

(16)

where

V (X , P, F ) =

λu

s∈S u ∈Us

βut tu tlu

+

βue Eu Eul

.

(17)

We observe that the ﬁrst term on the right hand side (RHS) of (16) is constant for a particular ofﬂoading decision, while V (X , P, F ) can be seen as the total ofﬂoading overheads of all ofﬂoaded users. Hence, we can recast (15) as the problem of minimizing the total ofﬂoading overheads, i.e.,

min V (X , P, F )
P,F

(18a)

s.t. (12e), (12f), (12g).

(18b)

Furthermore, from (8), (9), and (17), we have,

V (X , P, F ) =

φu + ψu pu +

ηu ,

s∈S u∈Us log2 (1 + γus ) s∈S u∈Us fus

(19)

in which, for simplicity, φu

=

λu

β

t u

du

t

l u

W

, ψu

=

λu

β

e u

du

E

l u

W

, and ηu

=

λu βut ful . Notice from (18b) and (19) that the problem in (18) has

a separable structure, i.e., the objectives and constraints corre-

sponding to the power allocation pu ’s and computing resource

allocation fus ’s can be decoupled from each other. Leveraging

this property, we can decouple problem (18) into two indepen-

dent problems, namely the Uplink Power Allocation (UPA) and

the Computing Resource Allocation (CRA), and address them

separately, as described in the following sections.

A. Uplink Power Allocation (UPA)

The UPA problem is decoupled from problem (18) by considering the ﬁrst term on the RHS of (19) as the objective function. Speciﬁcally, the UPA problem is expressed as,

min

φu + ψu pu

P s∈S u∈Us log2 (1 + γus )

s.t. 0 < pu ≤ Pu , ∀u ∈ U .

(20a) (20b)

Problem (20) is non-convex and difﬁcult to solve because the uplink SINR γuj s corresponding to user u ∈ Us depends on the transmit power of the other users associated with other
BSs on the same sub-band j through the inter-cell interference Iuj s = w ∈S\{s} k∈Uw xjks pk hjks , as seen in (3). Our approach is to ﬁnd an approximation for Iuj s and thus for γuj s such that problem (20) can be decomposed into sub-problems that,
in turn, can be efﬁciently solved. The optimal uplink power allocation P∗ still generates small objective value for (20).

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

862

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 1, JANUARY 2019

Suppose each BS s ∈ S calculates its uplink power allocation independently, i.e., without mutual cooperation, and informs
its associated users about the uplink transmit power; then, an achievable upper bound for Iuj s is given by,

I˜uj s =Δ

xjks Pk hjks , ∀u ∈ Us , s ∈ S, j ∈ N . (21)

w ∈S\{s} k ∈Uw

Similar to [39], we argue that I˜uj s is a good estimate of Iuj s since our ofﬂoading decision X is geared towards choosing the appropriate user-BS associations so as that I˜uj s be small in the ﬁrst place. This means that a small error in Iuj s should not lead to large bias in γuj s [39].
By replacing Iuj s with I˜uj s , we get the approximation for the
uplink SINR for user u uploading to BS s on sub-band j as,

γ˜uj s

=

pu I˜uj s

hju s + σ2

,

∀u

∈

Us , s

∈

S, j

∈

N.

(22)

Let ϑus =

j ∈N

hjus /(I˜uj s

+ σ2) and Γs

(pu )

=

. φu + ψ u pu
log2(1+ ϑ u s pu )

The objective function in (20a) can now be approximated

by s∈S u∈Us Γs (pu ). With this position, it can be seen that the objective function and the constraint corresponding to

each user’s transmit power is now decoupled from each other.

Therefore, the UPA problem in (20) can be approximated by

s∈S |Us | sub-problems, each optimizing the transmit power of a user u ∈ Us, s ∈ S, and can be written as,

min Γs (pu )
u ∈Us
s.t. 0 < pu ≤ Pu .

(23a) (23b)

Problem (23) is still non-convex as the second-order derivative of the objective function with respect to (w.r.t) pu , i.e., Γs (pu ), is not always positive. However, we can employ quasiconvex optimization technique to address problem (23) based on the following lemma.
Lemma 1: Γs (pu ) is strictly quasi-convex in the domain deﬁned in (23b).
Proof: See Appendix A. In general, a quasi-convex problem can be solved using the bisection method, which solves a convex feasibility problem in each iteration [40]. However, the popular interior cutting plane method for solving a convex feasibility problem requires O n2/ 2 iterations, where n is the dimension of the problem. We now propose to further reduce the complexity of the bisection method. Firstly, notice that a quasi-convex function achieves a local optimum at the diminishing point of the ﬁrst-order derivative, and that any local optimum of a strictly quasi-convex function is the global optimum [41]. Therefore, based on Lemma 1, we can conﬁrm that the optimal solution p∗u of problem (23) either lies at the constraint border, i.e., p∗u = Pu or satisﬁes Γs (p∗u ) = 0. It can be veriﬁed that Γs (pu ) = 0 when,

Ωs

(pu )

=

ψu log2 (1 + ϑus pu )

−

ϑus (φu + ψu pu ) (1 + ϑus pu ) ln 2

=

0.

(24)

Algorithm 1: Bisection Method for Uplink Power Alloca-

tion.

1: Calculate Ωs (Pu ) using (24)

2: if Ωs (Pu ) ≤ 0 then

3:

p∗u = Pu

4: else

5: Set optimality tolerance > 0

6: Initialize pu = 0 and pu = Pu

7: repeat

8:

Set p∗u = (pu + pu ) /2

9:

if Ωs (p∗u ) ≤ 0 then

10:

Set pu = p∗u

11:

else

12:

Set pu = p∗u

13:

end if

14: until pu − pu ≤ ξ 15: Set p∗u = (pu + pu ) /2 16: end if

Moreover, we have, Ωs (pu )

=

ϑ

2 u

s

(φu

+ψu

pu

)

(1+ ϑ u s pu )2 ln 2

>

0, and Ωs (0)

=

−ϑu s φu
ln 2

< 0. This implies that Ωs (pu ) is a monotonically in-

creasing function and is negative at the starting point pu = 0.

Therefore, we can design a low-complexity bisection method

that evaluates Ωs (pu ) in each iteration instead of solving a convex feasibility problem, so as to obtain the optimal solution p∗u ,
as presented in Algorithm 1.

In Algorithm 1, if Ωs (Pu ) > 0, the algorithm will terminate

in exactly log2 (Pu /ξ) iterations, where ξ is the convergence threshold in line 14. Let P∗ = {p∗u , u ∈ U } denote the optimal
uplink transmit power policy for a given task ofﬂoading policy X . In addition, we denote now as Γ (X , P∗) the objective value of problem (20) corresponding to P∗.

B. Computing Resource Allocation (CRA)
The CRA problem optimizes the second term on the RHS of (19) and is expressed as follows,

min

ηu /fus

F

s∈S u ∈Us

(25a)

s.t.

fus ≤ fs , ∀s ∈ S,

u ∈U

(25b)

fus > 0, ∀u ∈ Us , s ∈ S.

(25c)

Notice that the constraints in (25b) and (25c) are convex. Denote the objective function in (25a) as Λ (X , F); by calculating the second-order derivatives of Λ (X , F ) w.r.t. fus , we have,

∂2Λ (X , F ) ∂fu2s

=

2ηu fu3s

> 0, ∀s ∈ S, u ∈ Us ,

(26a)

∂2Λ (X , F ) = 0, ∀ (u, s) = (v, w) . ∂fus ∂fv w

(26b)

It can be seen that the Hessian matrix of the objective function in (25a) is diagonal with the strictly positive elements, thus it is positive-deﬁnite. Hence, (25) is a convex optimization

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

TRAN AND POMPILI: JOINT TASK OFFLOADING AND RESOURCE ALLOCATION FOR MULTI-SERVER MEC NETWORKS

863

problem and can be solved using Karush-Kuhn-Tucker (KKT)

conditions. We have the following Lemma.

Lemma 2: The optimal computing resource allocation fu∗s

for problem (25) and the corresponding optimal objective func-

tion Λ (X , F ∗) are given, respectively, as,

√

fu∗s =

fs
u ∈Us

η√u ηu

,

∀s

∈

S,

u

∈

Us

,

(27)

2

Λ (X , F ∗) =

1

s∈S fs

√ ηu
u ∈Us

.

(28)

Proof: See Appendix B.

C. Joint Task Ofﬂoading Scheduling and Resource Allocation

In the previous sections, for a given task ofﬂoading decision X , we obtained the solutions for the radio and computing resources allocation. In particular, according to (15), (16), (19), and (28), we have,

J ∗ (X ) =

λu βut + βue − Γ (X , P∗) − Λ (X , F ∗) ,

s∈S u ∈Us

(29)

where P∗ can be obtained through Algorithm 1 and Λ (X , F ∗) can be calculated using the closed-form expression in (28). Now, using (29), we can rewrite the TO problem in (14) as,

max
X

λu βut + βue − Γ (X , P∗) − Λ (X , F ∗)

s∈S u ∈Us

(30a)

s.t. xjus ∈ {0, 1} , ∀u ∈ U , s ∈ S, j ∈ N ,

(30b)

xjus ≤ 1, ∀u ∈ U ,
s∈S j ∈N

(30c)

xjus ≤ 1, ∀s ∈ S, j ∈ N .
u ∈U

(30d)

Problem (30) consists in maximizing a set function J∗ (X )

w.r.t X over the ground set G deﬁned by (30b), and the constraints in (30c) and (30d) deﬁne two matroids over G.1

Given the combinatorial nature of the TO problem, solving

for an optimal solution in polynomial time is extremely chal-

lenging. One straightforward approach to solve problem (30) is

to use exhaustive search method over all possible task ofﬂoading

decisions. However, the total number of candidate task ofﬂoading decisions would be 2n where n = S × U × N . Hence, the

exhaustive search method is clearly impractical.

To overcome the aforementioned drawback, we propose a

low-complexity heuristic algorithm that can ﬁnd a local op-

timum to problem (30) in polynomial time. Speciﬁcally, our

algorithm starts with an empty set X = ∅ and repeatedly per-

forms one of the local operations, namely the remove operation

or the exchange operation, as described in Routine 1, if it improves the set value J∗(X ). As we are dealing with two matroid

constraints, the exchange operation involves adding one element

1For detailed deﬁnition of matroid constraint on set function, refer to [42].

Routine 1: Remove and Exchange Operations.

remove X , xjus 1: Set X ← X \ xjus 2: Output: X

exchange X , xjus 3: for w ∈ S, i ∈ N do

to comply with (30c)

4: X ← X \ xiuw 5: end for

6: for v ∈ U do

to comply with (30d)

7: X ← X \ xjvs 8: end for

9: Set X ← X ∪ xjus 10: Output: X

Algorithm 2: Heuristic Task Ofﬂoading Scheduling.

1: Initialize: X = ∅

2: Find xikw = arg max J ∗ xjus

x

j u

s

,

j

∈N

,

s

∈S

,u

∈U

3: Set X ← xikw

4: if there exists xjus ∈ X such that J ∗ remove X , xjus

>

1

+

1 p(n,

)

J∗ (X ) then

5: Set X ← remove X , xjus 6: Go back to step 4

7: else if there exists xjus ∈ G\X such that J∗ exchange

X , xjus

>

1+

1 p(n,

)

J∗ (X ) then

8: Set X ← exchange X , xjus 9: Go back to step 4

10: end if

11: Output: X

from outside of the current set and dropping up to 2 elements

from the set, so as to comply with the constraints. In summary,

our proposed heuristic algorithm for task ofﬂoading scheduling

is presented in Algorithm 2.

Remark 1: (Complexity Analysis of Algorithm 2) In

Algorithm 2, p(n, ) is a suitably chosen polynomial in n

and 1/ . Let IN T be the initial value of problem (30) ob-

tained at step 3 in Algorithm 2, and OP T be the optimal

value of the problem. The algorithm insists that each local

step increases the value of the current solution by a factor

of at least

1+

1 p(n,

)

. Let t be the number of local steps

t

taken by Algorithm 2. It is clear that

1

+

1 p(n,

)

≤

OP T INT

;

and thus, t = O

p (n,

)

log

OP T INT

. Note that the number of

queries needed to calculate the value of the objective function

in each iteration is at most n. In each query, one needs to solve

an UPA problem and a CRA problem. Since the CRA prob-

lem has a closed-form solution, the running time complexity in

each query mainly comes from solving the UPA problem, which

takes log2 (Pu /ξ) iterations. Therefore, the running time of

Algorithm 2 is O

log2 (Pu /ξ)

p (n,

)

log

OP T INT

which is

polynomial in n and 1/ . Furthermore, since the queries in

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

864

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 1, JANUARY 2019

each iteration can be computed independently, the runtime can
be greatly reduced by utilizing parallel computing. Remark 2: (JTORA solution) Let X ∗ be the output of
Algorithm 2. The corresponding solutions P∗ for the uplink power allocation and F∗ for computing resource sharing can
be obtained using Algorithm 1 and the closed-form expression in (27), respectively, by setting X = X ∗. Thus, the local optimal solution for the JTORA problem is (X ∗, P∗, F ∗). While
characterizing the degree of suboptimality of the proposed so-
lution is a non-trivial task—mostly due to the combinatorial
nature of the task ofﬂoading decision and the nonconvexity of
the original UPA problem—in the next section we will show via
numerical results that our heuristic algorithm performs closely
to the optimal solution using exhaustive search method.

VI. PERFORMANCE EVALUATION

Simulation results are presented to evaluate the performance

of our proposed heuristic joint task ofﬂoading scheduling and

resource allocation strategy, referred to as hJTORA. We con-

sider a multi-cell cellular system consisting of multiple hexag-

onal cells with a BS in the center of each cell. The neighboring

BSs are set 1 km apart from each other. We assume that both

the users and BSs use a single antenna for uplink transmis-

sion and reception, respectively. The uplink channel gains are

generated using a distance-dependent path-loss model given as

L [dB] = 140.7 + 36.7log10d[km] [43], and the log-normal shadowing standard deviation is set to 8 dB. In most simulations, if

not stated otherwise, we consider S = 7 cells and the users’

maximum transmit power set to Pu = 20 dBm. In addition, the system bandwidth is set to B = 20 MHz and the background

noise variance is assumed to be σ2 = −100 dBm.

In terms of computing resources, we assume the CPU capabil-

ity of each MEC server and of each user to be fs = 20 GHz and ful = 1 GHz, respectively. According to the realistic measurements in [32], we set the energy coefﬁcient κ as 5 × 10−27. For

computation task, we consider the face detection and recognition

application for airport security and surveillance [4], which can

highly beneﬁt from the collaboration between mobile devices

and MEC platform. Unless otherwise stated, we choose the de-

fault task input size as du = 420 KB (following [4], [10]), and the preference parameters as βut = 0.2, βue = 0.8, and λu = 1, ∀u ∈ U. In addition, the users are dropped in random locations,

with uniform distribution, within the coverage area of the net-

work, and the number of sub-bands N is set equal to the number

of users per cell. We compare the system utility performance of

ourrprEoxphoasuesdtihvJeT: OThRiAs isstarabterugtye-afgoaricnestmthetehfoodlltohwatinﬁgnbdasstehleinoeps-.

timal ofﬂoading scheduling solution via exhaustive search

over 2n possible decisions; since the computational com-

plexity of this method is very high, we only evaluate its

r

performance in a small network setting. Greedy Ofﬂoading and Joint Resource

Allocation

(GO-

JRA): All tasks (up to the maximum number that can be

admitted by the BSs) are ofﬂoaded, as in [13]. In each

cell, ofﬂoading users are greedily assigned to sub-bands

that have the highest channel gains until all users are

Fig. 2. Comparison of average system utility.

admitted or all the sub-bands are occupied; we then apply

joint joint resource allocation across the BSs as proposed

r

in Section V-A, B. Independent Ofﬂoading

and

Joint

Resource

Alloca-

tion (IOJRA): Each user is randomly assigned a sub-band

from its home BS, then the users independently make

ofﬂoading decision [27]; joint resource allocation is em-

r

ployed. Distributed Ofﬂoading and Resource Allocation (DORA):

Each BS independently makes joint task ofﬂoading deci-

sions and resource allocation for users within its cell [14].

A. Suboptimality and Convergence Behavior of Algorithm 2
Firstly, to characterize the suboptimality of our proposed hJTORA solution obtained using Algorithm 2, we compare its performance with the optimal solution obtained by the Exhaustive method, and then with the three other described baselines. Since the Exhaustive method searches over all possible ofﬂoading scheduling decisions, its runtime is extremely long for a large number of variables; hence, we carry out the comparison in a small network setting with U = 6 users uniformly placed in the area covered by S = 4 cells, each having N = 2 sub-bands. We randomly generate 500 large-scale fading (shadowing) realizations and the average system utilities, with 95% Conﬁdence Interval (CI), of different schemes are reported in Fig. 2 when we set cu = 1000, 1500, and 2000 Megacycles, respectively. It can be seen that the proposed hJTORA algorithm performs very closely to that of the optimal Exhaustive algorithm while it signiﬁcantly outperforms the other baselines. We also observe that the performance of all schemes increases with the task workload. In all cases, hJTORA achieves an average system utility within 1% of that of the Exhaustive algorithm, while providing average gains of 31%, 38%, and 91% over DORA, GOJRA, and IOJRA schemes, respectively.
In Table II, we report the average runtime per simulation drop of different algorithms, running on a Windows 7 desktop PC with 3.6 GHz quad-core CPU and 16 GB RAM. It can be seen that the Exhaustive method takes very long time, about 100× longer than the hJTORA algorithm for such a small network. The DORA algorithm runs slightly faster than hJTORA, while IOJRA and GOJRA requires the lowest runtimes. Furthermore, in order to evaluate the runtime of Algorithm 2 when more BSs cooperate with each other, we consider three deployment

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

TRAN AND POMPILI: JOINT TASK OFFLOADING AND RESOURCE ALLOCATION FOR MULTI-SERVER MEC NETWORKS

865

TABLE II RUNTIME COMPARISON
TABLE III RUNTIME OF ALGORITHM 2 VERSUS NETWORK SIZE

We now evaluate the system utility performance against different number of users wishing to ofﬂoad their tasks, as shown in Fig. 4(a, b, c). In particular, we vary the number of users per cell from 1 to 10 and perform the comparison in three scenarios with different task workloads. Note that the number of sub-bands N is set equal to the number of users per cell, thus the bandwidth allocated for each user decreases when there are more users in the system. Observe from Fig. 4(a, b, c) that hJTORA always performs the best, and that the performance of all schemes signiﬁcantly increases when the tasks’ workload increases. This is because when the tasks require more computation resources, the users will beneﬁt more from ofﬂoading their tasks to the MEC servers. We also observe that, when the number of users is small, the system utility increases with the number of users; however, when the number of users exceeds some thresholds, the system utility starts to decrease. This is because, when there are many users competing for radio and computing resources for ofﬂoading their tasks, the overheads of sending the tasks and executing them at the MEC servers will be higher, thus degrading the ofﬂoading utility.

Fig. 3. (a) Average number of iterations versus number of users. (b) Average number of handovers per ofﬂoading decision versus number of users; cu = 2000 Megacycles.
scenarios: denser, very dense, and ultra dense networks for which the BS spacing (distance between two neighboring BSs) are set to 237 m, 209 m, and 112 m according to [44]. The number of BSs and users are set as in Table III, and the average runtime of Algorithm 2 (with 95% CI) are reported therein. We can see that the runtime increases considerably when there are many BSs cooperating with each other (e.g., 16 or 25). Therefore, in order to make the proposed solution practical, it is advisable to divide the network region into groups of cooperating BSs, each with fewer than 10 BSs.
B. Effect of Number of Users
In Fig. 3(a), we evaluate the convergence behavior of Algorithm 2 against different number of users by showing the average number of iterations with 95% CI. It can be seen that with a small and moderate number of users the number of iterations grows linearly (but less than) the number of users and the variation across different simulation runs is small. When the number of users is high, e.g., greater than 60, there is greater variation in the number of iterations but the growing rate of the average number of iteration gets lower. This shows that Algorithm 2 can scale well with the number of users. In Fig. 3(b), we plot the average number of handovers per simulation drop. While it can be seen that the average number of handovers (over 500 drops) varies with different number of users, it does not appear to follow a consistent trend.

C. Effect of Task Proﬁle
Here, we evaluate the system utility performance w.r.t. the computation tasks’ proﬁles in terms of input size du’s and workload cu ’s. We consider two conﬁguration of the MEC servers: (i) homogeneous servers—where all servers have the same CPU speed of 20 GHz, and (ii) heterogeneous servers— where the servers’ CPU speeds are randomly selected from {10, 20, 30} GHz. The average system utility of the four competing schemes are plotted in Fig. 5(a, b) with different values of cu ; and in Fig. 6(a, b) with different values of du . It can be seen that the average system utilities of all schemes increase with the task workload and decrease with the task input size. This implies that the tasks with small input sizes and high workloads beneﬁt more from ofﬂoading than those with large input sizes and low workloads do. Moreover, we observe that the performance gains of the proposed hJTORA scheme over the baselines also follow the similar trend, i.e., they increase with task workloads and decrease with task input size. Notice that the difference in performance of all schemes in the homogeneous server setting versus in the heterogeneous server setting is marginal.
D. Effect of Users’ Preferences
Figure 7(a, b) show the average time and energy consumption of all the users when we vary the users’ preference to time, βut ’s, from 0.1 to 0.9 while changing the users’ preference to energy accordingly as βue = 1 − βut , ∀u ∈ U . It can be seen that the average time consumption decreases when βut increases, at the cost of higher energy consumption. In addition, the users experience a larger average time and energy consumption when there are more users in the system. This is because when there are more users competing for the limited resources, the chance that a user can beneﬁt from ofﬂoading its task is lower.

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

866

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 1, JANUARY 2019

Fig. 4. Comparison of average system utility against different number of users, evaluated on three different task workloads. (a) cu = 1000 Megacycles. (b) cu = 1500 Megacycles. (c) cu = 2000 Megacycles, ∀u ∈ U.

Fig. 5. Comparison of average system utility against different task workloads, with U = 28 and du = 420 KB.

Fig. 7. (a) Average time consumption and (b) energy consumption of all users obtained using hJTORA; with cu = 2000 Megacycles, ∀u ∈ U.

Fig. 6. Comparison of average system utility against different task input size, with U = 28 and cu = 3000 Megacycles.

E. Effect of Inter-Cell Interference Approximation
To test the effect of the approximation to model the inter-cell interference as in (21) in Section V-A, we compare the results of the hJTORA solution to calculate the system utility using the approximated expression versus using the exact expression of the inter-cell interference. Fig. 8 shows the system utility when the users’ maximum transmit power Pu ’s vary between 0 and 35 dBm. It can be seen that the performance obtained using the approximated interference is almost identical to that of the exact interference when Pu is below 25 dBm, while an increasing gap appears when Pu > 25 dBm. However, as speciﬁed in the LTE standard, 3GPP TS36.101 section 6.2.3,2 the maximum UE transmit power is 23 dBm; hence, we can argue that our approximation can work well in practical systems.
2Refer to: 3GPP TS36.101, V14.3.0, Mar. 2017

Fig. 8. Average system utility obtained by hJTORA solution with exact expression and approximation of the inter-cell interference; with cu = 1000 Megacycles, ∀u ∈ U.
VII. CONCLUSIONS
We proposed a holistic strategy for a joint task ofﬂoading and resource allocation in a multi-cell Mobile-Edge Computing (MEC) network. The underlying optimization problem was formulated as a Mixed-Integer Non-linear Program (MINLP), which is very difﬁcult to solve to optimal. Our approach decomposes the original problem into a Resource Allocation (RA) problem with ﬁxed task ofﬂoading decision and a Task Ofﬂoading (TO) problem that optimizes the optimal-value function corresponding to the RA problem. We further decouple the RA problem into two independent subproblems, namely the

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

TRAN AND POMPILI: JOINT TASK OFFLOADING AND RESOURCE ALLOCATION FOR MULTI-SERVER MEC NETWORKS

867

uplink power allocation and the computing resource allocation, and address them using quasi-convex and convex optimization techniques, respectively. Finally, we proposed a novel heuristic algorithm that achieves a suboptimal solution for the TO problem in polynomial time. Simulation results showed that our heuristic algorithm performs closely to the optimal solution and signiﬁcantly improves the average system ofﬂoading utility over traditional approaches.
To further reduce the runtime of the proposed hJTORA algorithm, two approaches can be exploited: (i) parallel computing—since the queries in each iteration of Algorithm 2 are independent, they can be run in parallel to reduce the runtime in each iteration; (ii) pre-disassociation—for each user, the task ofﬂoading variables corresponding to the BSs that are far away can be set to zeros, thus reducing the search space of the task ofﬂoading decision before running Algorithm 2. In addition, as future work, it is worth characterizing the approximation ratio of the proposed algorithm with regard to the approximation of the interference term used in the uplink power allocation problem. Furthermore, it is also desirable to design a mistreatment-free solution where each user cannot improve its own performance by not following the network-wide solution.

APPENDIX A

Proof for Lemma 1: Firstly, it is straightforward to verify that Γs (pu ) is twice differentiable on R. We now check the second-order condition of a strictly quasi-convex function,
which requires that a point p satisfying Γs (p) = 0 also satisﬁes Γs (p) > 0 [40]. The ﬁrst-order and second-order derivatives of Γs (pu ) can be calculated, respectively, as,

Γs (pu )

=

ψu Cu

(pu )

−

ϑu s Du (pu ) Au (pu ) ln 2

Cu2 (pu )

,

(31)

Γs

(pu )

=

ϑu s

[Gu s

(pu ) Cus (pu ) + 2ϑus Dus A2us (pu ) Cu3s (pu ) ln 2

(pu ) / ln 2] ,

(32)

in which,

Aus (pu ) = 1 + ϑus pu ,

(33a)

Cus (pu ) = log2 (1 + ϑus pu ) ,

(33b)

Dus (pu ) = φu + ψu pu ,

(33c)

Gus (pu ) = ϑus Dus (pu ) − 2ψu Aus (pu ) .

(33d)

Suppose that p¯u ∈ (0, Pu ]; to satisfy Γs (p¯u ) = 0, we need,

Ωs

(p¯u )

=

ψu log2

(1

+

ϑus p¯u )

−

ϑus (φu + ψu p¯u ) (1 + ϑus p¯u ) ln 2

=

0.

(34)

By substituting p¯u into (32), we obtain,

Γs

(p¯u )

=

A2u s

ϑ3u (p¯u )

s Du2 Cu3s

s (p¯u (p¯u )

) ψu

ln2

2

.

(35)

It can be easily veriﬁed that both ϑus and Du2s (p¯u ) are strictly positive ∀p¯u ∈ (0, Pu ]. Hence, Γs (p¯u ) > 0, which conﬁrms
that Γs (pu ) is a strictly quasi-convex function in (0, Pu ].

APPENDIX B
Proof for Lemma 2: The Lagrangian of problem (25) can be calculated as,

L (Λ (X , F) , ν)

=

s∈S

u ∈Us

ηu fu s

+

s∈S

νs

fus − fs ,
u ∈U
(36)

where ν = [v1, ...vS ] is the vector of Lagrangian multipliers. Taking the derivatives of the Lagrangian w.r.t. fus ’s, we get,

∂L (Λ (X , F) , ν) ∂ fu s

=

−

ηu fu2s

+ νs , ∀s

∈

S, u

∈

Us .

(37)

By equating the gradient of the Lagrangian to zero and solving for fus , the optimal computing resource allocation solution for problem (25) is obtained as,

fu∗s = ηu /νs∗, ∀s ∈ S, u ∈ Us ,

(38)

in which νs∗ > 0 is the constant satisfying,

fu∗s = fs , ∀s ∈ S.

(39)

u ∈U

By substituting (38) into (39) and noting that fu∗s = 0, ∀u ∈/ Us , we obtain the optimal Lagrangian multiplier νs∗ as,

2

νs∗ =

1√ fs u∈Us ηu

, ∀s ∈ S

(40)

Finally, by substituting (40) into (38), we can obtain the optimal

solution to problem (25) in closed form as,

fu∗s =

fs √η√u u ∈Us ηu

,

∀s

∈

S,

u

∈

Us ,

(41)

and the optimal objective function of problem (25) is then calculated as,

2

Λ (X , F ∗) =

1

s∈S fs

√ ηu
u ∈Us

.

(42)

REFERENCES
[1] Y. C. Hu, M. Patel, D. Sabella, N. Sprecher, and V. Young, “Mobile edge computing—A key technology towards 5G,” ETSI White Paper, vol. 11, 2015.
[2] T. X. Tran, A. Hajisami, P. Pandey, and D. Pompili, “Collaborative mobile edge computing in 5G networks: New paradigms, scenarios, and challenges,” IEEE Commun. Mag., vol. 55, no. 4, pp. 54–61, Apr. 2017.
[3] T. X. Tran, M.-P. Hosseini, and D. Pompili, “Mobile edge computing: Recent efforts and ﬁve key research directions,” IEEE COMSOC MMTC Commun.-Frontiers, vol. 12, no. 4, pp. 29–33, 2017.
[4] T. Soyata, R. Muraleedharan, C. Funai, M. Kwon, and W. Heinzelman, “Cloud-vision: Real-time face recognition using a mobile-cloudlet-cloud acceleration architecture,” in Proc. IEEE Symp. Comput. Commun., 2012, pp. 59–66.
[5] K. Bilal, A. Erbad, and M. Hefeeda, “Crowdsourced multi-view live video streaming using cloud computing,” IEEE Access, vol. 5, pp. 12635–12647, 2017.
[6] M.-P. Hosseini, T. X. Tran, D. Pompili, K. Elisevich, and H. SoltanianZadeh, “Deep learning with edge computing for localization of epileptogenicity using multimodal rs-fMRI and EEG big data,” in Proc. IEEE Int. Conf. Autonomic Comput., 2017, pp. 83–92.

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

868

IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 1, JANUARY 2019

[7] L. Yang, J. Cao, H. Cheng, and Y. Ji, “Multi-user computation partitioning for latency sensitive mobile cloud applications,” IEEE Trans. Comput., vol. 64, no. 8, pp. 2253–2266, Aug. 2015.
[8] V. Cardellini et al., “A game-theoretic approach to computation ofﬂoading in mobile cloud computing,” Math. Program., vol. 157, no. 2, pp. 421–449, 2016.
[9] X. Chen, “Decentralized computation ofﬂoading game for mobile cloud computing,” IEEE Trans. Parallel Distrib. Syst., vol. 26, no. 4, pp. 974– 983, Apr. 2015.
[10] X. Chen, L. Jiao, W. Li, and X. Fu, “Efﬁcient multi-user computation ofﬂoading for mobile-edge cloud computing,” IEEE/ACM Trans. Netw., vol. 24, no. 5, pp. 2795–2808, Oct. 2016.
[11] L. Yang, J. Cao, Y. Yuan, T. Li, A. Han, and A. Chan, “A framework for partitioning and execution of data stream applications in mobile cloud computing,” ACM SIGMETRICS Perform. Eval. Rev., vol. 40, no. 4, pp. 23–32, 2013.
[12] M. R. Rahimi, N. Venkatasubramanian, and A. V. Vasilakos, “Music: Mobility-aware optimal service allocation in mobile cloud computing,” in Proc. IEEE Int. Conf. Cloud Comput., 2013, pp. 75–82.
[13] S. Sardellitti, G. Scutari, and S. Barbarossa, “Joint optimization of radio and computational resources for multicell mobile-edge computing,” IEEE Trans. Signal Inf. Process. Over Netw., vol. 1, no. 2, pp. 89–103, Jun. 2015.
[14] X. Lyu, H. Tian, P. Zhang, and C. Sengul, “Multi-user joint task ofﬂoading and resources optimization in proximate clouds,” IEEE Trans. Veh. Technol., vol. 66, no. 4, pp. 3435–3447, Apr. 2017.
[15] X. Ge, S. Tu, G. Mao, C.-X. Wang, and T. Han, “5G ultra-dense cellular networks,” IEEE Wireless Commun., vol. 23, no. 1, pp. 72–79, Feb. 2016.
[16] D. Lee et al., “Coordinated multipoint transmission and reception in LTEadvanced: Deployment scenarios and operational challenges,” IEEE Commun. Mag., vol. 50, no. 2, pp. 148–155, Feb. 2012.
[17] T. X. Tran and D. Pompili, “Dynamic radio cooperation for user-centric cloud-RAN with computing resource sharing,” IEEE Trans. Wireless Commun., vol. 16, no. 4, pp. 2379–2393, Apr. 2017.
[18] Q. Ye, B. Rong, Y. Chen, M. Al-Shalash, C. Caramanis, and J. G. Andrews, “User association for load balancing in heterogeneous cellular networks,” IEEE Trans. Wireless Commun., vol. 12, no. 6, pp. 2706–2716, Jun. 2013.
[19] Intel and Nokia Siemens Networks, “Increasing mobile operators’ value proposition with edge computing,” Technical Brief, 2013.
[20] Saguna and Intel, “Using mobile edge computing to improve mobile network performance and proﬁtability,” White paper, 2016.
[21] T. X. Tran, P. Pandey, A. Hajisami, and D. Pompili, “Collaborative multibitrate video caching and processing in mobile-edge computing networks,” in Proc. IEEE/IFIP Conf. Wireless On-Demand Netw. Syst. Services, Feb. 2017, pp. 165–172.
[22] J. O. Fajardo, I. Taboada, and F. Liberal, “Improving content delivery efﬁciency through multi-layer mobile edge adaptation,” IEEE Netw., vol. 29, no. 6, pp. 40–46, Nov./Dec. 2015.
[23] Nokia, “LTE and Car2x: Connected cars on the way to 5G,” 2016. [Online]: http://www.cambridgewireless.co.uk/Presentation/MB06.04.16Nokia-UwePutzschler.pdf
[24] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey on mobile edge computing: The communication perspective,” IEEE Commun. Surv. Tuts., vol. 19, no. 4, pp. 2322–2358, Sep.–Dec. 2017.
[25] Z. Sanaei, S. Abolfazli, A. Gani, and R. Buyya, “Heterogeneity in mobile cloud computing: Taxonomy and open challenges,” IEEE Commun. Surv. Tuts., vol. 16, no. 1, pp. 369–392, Jan.–Apr. 2014.
[26] W. Zhang, Y. Wen, and D. O. Wu, “Energy-efﬁcient scheduling policy for collaborative execution in mobile cloud computing,” in Proc. IEEE Int. Conf. Comput. Commun., 2013, pp. 190–194.
[27] W. Zhang, Y. Wen, and D. O. Wu, “Collaborative task execution in mobile cloud computing under a stochastic wireless channel,” IEEE Trans. Wireless Commun., vol. 14, no. 1, pp. 81–93, Jan. 2015.
[28] Z. Cheng, P. Li, J. Wang, and S. Guo, “Just-in-time code ofﬂoading for wearable computing,” IEEE Trans. Emerg. Topics Comput., vol. 3, no. 1, pp. 74–83, Mar. 2015.
[29] Y. Mao, J. Zhang, and K. B. Letaief, “Dynamic computation ofﬂoading for mobile-edge computing with energy harvesting devices,” IEEE J. Sel. Areas Commun., vol. 34, no. 12, pp. 3590–3605, Dec. 2016.
[30] X. Chen, L. Pu, L. Gao, W. Wu, and D. Wu, “Exploiting massive D2D collaboration for energy-efﬁcient mobile edge computing,” IEEE Wireless Commun., vol. 24, no. 4, pp. 64–71, Aug. 2017.
[31] S. Josˇilo and G. Da´n, “A game theoretic analysis of selﬁsh mobile computation ofﬂoading,” in Proc. IEEE Int. Conf. Comput. Commun., 2017, pp. 1–9.

[32] A. P. Miettinen and J. K. Nurminen, “Energy efﬁciency of mobile clients in cloud computing,” in Proc. 2nd USENIX Conf. Hot Topics Cloud Comput., Jun. 2010, pp. 1–7.
[33] Y. Wen, W. Zhang, and H. Luo, “Energy-optimal mobile application execution: Taming resource-poor mobile devices with cloud clones,” in Proc. IEEE Int. Conf. Comput. Commun., 2012, pp. 2716–2720.
[34] E. Dahlman, S. Parkvall, and J. Skold, 4G: LTE/LTE-Advanced for Mobile Broadband. New York, NY, USA: Academic, 2013.
[35] W. Saad, Z. Han, R. Zheng, M. Debbah, and H. V. Poor, “A college admissions game for uplink user association in wireless small cell networks,” in Proc. IEEE Int. Conf. Comput. Commun., 2014, pp. 1096–1104.
[36] Y. Pochet and L. A. Wolsey, Production Planning by Mixed Integer Programming. Berlin, Germany: Springer Science & Business Media, 2006.
[37] T. X. Tran, N. H. Tran, H. R. Bahrami, and S. Sastry, “On achievable rate and ergodic capacity of NAF multi-relay networks with CSI,” IEEE Trans. Commun., vol. 62, no. 5, pp. 1490–1502, May 2014.
[38] K. Tammer, “The application of parametric optimization and imbedding to the foundation and realization of a generalized primal decomposition approach,” Math. Res., vol. 35, pp. 376–386, 1987.
[39] Y. Du and G. De Veciana, “Wireless networks without edges: Dynamic radio resource clustering and user scheduling,” in Proc. IEEE Int. Conf. Comput. Commun., 2014, pp. 1321–1329.
[40] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge, U.K.: Cambridge Univ. Press, 2004.
[41] B. Bereanu, “Quasi-convexity, strictly quasi-convexity and pseudoconvexity of composite objective functions,” Revue Franc¸aise D’automatique, Informatique, Recherche Ope´rationnelle Mathe´matique, vol. 6, no. 1, pp. 15–26, 1972.
[42] J. Lee, V. S. Mirrokni, V. Nagarajan, and M. Sviridenko, “Non-monotone submodular maximization under matroid and knapsack constraints,” in Proc. Annu. ACM Symp. Theory Comput., 2009, pp. 323–332.
[43] X. Chu, D. Lo´pez-Pe´rez, Y. Yang, and F. Gunnarsson, Heterogeneous Cellular Networks: Theory, Simulation and Deployment. Cambridge, U.K.: Cambridge Univ. Press, 2013.
[44] Nokia White Paper, “Ultra dense network (UDN),” 2016. [Online]: https://onestore.nokia.com/asset/200295/Nokia Ultra Dense Network White Paper EN.pdf
Tuyen X. Tran received the M.Sc. degree in electrical and computer engineering from the University of Akron, OH, USA, in 2013, and the B.Eng. degree (Hons.) in electronics and telecommunications from the Hanoi University of Science and Technology, Hanoi, Vietnam, in 2011. He received the Ph.D. degree in electrical and computer engineering from Rutgers University, NJ, USA, in May 2018. His research interests include the area of wireless communications, mobile cloud computing, and network optimization. He is currently a Senior Inventive Scientist at AT&T Labs Research, Bedminster, NJ. During the summers of 2015–2017, he held research internships at Huawei Technologies R&D Center, Bridgewater, NJ. He received the Best Paper Award at the IEEE/IFIP Wireless On-demand Network Systems and Services Conference in 2017 and the Outstanding Graduate Student Award from the Rutgers School of Engineering in 2018.
Dario Pompili received the Ph.D. degree in electrical and computer engineering from the Georgia Institute of Technology, Atlanta, GA, USA, in 2007. He had previously received the “Laurea” (combined B.S. and M.S. degrees) and Doctorate degrees in telecommunications and system engineering from the University of Rome “La Sapienza,” Italy, in 2001 and 2004, respectively. He is currently an Associate Professor with the Department of Electrical and Computer Engineering, Rutgers U., where he directs the Cyber-Physical Systems Laboratory, which focuses on mobile computing, wireless communications and networking, acoustic communications, sensor networks, and datacenter management. He is a recipient of the NSF CAREER’11, ONR Young Investigator Program’12, and DARPA Young Faculty’12 Awards. In 2015, he was nominated Rutgers-New Brunswick Chancellor’s Scholar. He published more than 150 refereed scholar publications: with more than 8400 citations, he has an h-index of 34 and a i10-index of 72 (Google Scholar, September 2018). He is a Senior Member of the IEEE Communications Society and ACM.

Authorized licensed use limited to: KAUST. Downloaded on May 24,2022 at 11:53:14 UTC from IEEE Xplore. Restrictions apply.

