IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

2795

Efﬁcient Multi-User Computation Ofﬂoading for Mobile-Edge Cloud Computing
Xu Chen, Member, IEEE, Lei Jiao, Member, IEEE, Wenzhong Li, Member, IEEE, ACM, and Xiaoming Fu, Senior Member, IEEE

Abstract—Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we ﬁrst study the multi-user computation ofﬂoading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efﬁcient computation ofﬂoading in a distributed manner. We formulate the distributed computation ofﬂoading decision making problem among mobile device users as a multi-user computation ofﬂoading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the ﬁnite improvement property. We then design a distributed computation ofﬂoading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efﬁciency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation ofﬂoading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation ofﬂoading performance and scale well as the user size increases.
Index Terms—Computation ofﬂoading, game theory, mobile-edge cloud computing, Nash equilibrium.
I. INTRODUCTION
A S SMARTPHONES are gaining enormous popularity, more and more new mobile applications such as face recognition, natural language processing, interactive gaming, and augmented reality are emerging and attract great attention [1]–[3]. This kind of mobile applications are typically resource-hungry, demanding intensive computation and high energy consumption. Due to the physical size constraint,
Manuscript received March 17, 2015; revised September 05, 2015; accepted September 29, 2015; approved by IEEE/ACM TRANSACTIONS ON NETWORKING Editor U. Ayesta. Date of publication October 26, 2015; date of current version October 13, 2016. This work was supported in part by the EU FP7 IRSES MobileCloud Project under Grant No. 612212, the National Natural Science Foundation of China under Grants No. 61373128 and No. 61321491, the Sino-German Institutes of Social Computing, the Simulation Science Center sponsored by State Lower Saxony and Volkswagen Foundation, and the Alexander von Humboldt Foundation. (Corresponding author: Wenzhong Li.)
X. Chen and X. Fu are with the Institute of Computer Science, University of Göttingen, 37077 Göttingen, Germany (e-mail: xu.chen@cs.uni-goettingen.de; fu@cs.uni-goettingen.de).
L. Jiao was with the University of Göttingen, 37077 Göttingen, Germany. He is now with Bell Labs, Alcatel-Lucent, Dublin, Ireland (e-mail: lei.jiao@belllabs.com).
W. Li is with the State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210093, China (e-mail: lwz@nju.edu.cn).
Color versions of one or more of the ﬁgures in this paper are available online at http://ieeexplore.ieee.org.
Digital Object Identiﬁer 10.1109/TNET.2015.2487344

however, mobile devices are in general resource-constrained, having limited computation resources and battery life. The tension between resource-hungry applications and resource-constrained mobile devices hence poses a signiﬁcant challenge for the future mobile platform development [4].
Mobile cloud computing is envisioned as a promising approach to address such a challenge. By ofﬂoading the computation via wireless access to the resource-rich cloud infrastructure, mobile cloud computing can augment the capabilities of mobile devices for resource-hungry applications. One possible approach is to ofﬂoad the computation to the remote public clouds such as Amazon EC2 and Windows Azure. However, an evident weakness of public cloud based mobile cloud computing is that mobile users may experience long latency for data exchange with the public cloud through the wide area network. Long latency would hurt the interactive response, since humans are acutely sensitive to delay and jitter. Moreover, it is very difﬁcult to reduce the latency in the wide area network. To overcome this limitation, the cloudlet based mobile cloud computing was proposed as a promising solution [5]. Rather than relying on a remote cloud, the cloudlet based mobile cloud computing leverages the physical proximity to reduce delay by ofﬂoading the computation to the nearby computing sever/cluster via one-hop WiFi wireless access. However, there are two major disadvantages for the cloudlet based mobile cloud computing: 1) due to limited coverage of WiFi networks (typically available for indoor environments), cloudlet based mobile cloud computing can not guarantee ubiquitous service provision everywhere; 2) due to space constraint, cloudlet based mobile cloud computing usually utilizes a computing sever/cluster with small/medium computation resources, which may not satisfy QoS of a large number of users.
To address these challenges and complement cloudlet based mobile cloud computing, a novel mobile cloud computing paradigm, called mobile-edge cloud computing, has been proposed [6]–[9]. As illustrated in Fig. 1, mobile-edge cloud computing can provide cloud-computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this case, the need for fast interactive response can be met by fast and low-latency connection (e.g., via ﬁber transmission) to large-scale resource-rich cloud computing infrastructures (called telecom cloud) deployed by telecom operators (e.g., AT&T and T-Mobile) within the network edge and backhaul/core networks. By endowing ubiquitous radio access networks (e.g., 3G/4G macro-cell and small-cell base-stations) with powerful computing capabilities, mobile-edge cloud computing is envisioned to provide pervasive and agile computation

1063-6692 © 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

2796

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

Fig. 1. An illustration of mobile-edge cloud computing.
augmenting services for mobile device users at anytime and anywhere [6]–[9].
In this paper, we study the issue of designing efﬁcient computation ofﬂoading mechanism for mobile-edge cloud computing. One critical factor of affecting the computation ofﬂoading performance is the wireless access efﬁciency [10]. Given the fact that base-stations in most wireless networks are operating in multi-channel setting, a key challenge is how to achieve efﬁcient wireless access coordination among multiple mobile device users for computation ofﬂoading. If too many mobile device users choose the same wireless channel to ofﬂoad the computation to the cloud simultaneously, they may cause severe interference to each other, which would reduce the data rates for computation ofﬂoading. This hence can lead to low energy efﬁciency and long data transmission time. In this case, it would not be beneﬁcial for the mobile device users to ofﬂoad computation to the cloud. To achieve efﬁcient computation ofﬂoading for mobile-edge cloud computing, we hence need to carefully tackle two key challenges: 1) how should a mobile user choose between the local computing (on its own device) and the cloud computing (via computation ofﬂoading)? 2) if a user chooses the cloud computing, how can the user choose a proper channel in order to achieve high wireless access efﬁciency for computation ofﬂoading?
We adopt a game theoretic approach to address these challenges. Game theory is a powerful tool for designing distributed mechanisms, such that the mobile device users in the system can locally make decisions based on strategic interactions and achieve a mutually satisfactory computation ofﬂoading solution. This can help to ease the heavy burden of complex centralized management (e.g., massive information collection from mobile device users) by the telecom cloud operator. Moreover, as different mobile devices are usually owned by different individuals and they may pursue different interests, game theory provides a useful framework to analyze the interactions among multiple mobile device users who act in their own interests and devise incentive compatible computation ofﬂoading mechanisms such that no mobile user has the incentive to deviate unilaterally.
Speciﬁcally, we model the computation ofﬂoading decision making problem among multiple mobile device users for mobile-edge cloud computing in a multi-channel wireless environment as a multi-user computation ofﬂoading game. We then propose a distributed computation ofﬂoading algorithm that can achieve the Nash equilibrium of the game. The main results and contributions of this paper are as follows:
• Multi-User Computation Ofﬂoading Game Formulation: We ﬁrst show that it is NP-hard to ﬁnd the centralized

optimal multi-user computation ofﬂoading solutions in a multi-channel wireless interference environment. We hence consider the distributed alternative and formulate the distributed computation ofﬂoading decision making problem among the mobile device users as a multi-user computation ofﬂoading game, which takes into account both communication and computation aspects of mobile-edge cloud computing. We also extend our study to the scenario of multi-user computation ofﬂoading in the multi-channel wireless contention environment. • Analysis of Computation Ofﬂoading Game Properties: We then study the structural property of the multi-user computation ofﬂoading game and show that the game is a potential game by carefully constructing a potential function. According to the property of potential game, we show that the multi-user computation ofﬂoading game admits the ﬁnite improvement property and always possesses a Nash equilibrium. • Distributed Computation Ofﬂoading Algorithm Design: We next devise a distributed computation ofﬂoading algorithm that achieves a Nash equilibrium of the multi-user computation ofﬂoading game and derive the upper bound of the convergence time under mild conditions. We further quantify the efﬁciency ratio of the Nash equilibrium solution by the algorithm over the centralized optimal solutions in terms of two important metrics of the number of beneﬁcial cloud computing users and the system-wide computation overhead. Numerical results demonstrate that the proposed algorithm can achieve efﬁcient computation ofﬂoading performance and scale well as the user size increases. The rest of the paper is organized as follows. We ﬁrst present the system model in Section II. We then propose the multi-user computation ofﬂoading game and develop the distributed computation ofﬂoading algorithm in Sections III and IV, respectively. We next analyze the performance of the algorithm and present the numerical results in Sections V and VII, respectively. We further extend our study to the case under the wireless contention model in Section VI, discuss the related work in Section VIII, and ﬁnally conclude in Section IX.
II. SYSTEM MODEL
We ﬁrst introduce the system model. We consider a set of collocated mobile device users, where each
user has a computationally intensive task to be completed. There exists a wireless base-station and through which the mobile device users can ofﬂoad the computation to the cloud in proximity deployed by the telecom operator. Similar to many previous studies in mobile cloud computing (e.g., [9]–[17]) and mobile networking (e.g., [18] and [19]), to enable tractable analysis and get useful insights, we consider a quasi-static scenario where the set of mobile device users remains unchanged during a computation ofﬂoading period (e.g., several hundred milliseconds), while may change across different periods.1 Since both the communication and computation aspects play a key role in
1The general case that mobile users may depart and leave dynamically within a computation ofﬂoading period will be considered in a future work.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

CHEN et al.: EFFICIENT MULTI-USER COMPUTATION OFFLOADING FOR MOBILE-EDGE CLOUD COMPUTING

2797

mobile-edge cloud computing, we next introduce the communication and computation models in details.

A. Communication Model

We ﬁrst introduce the communication model for wireless

access in mobile-edge cloud computing. Here the wireless

base-station can be a 3G/4G macro-cell or small-cell base-sta-

tion [20] that manages the uplink/downlink communications of

mobile device users. There are wireless channels and the set

of channels is denoted as

. Furthermore,

we denote

as the computation ofﬂoading

decision of mobile device user . Speciﬁcally, we have

if user chooses to ofﬂoad the computation to the cloud via

a wireless channel ; we have

if user decides to

compute its task locally on its own mobile device. Given the

decision proﬁle

of all the mobile device

users, we can compute the uplink data rate of a mobile device

user that chooses to ofﬂoad the computation to the cloud via

a wireless channel

as [21]

codes and input parameters) involved in the computation task and denotes the total number of CPU cycles required to
accomplish the computation task . A mobile device user can apply the methods (e.g., call graph analysis) in [4], [24] to obtain the information of and . We next discuss the computation overhead in terms of both energy consumption and processing time for both local and cloud computing approaches.
1) Local Computing: For the local computing approach, a mobile device user executes its computation task locally on the mobile device. Let be the computation capability (i.e., CPU cycles per second) of mobile device user . Here we allow that different mobile devices may have different computation capabilities. The computation execution time of the task by local computing is then given as
(2)
For the computational energy, we have that
(3)

(1)
Here is the channel bandwidth and is user 's transmission power which is determined by the wireless base-station according to some power control algorithms such as [22] and [23].2 Further, denotes the channel gain between the mobile device user and the base-station , and denotes the background noise power. Note that here we focus on exploring the computation ofﬂoading problem under the wireless interference model, which can well capture user's time average aggregate throughput in the cellular communication scenario in which some physical layer channel access scheme (e.g., CDMA) is adopted to allow multiple users to share the same spectrum resource simultaneously and efﬁciently. In Section VI, we will also extend our study to the wireless contention model in which some media access control protocol such as CSMA is adopted in WiFi-alike networks.
From the communication model in (1), we see that if too many mobile device users choose to ofﬂoad the computation via the same wireless access channel simultaneously during a computation ofﬂoading period, they may incur severe interference, leading to low data rates. As we discuss latter, this would negatively affect the performance of mobile-edge cloud computing.
B. Computation Model
We then introduce the computation model. We consider that each mobile device user has a computation task that can be computed either locally on the mobile device or remotely on the telecom cloud via computation ofﬂoading. Here
denotes the size of computation input data (e.g., the program
2To be compatible with existing wireless systems, in this paper we consider that the power is determined to satisfy the requirements of wireless transmission (e.g., the speciﬁed SINR threshold). For the future work, we will study the joint power control and ofﬂoading decision making problem to optimize the performance of computation ofﬂoading. This joint problem would be very challenging to solve since the ofﬂoading decision making problem alone is NP-hard as we show later.

where is the coefﬁcient denoting the consumed energy per CPU cycle, which can be obtained by the measurement method in [15].
According to (2) and (3), we can then compute the overhead of the local computing approach in terms of computational time and energy as

(4)

where

denote the weighting parameters of com-

putational time and energy for mobile device user 's decision

making, respectively. When a user is at a low battery state and

cares about the energy consumption, the user can set

and

in the decision making. When a user is running some

application that is sensitive to the delay (e.g., video streaming)

and hence concerns about the processing time, then the user can

set

and

in the decision making. To provide rich

modeling ﬂexibility, our model can also apply to the general-

ized case where

such that a user can take both

computational time and energy into the decision making at the

same time. In practice the proper weights that capture a user's

valuations on computational energy and time can be determined

by applying the multi-attribute utility approach in the multiple

criteria decision making theory [25].

2) Cloud Computing: For the cloud computing approach, a

mobile device user will ofﬂoad its computation task to the

cloud in proximity deployed by telecom operator via wireless

access and the cloud will execute the computation task on behalf

of the mobile device user.

For the computation ofﬂoading, a mobile device user

would incur the extra overhead in terms of time and energy

for transmitting the computation input data to the cloud via

wireless access. According to the communication model in

Section II-A, we can compute the transmission time and energy

of mobile device user for ofﬂoading the input data of size

as, respectively,

(5)

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

2798

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

and
(6)
where is the tail energy due to that the mobile device will continue to hold the channel for a while even after the data transmission. Such a tail phenomenon is commonly observed in 3G/4G networks [26]. After the ofﬂoading, the cloud will execute the computation task . We denote as the computation capability (i.e., CPU cycles per second) assigned to user by the cloud. Similar to the mobile data usage service, the cloud computing capability is determined according to the cloud computing service contract subscribed by the mobile user from the telecom operator. Due to the fact many telecom operators (e.g., AT&T and T-Mobile) are capable for large-scale cloud computing infrastructure investment, we consider that the cloud computing resource requirements of all users can be satisﬁed. The case that a small/medium telecom operator has limited cloud computing resource provision will be considered in a future work. Then the execution time of the task of mobile device user on the cloud can be then given as
(7)
According to (5), (6), and (7), we can compute the overhead of the cloud computing approach in terms of processing time and energy as
(8)
Similar to many studies such as [11]–[14], we neglect the time overhead for the cloud to send the computation outcome back to the mobile device user, due to the fact that for many applications (e.g., face recognition), the size of the computation outcome in general is much smaller than the size of computation input data, which includes the mobile system settings, program codes and input parameters. Also, due to the fact that wireless spectrum is the most constrained resource, and higher-layer network resources are much richer and the higher-layer management can be done quickly and efﬁciently via high-speed wired connection and high-performance computing using powerful servers at the base-station, the wireless access efﬁciency at the physical layer is the bottleneck for computation ofﬂoading via wireless transmission [10]. Similar to existing studies for mobile cloud computing [9], [17], [24], we hence account for the most critical factor (i.e., wireless access at the physical layer) only.3
Based on the system model above, in the following sections we will develop a game theoretic approach for devising efﬁcient multi-user computation ofﬂoading policy for the mobile-edge cloud computing.
III. MULTI-USER COMPUTATION OFFLOADING GAME
In this section, we consider the issue of achieving efﬁcient multi-user computation ofﬂoading for the mobile-edge cloud computing.
3We can account for the high-layer factors by simply adding a processing latency term (which is typically much smaller than the wireless access) into user's time overhead function and this will not affect the analysis of the problem.

According to the communication and computation models in

Section II, we see that the computation ofﬂoading decisions

among the mobile device users are coupled. If too many mobile

device users simultaneously choose to ofﬂoad the computation

tasks to the cloud via the same wireless channel, they may incur

severe interference and this would lead to a low data rate. When

the data rate of a mobile device user is low, it would con-

sume high energy in the wireless access for ofﬂoading the com-

putation input data to cloud and incur long transmission time

as well. In this case, it would be more beneﬁcial for the user

to compute the task locally on the mobile device to avoid the

long processing time and high energy consumption by the cloud

computing approach. Based on this insight, we ﬁrst deﬁne the

concept of beneﬁcial cloud computing.

Deﬁnition 1: Given a computation ofﬂoading decision proﬁle

, the decision of user that chooses the cloud computing

approach (i.e.,

) is beneﬁcial if the cloud computing ap-

proach does not incur higher overhead than the local computing

approach (i.e.,

).

The concept of beneﬁcial cloud computing plays an impor-

tant role in the mobile-edge cloud computing. On the one hand,

from the user's perspective, beneﬁcial cloud computing ensures

the individual rationality, i.e., a mobile device user would not

suffer performance loss by adopting the cloud computing ap-

proach. On the other hand, from the telecom operator's point of

view, the larger number of users achieving beneﬁcial cloud com-

puting implies a higher utilization ratio of the cloud resources

and a higher revenue of providing mobile-edge cloud computing

service. Thus, different from traditional multi-user trafﬁc sched-

uling problem, when determining the wireless access schedule

for computation ofﬂoading, we need to ensure that for a user

choosing cloud computing, that user must be a beneﬁcial cloud

computing user. Otherwise, the user will not follow the compu-

tation ofﬂoading schedule, since it can switch to the local com-

puting approach to reduce the computation overhead.

A. Finding Centralized Optimum is NP-Hard
We ﬁrst consider the centralized optimization problem in term of the performance metric of the total number of beneﬁcial cloud computing users. We will further consider another important metric of the system-wide computation overhead later. Mathematically, we can model the problem as follows:

(9)

Here is an indicator function with

if the event

is true and

otherwise.

Unfortunately, it turns out that the problem of ﬁnding the

maximum number of beneﬁcial cloud computing users can be

extremely challenging.

Theorem 1: The problem in (9) that computes the maximum

number of beneﬁcial cloud computing users is NP-hard.

Proof: To proceed, we ﬁrst introduce the maximum car-

dinality bin packing problem [27]: we are given items with

sizes for

and bins of identical capacity , and the

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

CHEN et al.: EFFICIENT MULTI-USER COMPUTATION OFFLOADING FOR MOBILE-EDGE CLOUD COMPUTING

2799

objective is to assign a maximum number of items to the ﬁxed Besides the performance metric of the number of beneﬁcial

number of bins without violating the capacity constraint. Math- cloud computing users, in this paper we also consider another

ematically, we can formulate the problem as

important metric of the system-wide computation overhead, i.e.,

(10)

It is known from [27] that the maximum cardinality bin packing

problem above is NP-hard.

For our problem, according to Theorem 1, we know that a

user that can achieve beneﬁcial cloud computing if and only

if its received interference

. Based

on this, we can transform the maximum cardinality bin packing

problem to a special case of our problem of ﬁnding the max-

imum number of beneﬁcial cloud computing users as follows.

We can regard the items and the bins in the maximum cardinality

bin packing problem as the mobile device users and channels in

our problem, respectively. Then the size of an item and the

capacity constraint of each bin can be given as

and

, respectively. By this, we can ensure that as

long as a user on its assigned channel achieves the beneﬁ-

cial cloud computing, for an item , the total sizes of the items

on its assigned bin will not violate the capacity constraint

. This is due to the fact that

,

which implies that .
Therefore, if we have an algorithm that can ﬁnd the maximum number of beneﬁcial cloud computing users, then we can also obtain the optimal solution to the maximum cardinality bin packing problem. Since the maximum cardinality bin packing problem is NP-hard, our problem is hence also NP-hard.
The key idea of proof is to show that the maximum cardinality bin packing problem (which is known to be NP-hard [27]) can be reduced to a special case of our problem. Theorem 1 provides the major motivation for our game theoretic study, because it suggests that the centralized optimization problem is fundamentally difﬁcult. By leveraging the intelligence of each individual mobile device user, game theory is a powerful tool for devising distributed mechanisms with low complexity, such that the users can self-organize into a mutually satisfactory solution. This can also help to ease the heavy burden of complex centralized computing and management by the cloud operator. Moreover, another key rationale of adopting the game theoretic approach is that the mobile devices are owned by different individuals and they may pursue different interests. Game theory is a useful framework to analyze the interactions among multiple mobile device users who act in their own interests and devise incentive compatible computation ofﬂoading mechanisms such that no user has the incentive to deviate unilaterally.

(11)

Note that the centralized optimization problem for minimizing

the system-wide computation overhead is also NP-hard, since

it involves a combinatorial optimization over the multi-di-

mensional discrete space (i.e.,

). As shown in

Sections V and VII, the proposed game theoretic solution can

also achieve superior performance in terms of the performance

metric of the system-wide computation overhead.

B. Game Formulation

We then consider the distributed computation ofﬂoading

decision making problem among the mobile device users. Let

be the computation

ofﬂoading decisions by all other users except user . Given

other users' decisions , user would like to select a proper

decision , by using either the local computing (

)

or the cloud computing via a wireless channel (

) to

minimize its computation overhead, i.e.,

According to (4) and (8), we can obtain the overhead function of mobile device user as

if if

(12)

We then formulate the problem above as a strategic game

, where the set of mobile device

users is the set of players, is the set of strategies for player

, and the overhead function

of each user is the

cost function to be minimized by player . In the sequel, we call

the game as the multi-user computation ofﬂoading game. We

now introduce the important concept of Nash equilibrium.

Deﬁnition 2: A strategy proﬁle

is a Nash

equilibrium of the multi-user computation ofﬂoading game if

at the equilibrium , no user can further reduce its overhead

by unilaterally changing its strategy, i.e.,

(13)

According to the concept of Nash equilibrium, we ﬁrst have

the following observation.

Corollary 1: For the multi-user computation ofﬂoading

game, if a user at Nash equilibrium chooses cloud com-

puting approach (i.e.,

), then the user must be a

beneﬁcial cloud computing user.

This is because if a user choosing the cloud computing ap-

proach is not a beneﬁcial cloud computing user at the equilib-

rium, then the user can improve its beneﬁt by just switching

to the local computing approach, which contradicts with the

fact that no user can improve unilaterally at the Nash equi-

librium. Furthermore, the Nash equilibrium also ensures the

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

2800

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

nice self-stability property such that the users at the equilibrium can achieve a mutually satisfactory solution and no user has the incentive to deviate. This property is very important to the multi-user computation ofﬂoading problem, since the mobile devices are owned by different individuals and they may act in their own interests.

C. Structural Properties

We next study the existence of Nash equilibrium of the multi-

user computation ofﬂoading game. To proceed, we shall resort

to a powerful tool of potential game [28].

Deﬁnition 3: A game is called a potential game if it admits

potential function

such that for every

,

, and

, if

(14) we have

(15)

An appealing property of the potential game is that it always

admits a Nash equilibrium and possesses the ﬁnite improve-

ment property, such that any asynchronous better response up-

date process (i.e., no more than one player updates the strategy

to reduce the overhead at any given time) must be ﬁnite and

leads to a Nash equilibrium [28].

To show the multi-user computation ofﬂoading game is a po-

tential game, we ﬁrst show the following result.

Lemma 1: Given a computation ofﬂoading decision proﬁle

, a user achieves beneﬁcial cloud computing if its received

interference

on the chosen

wireless channel

satisﬁes that

, with the

threshold

game is indeed a potential game by constructing the potential function as

(16)

Theorem 2: The multi-user computation ofﬂoading game is a

potential game with the potential function as given in (16), and

hence always has a Nash equilibrium and the ﬁnite improvement

property.

Proof: Suppose that a user

updates its current deci-

sion to the decision and this leads to a decrease in its over-

head function, i.e.,

. According to

the deﬁnition of potential game, we will show that this also

leads to a decrease in the potential function, i.e.,

. We will consider the following three cases: 1)

and

; 2)

and

; 3)

and

.

For case 1), since the function of

is monotonously

increasing in terms of , according to (1), we know that the

condition

implies that

(17)

Since

and

know that

, according to (16) and (17), we then

Proof: According to (4), (8), and Deﬁnition 1, we know

that the condition

is equivalent to

That is,

According to (1), we then have that

For case 2), since

,

, we know that

implies that

, and

(18) . This

According to Lemma 1, we see that when the received inter-

ference

of user on a wireless channel is lower enough,

(19)

it is beneﬁcial for the user to adopt cloud computing approach

and ofﬂoad the computation to the cloud. Otherwise, the user

For case 3), by the similar argument in case 2), when

should compute the task on the mobile device locally. Based on and

, we can also show that

Lemma 1, we show that the multi-user computation ofﬂoading implies

.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

CHEN et al.: EFFICIENT MULTI-USER COMPUTATION OFFLOADING FOR MOBILE-EDGE CLOUD COMPUTING

2801

Algorithm 1 Distributed Computation Ofﬂoading Algorithm

1: initialization:

2: each mobile device user chooses the computation

decision

.

3: end initialization

4: repeat for each user and each decision slot in parallel:

5: transmit the pilot signal on the chosen channel

to the wireless base-station .

6: receive the information of the received powers on all

the channels from the wireless base-station .

7: compute the best response set

.

8: if

then

9:

send RTU message to the cloud for contending for

the decision update opportunity.

10:

if receive the UP message from the cloud then

11:

choose the decision

for next

slot.

12:

else choose the original decision

for next slot.

13:

end if

14: else choose the original decision

for next slot.

15: end if

16: until END message is received from the cloud

1) Wireless Interference Measurement: at this stage, we

measure the interference on different channels for wireless

access. Speciﬁcally, each mobile device user who selects

decision

(i.e., cloud computing approach) at the

current decision slot will transmit some pilot signal on its

chosen channel

to the wireless base-station . The

wireless base-station then measures the total received power

on each channel

and

feedbacks the information of the received powers on all the

channels (i.e.,

) to the mobile device users.

Accordingly, each user can obtain its received interference

from other users on each channel

as

if otherwise.

That is, for its current chosen channel

, user determines

the received interference by subtracting its own power from the

total measured power; for other channels over which user does

not transmit the pilot signal, the received interference is equal

to the total measured power.

2) Ofﬂoading Decision Update: at this stage, we exploit the

ﬁnite improvement property of the multi-user computation of-

ﬂoading game by having one mobile device user carry out a de-

cision update. Based on the information of the measured inter-

ferences

on different channels, each

mobile device user ﬁrst computes its set of best response up-

date as

Combining results in the three cases above, we can hence conclude that the multi-user computation ofﬂoading game is a potential game.
The key idea of the proof is to show that when a user updates its current decision to a better decision , the decrease in its overhead function will lead to the decrease in the potential function of the multi-user computation ofﬂoading game. Theorem 2 implies that any asynchronous better response update process is guaranteed to reach a Nash equilibrium within a ﬁnite number of iterations. We shall exploit such ﬁnite improvement property for the distributed computation ofﬂoading algorithm design in following Section IV.
IV. DISTRIBUTED COMPUTATION OFFLOADING ALGORITHM
In this section we develop a distributed computation ofﬂoading algorithm in Algorithm 1 for achieving the Nash equilibrium of the multi-user computation ofﬂoading game.
A. Algorithm Design
The motivation of using the distributed computation ofﬂoading algorithm is to enable mobile device users to achieve a mutually satisfactory decision making, prior to the computation task execution. The key idea of the algorithm design is to utilize the ﬁnite improvement property of the multi-user computation ofﬂoading game and let one mobile device user improve its computation ofﬂoading decision at a time. Specifically, by using the clock signal from the wireless base-station for synchronization, we consider a slotted time structure for the computation ofﬂoading decision update. Each decision slot consists the following two stages:

and

Then, if

(i.e., user can improve its decision),

user will send a request-to-update (RTU) message to the cloud

to indicate that it wants to contend for the decision update op-

portunity. Otherwise, user will not contend and adhere to the

current decision at next decision slot, i.e.,

.

Next, the cloud will randomly select one user out of the set of

users who have sent the RTU messages and send the update-per-

mission (UP) message to the user for updating its decision for

the next slot as

. For other users who do not

receive the UP message from the cloud, they will not update

their decisions and choose the same decisions at next slot, i.e.,

.

B. Convergence Analysis
According to the ﬁnite improvement property in Theorem 2, the algorithm will converge to a Nash equilibrium of the multiuser computation ofﬂoading game within ﬁnite number of decision slots. In practice, we can implement that the computation ofﬂoading decision update process terminates when no RTU messages are received by the cloud. In this case, the cloud will broadcast the END message to all the mobile device users and each user will execute the computation task according to the decision obtained at the last decision slot by the algorithm. Due to the property of Nash equilibrium, no user has the incentive to deviate from the achieved decisions.
We then analyze the computational complexity of the distributed computation ofﬂoading algorithm. In each decision

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

2802

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

slot, each mobile device user will in parallel execute the op-

erations in Lines 5–15 of Algorithm 1. Since most operations

only involve some basic arithmetical calculations, the dom-

inating part is the computing of the best response update in

Line 11, which involves the sorting operation over channel

measurement data and typically has a complexity of

. The computational complexity in each decision slot

is hence

. Suppose that it takes decision slots

for the algorithm to terminate. Then the total computational

complexity of the distributed computation ofﬂoading algorithm

is

. Let

,

,

, and

. For

the number of decision slots for convergence, we have the

following result.

Theorem 3: When and are non-negative integers for

any

, the distributed computation ofﬂoading algorithm

will terminate within at most

decision

slots, i.e.,

.

Proof: First of all, according to (16), we know that

(20)

During a decision slot, suppose that a user

updates its

current decision to the decision and this leads to a decrease

in its overhead function, i.e.,

. Ac-

cording to the deﬁnition of potential game, we will show that

this also leads to a decrease in the potential function by at least

, i.e.,

(21)

We will consider the following three cases: 1)

and

; 2)

and

; 3)

and

.

For case 1), according to (18) in the proof of Theorem 2, we

know that

For case 3), by the similar argument in case 2), we can also

show that

.

Thus, according to (20) and (21), we know that the algorithm

will terminate by driving the potential function

to a min-

imal point within at most

decision slots.

Theorem 3 shows that under mild conditions the distributed

computation ofﬂoading algorithm can converge in a fast manner

with at most a quadratic convergence time (i.e., upper bound).

Note that in practice the transmission power and channel gain

are non-negative (i.e.,

), we hence have

. The non-negative condition of

ensures

that a user could have the chances to achieve beneﬁcial cloud

computing (otherwise, the user should always choose the local

computing). For ease of exposition, we consider that and

are integers, which can also provide a good approximation for

the general case that and could be real number. For the

general case, numerical results in Section VII demonstrate that

the distributed computation ofﬂoading algorithm can also con-

verge in a fast manner with the number of decision slots for con-

vergence increasing (almost) linearly with the number of users

. Since the time length of a slot in wireless systems is typi-

cally at time scale of microseconds (e.g., the length of a slot is

around 70 microseconds in LTE system [29]), this implies that

the time for the computation ofﬂoading decision update process

is very short and can be neglectable, compared with the com-

putation execution process, which is typically at the time scale

of millisecond/seconds (e.g., for mobile gaming application, the

execution time is typically several hundred milliseconds [30]).

V. PERFORMANCE ANALYSIS
We then analyze the performance of the distributed computation ofﬂoading algorithm. Following the deﬁnition of price of anarchy (PoA) in game theory [31], we will quantify the efﬁciency ratio of the worst-case Nash equilibrium over the centralized optimal solutions in terms of two important metrics: the number of beneﬁcial cloud computing users and the system-wide computation overhead.

Since are integers for any

, we know that

Thus, according to (22), we have

A. Metric I: Number of Beneﬁcial Cloud Computing Users

(22)

We ﬁrst study the PoA in terms of the metric of the number

of beneﬁcial cloud computing users in the system. Let be the

set of Nash equilibria of the multi-user computation ofﬂoading

game and

denote the the centralized optimal

solution that maximizes the number of beneﬁcial cloud com-

puting users. Then the PoA is deﬁned as

For case 2), according to (19) in the proof of Theorem 2, we know that
By the similar augment as in case 1), we have

For the metric of the number of beneﬁcial cloud com-

puting users, a larger PoA implies a better performance of

the multi-user computation ofﬂoading game solution. Re-

call that

,

,

, and

.

We can show the following result.

Theorem 4: Consider the multi-user computation ofﬂoading

game, where

for each user

. The PoA for the

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

CHEN et al.: EFFICIENT MULTI-USER COMPUTATION OFFLOADING FOR MOBILE-EDGE CLOUD COMPUTING

2803

metric of the number of beneﬁcial cloud computing users satis- Thus, we have ﬁes that
(25)

Proof: Let

be an arbitrary Nash equilibrium of

the game. Since the centralized optimum maximizes the

number of beneﬁcial cloud computing users, we hence have that

and

. Moreover,

if

, we have

and

. In following proof, we will focus on the case that

.

First, we show that for the centralized optimum ,

we have

, where

is the number of channels. To proceed, we ﬁrst denote

as the number of users on channel

for a given decision proﬁle . Since

, we have

for

, i.e., there exists at

least a user that can achieve beneﬁcial cloud computing by

letting the user choose cloud computing and the other

users choose local computing. This implies that for the cen-

tralized optimum , we have

. Let

, i.e., channel is the one with most users. Suppose user is on the channel . Then

we know that

Based on (24) and (25), we can conclude that

, which completes the proof.

Recall that the constraint

ensures that some user

can achieve beneﬁcial cloud computing in the centralized op-

timum, and avoid the possibility of the PoA involving “division

by zero”. Theorem 4 implies that the worst-case performance of

the Nash equilibrium will be close to the centralized optimum

when the gap between the best and worst users in terms of

wireless access performance

and interference tolerance

threshold for achieving beneﬁcial cloud computing is not

large.

B. Metric II: System-Wide Computation Overhead

We then study the PoA in terms of another metric of the

total computation overhead of all the mobile device users in the

system, i.e.,

. Let be the centralized optimal so-

lution that minimizes the system-wide computation overhead,

i.e.,

. Similarly, we can

deﬁne the PoA as

which implies that It follows that

Note that, different from the metric of the number of beneﬁcial cloud computing users, a smaller system-wide computation overhead is more desirable. Hence, for the metric of the system-wide computation overhead, a smaller PoA is better. Let
and

We hence have that

(23)

(24)

Second, for the Nash equilibrium , since

, there exists at lease one user that chooses the local com-

puting approach, i.e.,

. Since is a Nash equilibrium, we

have that user cannot reduce its overhead by choosing compu-

tation ofﬂoading via any channel

. We then know that

We can show the following result. Theorem 5: For the multi-user computation ofﬂoading game,
the PoA of the metric of the system-wide computation overhead satisﬁes that

which implies that It follows that

Proof: Let

be an arbitrary Nash equilibrium of the

game. Since the centralized optimum minimizes the system-

wide computation overhead, we hence ﬁrst have that

.

For a Nash equilibrium

, if

, we shall show that

the interference that a user receives from other other users on

the wireless access channel is at most

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

2804

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

We prove this by contradiction. Suppose that a user at the Nash equilibrium receives an interference greater than
. Then, we have that

For the centralized optimal solution , if that

(26)

According to the property of Nash equilibrium such that no user can improve by changing the channel unilaterally, we also have that

which implies that

, we have

This implies that

(27) According to (26) and (27), we now reach a contradiction that

Moreover, if

and

, then the system-wide

computation overhead can be further reduced by letting user

switch to the local computing approach (i.e.,

). This is

because such a switching will not increase extra interference to

other users. We thus know that

(29)

According to (28) and (29), we can conclude that

Thus, a user at the Nash equilibrium receives an interference

not greater than

. Based on this, if

, we hence have that

which implies that

Intuitively, Theorem 5 indicates that when the resource for

wireless access increases (i.e., the number of wireless access

channels is larger and hence

is smaller), the worst-

case performance of Nash equilibrium can be improved. More-

over, when users have lower cost of local computing (i.e.,

is smaller), the worst-case Nash equilibrium is closer to the cen-

tralized optimum and hence the PoA is lower.

Moreover, if

and

, then the user can

always improve by switching to the local computing approach

(i.e.,

), we thus know that

(28)

VI. EXTENSION TO WIRELESS CONTENTION MODEL
In the previous sections above, we mainly focus on exploring the distributed computation ofﬂoading problem under the wireless interference model as given in (1). Such wireless interference model is widely adopted in literature (see [21], [32] and references therein) and can well capture user's time average aggregate throughput in the cellular communication scenario in which some physical layer channel access scheme (e.g., CDMA) is adopted to allow multiple users to share the same spectrum resource simultaneously and efﬁciently. In this case, the multiple access among users for the shared spectrum is carried out over the signal/symbol level (e.g., at the time scale of microseconds), rather than the packet level (e.g., at the time scale of milliseconds/seconds).

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

CHEN et al.: EFFICIENT MULTI-USER COMPUTATION OFFLOADING FOR MOBILE-EDGE CLOUD COMPUTING

2805

In this section, we extend our study to the wireless contention

model in which the multiple access among users for the shared

spectrum is carried out over the packet level. This is most rel-

evant to the scenario that some media access control protocol

such as CSMA is implemented such that users content to capture

the channel for data packet transmission for a long period (e.g.,

hundreds of milliseconds or several seconds) in the WiFi-like

networks (e.g., White-Space Network [33]). In this case, we can

model a user's expected throughput for computation ofﬂoading

over the chosen wireless channel

as follows

(30)

where is the data rate that user can achieve when it can

successfully gab the channel, and

denotes user's weight

in the channel contention/sharing, with a larger weight im-

plying that user is more dominant in grabbing the channel.

When

for any user , it is relevant to the equal-sharing

case (e.g., round robin scheduling).

Similarly, we can apply the communication and computation

models in the previous sections above to compute the over-

head for both local and cloud computing approaches, and model

the distributed computation ofﬂoading problem as a strategic

game. For such multi-user computation ofﬂoading game under

the wireless contention model, we can show that it exhibits the

same structural property as the case under the wireless interfer-

ence model. We can ﬁrst deﬁne the received “interference” (i.e.,

aggregated contention weights) of user on the chosen channel

as

. Then we can show the same

threshold structure for the game as follow.

Lemma 2: For the multi-user computation ofﬂoading game

under the wireless contention model, a user achieves beneﬁ-

cial cloud computing if its received interference

on the

chosen channel

satisﬁes that

, with the

threshold

By exploiting the threshold structure above and following the similar arguments in the proof of Theorem 2, we can also show that the multi-user computation ofﬂoading game under the wireless contention model is a potential game.
Theorem 6: The multi-user computation ofﬂoading game under the wireless contention model is a potential game under the wireless contention model with the potential function as given in (31), and hence always has a Nash equilibrium and the ﬁnite improvement property.

under the wireless interference model. Moreover, by deﬁning , the potential function in (31) is the same as that
in (16). Thus, by regarding the aggregated contention weights as the received interference, we
can apply the distributed computation ofﬂoading algorithm in Section IV to achieve the Nash equilibrium, which possesses the same performance and convergence guarantee for the case under the wireless contention model.

VII. NUMERICAL RESULTS

In this section, we evaluate the proposed distributed compu-

tation ofﬂoading algorithm by numerical studies. We ﬁrst con-

sider the scenario where the wireless small-cell base-station has

a coverage range of 50 m [34] and

mobile device

users are randomly scattered over the coverage region [34]. The

base-station consists of

channels and the channel band-

width

MHz. The transmission power

mWatts

and the background noise

dBm [21]. According

to the wireless interference model for urban cellular radio envi-

ronment [21], we set the channel gain

, where

is the distance between mobile device user and the wireless

base-station and

is the path loss factor.

For the computation task, we consider the face recognition

application in [2], where the data size for the computation of-

ﬂoading

KB and the total number of CPU cycles

Megacycles. The CPU computational capability

of a mobile device user is randomly assigned from the set

{0.5, 0.8, 1.0} GHz to account for the heterogenous computing

capability of mobile devices, and the computational capability

allocated for a user on the cloud is

GHz [2]. For the

decision weights of each user for both the computation time

and energy, we set that

and is randomly as-

signed from the set {1, 0.5, 0}. In this case, if

(

,

respectively), a user only cares about the computation energy

(computation time, respectively); if

, then user cares

both the computation time and energy.

We ﬁrst show the dynamics of mobile device users' compu-

tation overhead

by the proposed distributed computa-

tion ofﬂoading algorithm in Fig. 2. We see that the algorithm

can converge to a stable point (i.e., Nash equilibrium of the

multi-user computation ofﬂoading game). Fig. 3 shows the dy-

namics of the achieved number of beneﬁcial cloud computing

users by the proposed algorithm. It demonstrates that the algo-

rithm can keep the number of beneﬁcial cloud computing users

in the system increasing and converge to an equilibrium. We fur-

ther show the dynamics of the system-wide computation over-

head

by the proposed algorithm in Fig. 4. We see

that the algorithm can also keep the system-wide computation

overhead decreasing and converge to an equilibrium.

We then compare the distributed computation ofﬂoading al-

gorithm with the following solutions:

(31)
Based on Lemma 2 and Theorem (6), we observe that the multi-user computation ofﬂoading game under the wireless contention model exhibits the same structural property as the case

A. Local Computing by All Users
each user chooses to compute its own task locally on the mobile phone. This could correspond to the scenario that each user is risk-averse and would like to avoid any potential performance degradation due to the concurrent computation ofﬂoadings by other users.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

2806

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

Fig. 2. Dynamics of users' computation overhead.

Fig. 5. Average number of beneﬁcial cloud computing users with different number of users.

Fig. 3. Dynamics of the number of beneﬁcial cloud computing users.

Fig. 6. Average system-wide computation overhead with different number of users.

Fig. 4. Dynamics of system-wide computation overhead.
B. Cloud Computing by All Users
each user chooses to ofﬂoad its own task to the cloud via a randomly selected wireless channel. This could correspond to the scenario that each user is myopic and ignores the impact of other users for cloud computing.
C. Cross Entropy Based Centralized Optimization
we compute the centralized optimum by the global optimization using Cross Entropy (CE) method, which is an advanced randomized searching technique and has been shown to be efﬁcient in ﬁnding near-optimal solutions to complex combinatorial optimization problems [35].
We run experiments with different number of [34], respectively. We repeat
each experiment 100 times for each given user number and show the average number of beneﬁcial cloud computing users and the average system-wide computation overhead in Figs. 5 and 6, respectively. We see that, for the metric of the number of beneﬁcial cloud computing users, the distributed

computation ofﬂoading solution can achieve up-to 30% performance improvement over the solutions by cloud computing by all users, respectively. For the metric of the system-wide computation overhead, the distributed computation ofﬂoading solution can achieve up-to 68% and 55%, and 51% overhead reduction over with the solutions by local computing by all users, and cloud computing by all users, respectively. Moreover, compared with the centralized optimal solution by CE method, the performance loss of the distributed computation ofﬂoading solution is at most 12% and 14%, for the metrics of number of beneﬁcial cloud computing users and system-wide computation overhead, respectively. This demonstrates the efﬁciency of the proposed distributed computation ofﬂoading algorithm. Note that for the distributed computation ofﬂoading algorithm, a mobile user makes the computation ofﬂoading decision locally based on its local parameters. While for CE based centralized optimization, the complete information is required and hence all the users need to report all their local parameters to the cloud. This would incur high system overhead for massive information collection and may raise the privacy issue as well. Moreover, since the mobile devices are owned by different individuals and they may pursue different interests, the users may not have the incentive to follow the centralized optimal solution. While, due to the property of Nash equilibrium, the distributed computation ofﬂoading solution can ensure the self-stability such that no user has the incentive to deviate unilaterally.
We next evaluate the convergence time of the distributed computation ofﬂoading algorithm in Fig. 7. It shows that the average number of decision slots for convergence increases

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

CHEN et al.: EFFICIENT MULTI-USER COMPUTATION OFFLOADING FOR MOBILE-EDGE CLOUD COMPUTING

2807

Fig. 7. Average number of decision slots for convergence with different number of users.
(almost) linearly as the number of mobile device users increases. This demonstrates that the distributed computation ofﬂoading algorithm converges in a fast manner and scales well with the size of mobile device users in practice.4
VIII. RELATED WORK
Many previous work has investigated the single-user computation ofﬂoading problem (e.g., [10]–[16]). Barbera et al. in [10] showed by realistic measurements that the wireless access plays a key role in affecting the performance of mobile cloud computing. Rudenko et al. in [11] demonstrated by experiments that signiﬁcant energy can be saved by computation ofﬂoading. Gonzalo et al. in [12] developed an adaptive ofﬂoading algorithm based on both the execution history of applications and the current system conditions. Xian et al. in [13] introduced an efﬁcient timeout scheme for computation ofﬂoading to increase the energy efﬁciency on mobile devices. Huang et al. in [14] proposed a Lyapunov optimization based dynamic ofﬂoading algorithm to improve the mobile cloud computing performance while meeting the application execution time. Wen et al. in [15] presented an efﬁcient ofﬂoading policy by jointly conﬁguring the clock frequency in the mobile device and scheduling the data transmission to minimize the energy consumption. Wu et al. in [16] applied the alternating renewal process to model the network availability and developed ofﬂoading decision algorithm accordingly.
To the best of our knowledge, only a few works have addressed the computation ofﬂoading problem under the setting of multiple mobile device users [9]. Yang et al. in [24] studied the scenario that multiple users share the wireless network bandwidth, and solved the problem of maximizing the mobile cloud computing performance by a centralized heuristic genetic algorithm. Our previous work in [17] considered the multi-user computation ofﬂoading problem in a single-channel wireless setting, such that each user has a binary decision variable (i.e., to ofﬂoad or not). Given the fact that base-stations in most wireless networks are operating in the multi-channel wireless environment, in this paper we study the generalized multi-user computation ofﬂoading problem in a multi-channel setting, which results in signiﬁcant differences in analysis. For example, we
4For example, the length of a slot is at the time scale of microseconds in LTE system [29] and hence the convergence time of the proposed algorithm is very short.

show the generalized problem is NP-hard, which is not true for the single-channel case. We also investigate the price of anarchy in terms of two performance metrics and show that the number of available channels can also impact the price of anarchy (e.g., Theorem 5). We further derive the upper bound of the convergence time of the computation ofﬂoading algorithm in the multi-channel environment. Barbarossa et al. in [9] studied the multi-user computation ofﬂoading problem in a multi-channel wireless environment, by assuming that the number of wireless access channels is greater than the number of users such that each mobile user can ofﬂoad the computation via a single orthogonal channel independently without experiencing any interference from other users. In this paper we consider the more practical case that the number of wireless access channels is limited and each user mobile may experience interference from other users for computation ofﬂoading.
IX. CONCLUSION
In this paper, we propose a game theoretic approach for the computation ofﬂoading decision making problem among multiple mobile device users for mobile-edge cloud computing. We formulate the problem as as a multi-user computation ofﬂoading game and show that the game always admits a Nash equilibrium. We also design a distributed computation ofﬂoading algorithm that can achieve a Nash equilibrium, derive the upper bound of convergence time, and quantify its price of anarchy. Numerical results demonstrate that the proposed algorithm achieves superior computation ofﬂoading performance and scales well as the user size increases.
For the future work, we are going to consider the more general case that mobile users may depart and leave dynamically within a computation ofﬂoading period. In this case, the user mobility patterns will play an important role in the problem formulation. Another direction is to study the joint power control and ofﬂoading decision making problem, which would be very interesting and technically challenging.
REFERENCES
[1] K. Kumar and Y. Lu, “Cloud computing for mobile users: Can ofﬂoading computation save energy?,” IEEE Comput., vol. 43, no. 4, pp. 51–56, Apr. 2010.
[2] T. Soyata, R. Muraleedharan, C. Funai, M. Kwon, and W. Heinzelman, “Cloud-vision: Real-time face recognition using a mobile-cloudlet-cloud acceleration architecture,” in Proc. IEEE ISCC, 2012, pp. 000059–000066.
[3] J. Cohen, “Embedded speech recognition applications in mobile phones: Status, trends, and challenges,” in Proc. IEEE ICASSP, 2008, pp. 5352–5355.
[4] E. Cuervo et al., “MAUI: Making smartphones last longer with code ofﬂoad,” in Proc. 8th Int. Conf. Mobile Syst., Appl., Services, 2010, pp. 49–62.
[5] M. Satyanarayanan, P. Bahl, R. Caceres, and N. Davies, “The case for VM-based cloudlets in mobile computing,” IEEE Pervasive Comput., vol. 8, no. 4, pp. 14–23, Oct.–Dec. 2009.
[6] European Telecommunications Standards Institute, “Mobile-edge computing—Introductory technical white paper,” 2014.
[7] U. Drolia et al., “The case for mobile edge-clouds,” in Proc. 10th IEEE Int. Conf. Ubiquitous Intell. Comput., 2013, pp. 209–215.
[8] Ericsson, “The telecom cloud opportunity,” Mar. 2012 [Online]. Available: http://www.ericsson.com/res/site_AU/docs/2012/ericsson_telecom_cloud_discussion_paper.pdf
[9] S. Barbarossa, S. Sardellitti, and P. D. Lorenzo, “Joint allocation of computation and communication resources in multiuser mobile cloud computing,” in Proc. IEEE Workshop SPAWC, 2013, pp. 26–30.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

2808

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 24, NO. 5, OCTOBER 2016

[10] M. V. Barbera, S. Kosta, A. Mei, and J. Stefa, “To ofﬂoad or not to ofﬂoad? the bandwidth and energy costs of mobile cloud computing,” in Proc. IEEE INFOCOM, 2013, pp. 1285–1293.
[11] A. Rudenko, P. Reiher, G. J. Popek, and G. H. Kuenning, “Saving portable computer battery power through remote process execution,” Mobile Comput. Commun. Rev., vol. 2, no. 1, pp. 19–26, 1998.
[12] G. Huertacanepa and D. Lee, “An adaptable application ofﬂoading scheme based on application behavior,” in Proc. 22nd Int. Conf. Adv. Inf. Netw. Appl.–Workshops, 2008, pp. 387–392.
[13] C. Xian, Y. Lu, and Z. Li, “Adaptive computation ofﬂoading for energy conservation on battery-powered systems,” in Proc. IEEE ICDCS, 2007, vol. 2, pp. 1–8.
[14] D. Huang, P. Wang, and D. Niyato, “A dynamic ofﬂoading algorithm for mobile computing,” IEEE Trans. Wireless Commun., vol. 11, no. 6, pp. 1991–1995, Jun. 2012.
[15] Y. Wen, W. Zhang, and H. Luo, “Energy-optimal mobile application execution: Taming resource-poor mobile devices with cloud clones,” in Proc. IEEE INFOCOM, 2012, pp. 2716–2720.
[16] H. Wu, D. Huang, and S. Bouzefrane, “Making ofﬂoading decisions resistant to network unavailability for mobile cloud collaboration,” in Proc. IEEE Collaboratecom, 2013, pp. 168–177.
[17] X. Chen, “Decentralized computation ofﬂoading game for mobile cloud computing,” IEEE Trans. Parallel Distrib. Syst., vol. 26, no. 4, pp. 974–983, Apr. 2014.
[18] S. Wu, Y. Tseng, C. Lin, and J. Sheu, “A multi-channel MAC protocol with power control for multi-hop mobile ad hoc networks,” Comput. J., vol. 45, no. 1, pp. 101–110, 2002.
[19] G. Iosiﬁdis, L. Gao, J. Huang, and L. Tassiulas, “An iterative double auction mechanism for mobile data ofﬂoading,” in Proc. IEEE WiOpt, 2013, pp. 154–161.
[20] D. López-Pérez, X. Chu, A. V. Vasilakos, and H. Claussen, “On distributed and coordinated resource allocation for interference mitigation in self-organizing LTE networks,” IEEE/ACM Trans. Netw., vol. 21, no. 4, pp. 1145–1158, Aug. 2013.
[21] T. S. Rappaport, Wireless Communications: Principles and Practice. Upper Saddle River, NJ, USA: Prentice-Hall, 1996.
[22] M. Xiao, N. B. Shroff, and E. K. Chong, “A utility-based power-control scheme in wireless cellular systems,” IEEE/ACM Trans. Netw., vol. 11, no. 2, pp. 210–221, Apr. 2003.
[23] M. Chiang, P. Hande, T. Lan, and C. W. Tan, “Power control in wireless cellular networks,” Found. Trends Netw., vol. 2, no. 4, pp. 381–533, 2008.
[24] L. Yang et al., “A framework for partitioning and execution of data stream applications in mobile cloud computing,” Perform. Eval. Rev., vol. 40, no. 4, pp. 23–32, 2013.
[25] J. Wallenius et al., “Multiple criteria decision making, multiattribute utility theory: Recent accomplishments and what lies ahead,” Manage. Sci., vol. 54, no. 7, pp. 1336–1349, 2008.
[26] W. Hu and G. Cao, “Quality-aware trafﬁc ofﬂoading in wireless networks,” in Proc. ACM Mobihoc, 2014, pp. 277–286.
[27] K.-H. Loh, B. Golden, and E. Wasil, “Solving the maximum cardinality bin packing problem with a weight annealing-based algorithm,” in Operations Research and Cyber-Infrastructure. New York, NY, USA: Springer, 2009.
[28] D. Monderer and L. S. Shapley, “Potential games,” Games Econ. Behav., vol. 14, no. 1, pp. 124–143, 1996.
[29] T. Innovations, “LTE in a nutshell,” White Paper, 2010. [30] S. Dey, Y. Liu, S. Wang, and Y. Lu, “Addressing response time of
cloud-based mobile applications,” in Proc. 1st Int. Workshop Mobile Cloud Comput. Netw., 2013, pp. 3–10. [31] T. Roughgarden, Selﬁsh Routing and the Price of Anarchy. Cambridge, MA, USA: MIT Press, 2005. [32] J. G. Andrews et al., “What will 5G be?,” IEEE J. Sel. Areas Commun., vol. 32, no. 6, pp. 1065–1082, Jun. 2014. [33] P. Bahl, R. Chandra, T. Moscibroda, R. Murty, and M. Welsh, “White space networking with Wi-Fi like connectivity,” Comput. Commun. Rev., vol. 39, no. 4, pp. 27–38, 2009. [34] T. Q. Quek, G. de la Roche, I. Güvenç, and M. Kountouris, Small Cell Networks: Deployment, PHY Techniques, and Resource Management. Cambridge, U.K.: Cambridge Univ. Press, 2013. [35] R. Y. Rubinstein and D. P. Kroese, The Cross-Entropy Method: A Uniﬁed Approach to Combinatorial Optimization, Monte-Carlo Simulation and Machine Learning. New York, NY, USA: Springer, 2004.

Xu Chen received the Ph.D. degree in information engineering from the Chinese University of Hong Kong (Hong Kong, China) in 2012, and worked as a Postdoctoral Research Associate at Arizona State University, Tempe, USA from 2012 to 2014. He is currently a Humboldt Scholar Fellow at Institute of Computer Science of University of Göttingen, Germany. He serves as an Associate Editor of EURASIP Journal on Wireless Communications and Networking, the guest editor of International Journal of Big Data Intelligence, the special track co-chair of International Symposium on Visual Computing (ISCV'15), the publicity co-chair of International Conference on Network Games, Control and Optimization (NETGCOOP'14), and TPC members for many conferences including MOBIHOC, GLOBECOM, ICC, and WCNC. He is also the recipient of the Honorable Mention Award (ﬁrst runner-up of best paper award) in 2010 IEEE international conference on Intelligence and Security Informatics (ISI), the Best Paper Runner-up Award of 2014 IEEE International Conference on Computer Communications (INFOCOM), and 2014 Hong Kong Young Scientist Award Runner-up.
Lei Jiao received the B.Sc. and M.Sc. degrees from Northwestern Polytechnical University, Xi'an, China, in 2007 and 2010, respectively, and the Ph.D. degree from University of Göttingen, Göttingen, Germany, in 2014, all in computer science. He is now a researcher with Bell Labs, Dublin, Ireland. Prior to Ph.D. study, he was a researcher with IBM Research, Beijing, China. His research interests span networking and distributed computing, with a recent focus on performance modeling, analysis, optimization, and evaluation.
Wenzhong Li received his B.S. and Ph.D. degree from Nanjing University, China, both in computer science. He was an Alexander von Humboldt Scholar Fellow in University of Göttingen, Germany. He is now an Associate Professor in the Department of Computer Science, Nanjing University. Dr. Li's research interests include wireless networks, pervasive computing, mobile cloud computing, and social networks. He has published over 40 peer-review papers at international conferences and journals, which include INFOCOM, ICDCS, IWQoS, ICPP, IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS, etc. He is a member of IEEE, ACM, and China Computer Federation (CCF). He was also the winner of the Best Paper Award of ICC 2009.
Xiaoming Fu received the Ph.D. degree from Tsinghua University, Beijing, China. He was a research staff at the Technical University Berlin until joining the University of Göttingen, Germany in 2002, where he has been a Professor in computer science and heading the Computer Networks Group since 2007. His research interests include network architectures, protocols, and applications. He is currently an Editorial Board member of IEEE Communications Magazine, IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT, Elsevier Computer Networks, and Computer Communications, and has published more than 100 papers in journals and international conference proceedings. He is the coordinator of EU FP7, GreenICN, and MobileCloud projects, and received ACM ICN 2014 Best Paper Award, IEEE LANMAN 2013 Best Paper Award and the 2005 University of Göttingen Foundation Award for Exceptional Publications by Young Scholars. He is a senior member of the IEEE.

Authorized licensed use limited to: KAUST. Downloaded on May 27,2022 at 12:35:24 UTC from IEEE Xplore. Restrictions apply.

