2022 26th International Conference on Pattern Recognition (ICPR) | 978-1-6654-9062-7/22/$31.00 ©2022 IEEE | DOI: 10.1109/ICPR56361.2022.9956625

2022 26th International Conference on Pattern Recognition (ICPR) August 21-25, 2022, Montréal, Québec, Canada
I-SPLIT: Deep Network Interpretability for Split Computing
Federico Cunico, Luigi Capogrosso, Francesco Setti, Damiano Carra, Franco Fummi, Marco Cristani Department of Computer Science, University of Verona name.surname@univr.it

Abstract—This work makes a substantial step in the field of split computing, i.e., how to split a deep neural network to host its early part on an embedded device and the rest on a server. So far, potential split locations have been identified exploiting uniquely architectural aspects, i.e., based on the layer sizes. Under this paradigm, the efficacy of the split in terms of accuracy can be evaluated only after having performed the split and retrained the entire pipeline, making an exhaustive evaluation of all the plausible splitting points prohibitive in terms of time. Here we show that not only the architecture of the layers does matter, but the importance of the neurons contained therein too. A neuron is important if its gradient with respect to the correct class decision is high. It follows that a split should be applied right after a layer with a high density of important neurons, in order to preserve the information flowing until then. Upon this idea, we propose Interpretable Split (I-SPLIT): a procedure that identifies the most suitable splitting points by providing a reliable prediction on how well this split will perform in terms of classification accuracy, beforehand of its effective implementation. As a further major contribution of I-SPLIT, we show that the best choice for the splitting point on a multiclass categorization problem depends also on which specific classes the network has to deal with. Exhaustive experiments have been carried out on two networks, VGG16 and ResNet-50, and three datasets, Tiny-Imagenet-200, notMNIST, and Chest X-Ray Pneumonia. The source code is available at https://github.com/vips4/I-Split.

I. INTRODUCTION
In the last decade, Deep Neural Networks (DNNs) achieved state-of-the-art performance in a broad range of problems. However, DNN computational requirements preclude their device-only deployment on most of the resource-constraint systems, such as mobile phones [1]. The opposite cloud-only paradigm transfers the sensory data to a server [2], which processes them and sends the output back to the device. In this case, the high data transfer time and possible server congestion are obvious downsides. Between the two extremes lies the fog computing paradigm [3], where computation is distributed over a large number of low-power devices, and communication is routed over the internet backbone.
As a compromise between the device-only and the cloudonly approaches or to drive the design of a fog computing architecture, the split computing (SC) framework [4], [5], [6] proposes to divide a DNN model into a “head” and a “tail”, deployed at the edge device and the server, respectively. Using SC, the computational load is distributed across the two platforms, exploiting the computational power of both devices at the cost of transferring data on a network connection. Data transfer effort is mitigated by the injection of bottlenecks,

Fig. 1. I-SPLIT teaser: the DNN architecture is divided into a “head” part running on the edge device and a “tail” part running on a server machine. Intermediate data representation is sent through a network connection. The optimal splitting point is determined by analyzing the value of the CUmulated Importance curve (CUI), which indicates the importance of each layer in predicting the correct class. The higher the CUI, the higher the amount of accuracy of the original model preserved when splitting at that layer.
usually implemented as autoencoders [7], achieving in-model compression. It is worth noting that SC is even gaining more and more relevance in the 5G Telecom scenario, which is intrinsically based on the edge/cloud paradigm, thus requiring SC by design [8].
Setting up a SC system requires determining the optimal splitting point: so far, this choice was driven primarily by architectural considerations such as memory capabilities of the edge device, desired transmission rate between head and tail, and size of the layers [5]. In all of these cases, deciding a splitting point is blind to a crucial feature a deep network has to preserve: its classification accuracy. For example, two consecutive layers of the same size are equally likely to be chosen as splitting points, and the accuracy of the final system has to be verified only after retraining the head, bottleneck, and tail. This brings to a cumbersome trial-and-error cycle.

978-1-6654-9062-7/22/$31.00 ©2022 IEEE

2575

Authorized licensed use limited to: KAUST. Downloaded on March 02,2023 at 07:32:51 UTC from IEEE Xplore. Restrictions apply.

In this paper, we propose a fast procedure to select the split location for a generic DNN architecture that, for the first time, is predictive of the accuracy that the system will have once retrained (see Fig. 1), thus eliminating the need for multiple trials and error retraining sessions of the system. The procedure is dubbed I-SPLIT, where “I” stands for interpretability. I-SPLIT builds upon the concept of importance or saliency of a neuron [9], which is related to the gradient it possesses with respect to the decision towards the correct class, for specific input. Importance is exploited with success in the Grad-CAM approach [9]: Grad-CAM creates an input neuron saliency map that indicates which parts of an input image are more important for deciding a specific class. In particular, the GradCAM approach has been proved to be strongly dependent on the given trained model on which it runs (it passes the “sanity check” test [10]), while other approaches do not, making it perfectly suited to our purposes.
I-SPLIT exploits Grad-CAM by creating, for a given image, multiple saliency maps, one for each layer of the network, which we rename as importance maps. Each layer-based importance map can be accumulated in a single value, accounting for how many important neurons it is formed by. Therefore, a single image gives rise to multiple CUmulated Importance (CUI) values, one for each layer, that can be rearranged into a CUI curve. Multiple validation images create multiple CUI curves, that summed together do create a statistic of how much a layer is, in general, decisive for the right class. A layer that exhibits a high CUI value needs to be preserved, i.e., the bottleneck should be injected right after this layer. Higher CUI values are predictors of high accuracy, and the ranking over CUI allows to easily select the optimal splitting point.
Several are the advantages of I-SPLIT. The process is computationally efficient: the evaluation of the CUI values for N potential splitting points requires one step of backpropagation for each image of a given validation set, instead of N complete retraining sessions; in practice, for 10 potential splitting points to evaluate, I-SPLIT requires 150 minutes on a VGG network, instead of 6 hours needed to for the retraining. Moreover, we are able to discriminate, among layers of the same size which one is best suitable as the splitting point. Finally, and most interestingly, our approach shows that optimal splitting points are conditioned on the specific classes that the network is expected to process: indeed, specific classes trigger specific neurons, which in turn highlight layers which are possibly different. This provides the fresh-new concept of class-dependent split decision, which allows us to adapt the splitting point depending on the classes taken into account.
The experiments are conducted on two popular network architectures (VGG16 [11] and ResNet-50 [12]), and three classification benchmarks (Tiny-Imagenet-200 [13], notMNIST [14], and Chest X-Ray Pneumonia [15]), confirming each of the claims discussed above and surpassing previous empirical split strategies as in [5].
In summary, the contributions of this paper are:
• I-SPLIT, a principled and fast way to individuate splitting points in a DNN, together with an indication of how the

networks split and those points will perform in terms of classification accuracy; • With I-SPLIT, we show that specific classes bring different splitting points.
II. RELATED WORK
This section provides an overview of existing state-of-theart split computing approaches along with a discussion of different interpretation methods for neural networks. Interested readers can refer to surveys [1] and [16].
A. Split Computing Methods
A typical split computing scenario is discussed in [17], where the authors show that neither cloud-only nor device-only approaches are optimal, and a split configuration is the ideal solution. In [18], it is shown that the early layers of a DNN are the most suitable for a split since they optimize latency and energy consumption. Furthermore, latency can be reduced by either quantization [19] or lossy compression before data transmission [20], [21]. The use of autoencoders as a way to further diminish the data to be transferred is discussed in [7], [22], [23]. All these approaches have an impact on the overall accuracy, therefore some works explore the trade-off between latency and accuracy [5], [24], [25]. The impact on the accuracy is also mitigated by additional techniques, such as knowledge distillation [26], [27]. To find candidate splitting points, the most used approach is the “Cut, Distil and Encode” (CDE) [5]. It states that candidate split locations are where the size of the DNN layers decreases: the rationale is that compressing information by autoencoders, where compression would still occur due to the shrinking of the architecture, certainly seems reasonable.
Notably, all these approaches first identify a set of candidate splitting points, then they re-train the split models to find the one with the highest accuracy. In this paper, we present a way to individuate the best splitting point before any retraining.
B. Interpretability Methods
In deep learning, interpretability refers to the “intrinsic properties of a deep model measuring to which degree the inference result of the model is predictable or understandable to human beings” [28]. It can be distinguished into intrinsic and post-hoc [29]: intrinsic interpretability applies to models that have a simple analytical form such as short decision trees or sparse linear models [30]; post-hoc interpretability refers to the application of interpretation methods once a model has been trained [31]. In this paper, we focus on post-hoc methodologies, and in particular, on gradient-based techniques [10], also known as “saliency-based” approaches. These techniques are based on the computation of the partial derivative of the prediction yc for the class c with respect to image input x, that is, ∂yc/∂x [32]. The derivative indicates how much a change in each input feature would change yc; simple but effective, an approach that exploits this principle is the Gradients technique [10]. The element-wise product of the input and the gradient represents another popular method [33]:

2576

Authorized licensed use limited to: KAUST. Downloaded on March 02,2023 at 07:32:51 UTC from IEEE Xplore. Restrictions apply.

Fig. 2. Overview of our I-SPLIT framework. The input images are fed into a neural network to extract high-resolution importance maps using the Grad-CAM algorithm at each layer. Then, we average over all the image pixels of each map to produce per-image CUI curves. Finally, all curves are fused to generate the general CUI curve. The best splitting point for the network is the global maximum of the CUI curve.

the idea is that the gradient communicates the importance of a dimension, and the input indicates how strongly this dimension is expressed in the input image. In the same paper, it is proposed the DeepLift approach, which explains the difference in the saliency map from some reference maps in terms of the difference between the input image from some reference input. The Integrated Gradients method [34] addresses the sensitivity and the implementation invariance properties of saliency maps. The sensitivity states that if a single feature of an input is responsible for deciding a class, it has to be highlighted. The implementation invariance means that saliency maps should be the same independently on the models if the models have the same input/output pairs. Guided Backpropagation [35] focuses on the quality of the saliency maps, combining vanilla backpropagation and DeconvNets to obtain saliency maps with a high level of detail. The Grad-CAM technique, at the basis of our approach, operates a downstream summation of classspecific coefficients multiplied by activation maps [9]. Notably, the Grad-CAM approach has been proved to pass the “sanity check” for saliency-based interpretability approaches [10], together with the Gradients technique. In practice, this check ensures that the saliency maps provided as output depend on the specific model instance taken into account, while other saliency-based approaches do not. Since our split strategy operates on a given specific model by finding split points as summations over these saliency maps, this kind of dependence is crucial and desirable.
III. METHODOLOGY
The final goal of I-SPLIT is to individuate and rank potential splitting points in a generic DNN architecture so that the accuracy values obtained by the DNN, once split at those points, follow a similar ranking. The input of the approach is a network that has been trained beforehand on some training images. The overview of the approach is shown in Fig. 2: each image in a pool of evaluation images, we compute importance

maps associated with each layer of the network instead of being associated with input images only. These importance maps are then aggregated to form per-image CUI curves (the light-colored curves). Then, these curves are averaged together over the classes giving the general CUI curve on the right in yellow. Each point of the CUI curve is found to be proportional to the accuracy that the network will have, on the same data, once the split has been applied and the network re-trained. The highest point in the CUI curve identifies the location where the split will provide the best performing system.
In the following, we will give the mathematical details to generate the CUI curve. Then we will detail how to compute the split in correspondence to a given location (Sec. III-B) and how to re-train the network (Sec. III-C).

A. CUI Curve Computation

We assume our neural network model is pre-trained on

a given training set. The CUI curve is computed on some

validation set composed of C classes, each formed by NC images. For each c-th class, we do as follows.

For a given i-th layer of the neural network, i = 1, . . . , I,

we extract the class-discriminative activation map Lij,c for each j-th image belonging to class c ∈ C. For this sake, we start

by computing the feature map importance coefficient of Grad-

CAM αci,j :

αci,j

=

1 z

n

∂yc m ∂Fni,,jm

(1)

where F i,j ∈ Rn×m×z is the feature map of the convolutional
layer i for the image j. The weight αci,j represents a partial linearization of the deep
network downstream from F and captures the value of the
feature map of the i-th layer for a target class c. Then, we
perform a weighted sum between the value just calculated and the feature maps F i,j of the chosen layer. Finally, ReLU

2577

Authorized licensed use limited to: KAUST. Downloaded on March 02,2023 at 07:32:51 UTC from IEEE Xplore. Restrictions apply.

activation function is applied to reset the negative values of the gradient to zero obtaining the class activation map Lij,c for a specific query image j:

I

Lij,c = ReLU

αck,j F k,j

(2)

k=i

This represents the analog of the saliency map of the standard

Grad-CAM [9], which instead of being computed on the input

image, is focused on the i-th layer, summing from the class

activations of the networks back until i.

Now we aim to obtain a single value for our class activation map Lij,c: thus, we simply sum over the dimensions of F i,j ∈ Rn×m×z, obtaining the per-image CUI values CUIij,c. Ideally, computing these values for each i-th layer of the network gives

a curve showing how the image has triggered the different

layers of the network (see Fig. 2, the pool of curves below

each class). At this point, averaging over all the images of

all the classes provides our final cumulated importance CUI

curve (Fig. 2 the yellow curve on the right), where the ith point CUIi of the curve is a surrogate of the information

conveyed through the i-th layer towards the decision for the

correct class, for all the classes into play. It is worth noting

that, possibly, one may limit to compute CUI curve only on

specific classes (or set of classes), obtaining per-class curves CUIic.

B. Split Application

Once the CUI curve has been computed, candidate splitting points can be individuated by (i) choosing the layer which gives the highest peak or (ii) selecting layers that give local CUI maxima, if other constraints than the accuracy have to be taken into account.
Let T i be the target layer for splitting the model at index i and T i+1 the subsequent layer. We divide the network into three main blocks: The head, running on the edge device, is composed of the first layers of the original DNN architecture, up to layer T i; the bottleneck, an under-complete autoencoder [36] that learns low-dimensional latent attributes which explain the input data; and the tail, from layer T i+1 to the very end of the network, that is executed on the serverside. The encoder part of the bottleneck is deployed to the edge device, while the decoder is executed on the serverside. Encoders and decoders use both spatial and channel-wise reduction/restoration units, respectively.

C. Re-Training Strategy

In order to train the entire model M , we first train our

bottleneck, and then we fine-tune end-to-end the entire net-

work. We create an under-complete autoencoder which acts as a bottleneck inserted after T i. This bottleneck should learn

to replicate the input, which is the feature map in output at layer T i. Therefore, given {Ij, j = 1, 2, ..., n} as the n
number of training data, we train the sole bottleneck freezing

the remaining network with the following loss:

1 LAE = n

n

||ΦT i (Ij ) − Ψ(ΦT i (Ij ); W AE)||2

(3)

j=1

Fig. 3. Candidate splitting points identified by CDE and the CUI curve of I-SPLIT on the VGG16. In dashed purple, the accuracy values are obtained by splitting the network at that point, re-training it, and testing on a validation set. The “star” markers show the extra points that our method is able to identify, and not identified by the CDE approach.

with ΦT i the model layers up to the i-th layer T i (target layer), Ψ is the AE part of the model with weights W AE.
After training the bottleneck, we perform a fine-tuning of
the network with the following loss function:

1 Ltask = n

n

||ΦM (Ij; W M ) − yˆj||2

(4)

j=1

with ΦM the full M ’s DNN layers, W M the weights of the model M and yˆj the ground truth label for the image j.

IV. EXPERIMENTAL RESULTS
In this section, we show how I-SPLIT individuates split points by the CUI curve so that the associated CUI values are predictive of the classification accuracy when the network is split at those points. This hypothesis is evaluated on three benchmarks and two classification networks (Sec. IV-A). Moreover, we show that the CUI curve and the associated best split point (correspondent to the highest CUI peak) do depend on the classes on which we are focusing (Sec. IV-B).
In all the experiments, the bottlenecks injected in the split networks are standard convolutional under-complete autoencoders with two convolutional layers with stride 2 for the encoder and two layers for the decoder. The number of filters depends on the desired compression rate: specifically, we keep constant the compression rate at 90%, which means that the dimensionality of the encoded data is 10% of the dimension of the splitting layer.

A. Splitting Point Analysis
Since our framework is agnostic with respect to the network architecture, we consider the VGG16 and the ResNet-50 networks, with most of the experiments run on the first one. Other than being very popular architectures, they are also interesting for SC: they exhibit a large number of parameters, a good depth in terms of the number of layers, with a dramatic variation in the layer dimensionality as depth increases.
The first experiment focuses on the Tiny-Imagenet-200 dataset [13], a compact version of ImageNet that comprises

2578

Authorized licensed use limited to: KAUST. Downloaded on March 02,2023 at 07:32:51 UTC from IEEE Xplore. Restrictions apply.

Fig. 4. The sensibility of our I-SPLIT method to the chosen interpretability approach: in gray the CUI using the Gradients approach. In yellow, GradCAM. As visible, Grad-CAM gives a better curve in terms of proportionality w.r.t. the final class accuracy, while Gradients is growing as soon as the layer is deeper.
a subset of 200 classes, with a training set of 100.000 images, a validation, and a test set of 10.000 images each. All the images are 64×64 pixels.
As a comparative approach, we consider CDE [5], which individuates splitting points whereas there is a decrease in the size of the layers (see Sec. II for more details). The multi-axis Fig. 3 reports the CDE curve in blue, with the markers indicating the candidate split points. Our I-SPLIT is reported with the curve in solid yellow, with the red markers individuating local maxima of the CUI curve to simplify the visualization. Importantly, we report also the accuracy curve, in dashed purple, obtained by retraining the network after splitting it at the selected locations.
Several facts do emerge: (i) Our I-SPLIT identifies all candidate splitting points output by CDE (namely layers 5, 9 and 13, corresponding to block2 pool, block3 pool, and block4 pool, respectively): these are max-pooling layers in the VGG architecture, which are worth conveying more information-per-pixel since there is a local dimensionality reduction with limited loss of information. (ii) I-SPLIT finds two additional points at layers 11 and 15, or block4 conv2 and block5 conv2, that do not correspond to a decrease in the layer size. (iii) Looking at the accuracy curve, it becomes apparent the significance of the CUI curve: all the candidate splitting points are proportional to the post-hoc accuracy obtained by the split network, while CDE does not exhibit such behavior at all. (iv) While the absolute values of classification accuracy are relatively close to each other, we provided a statistical analysis generating 15 testing sets by randomly sampling 800 images from the validation set. Box plots in Fig. 3 demonstrate how the distributions are well separated, and thus the relatively small improvement in accuracy is statistically relevant.
I-SPLIT strongly relies on the Grad-CAM interpretability approach. To evaluate the efficacy of another interpretability technique if injected in I-SPLIT, we perform a second experiment. In Fig. 4 we report the result obtained with Gradients, the other approach that together with Grad-CAM passes the “sanity check” of the interpretability approaches [10]. In

Fig. 5. The behavior of I-SPLIT on preserving the per-class performance before the split (original model, in blue) and after the split (split model, in orange). As expected, no dramatic changes in the single performance are visible, especially with the best and worse performing classes: the best performance does not become the worst after the split, and vice-versa.
practice, this approach amounts to remove from Eq. (2) the feature map variable F k,j. This brings to a sort of CUI curve where we summed the gradients associated with a given input without multiplying it by the features themselves.
As visible, Grad-CAM gives a better curve in terms of proportionality w.r.t. the final class accuracy, while Gradients is growing as soon as the layer is deeper, making it hard to spot the best split point. This is due to the vanishing gradient effect: gradients are much higher when closer to the network’s end. For this reason we prefer Grad-CAM, since the multiplication of the gradients by the values of the feature (close to 0) provides a more constrained range of CUI values.
The third experiment investigates how the classification performance of a DNN does change, once it is split by our approach. In particular, we focus on the performance of every single class. As a split location, we select the layer 15, where the CUI curve has the highest peak. After training the original VGG network, we rank the 200 classes in descending F1 order (the blue line of Fig. 5). As visible, the performance is unbalanced, since the F1 scores range from a few decimals to 87%. On the (re-trained) split version we calculate new F1 scores, reporting them in the figure whilst keeping the previous class ranking to highlight possible variations in the performance (the orange line of Fig. 5). The plot is very interesting: actually, classes that were best or worst performing before the split do not change seriously their performance after the split, providing F1 scores which are still high/low. For classes with an average performance, the split shuffled a little the F1 scores. Overall, a certain degree of variability is expected, since (i) the CUI curve indicating the optimal split point requires a summation over all the classes, so the perclass performance cannot be precisely preserved. (ii) It seems that for specific classes the optimal splitting point may be different. We will focus on this aspect in the second part of the experiments.
The fourth and fifth experiments check how I-SPLIT will perform with datasets with fewer classes, possibly unbalanced in terms of cardinality. For this sake, we apply our method to notMNIST [14] (10 classes) and Chest X-Ray Pneumonia [15] (2 classes, unbalanced). The notMNIST dataset is focused on the task of digit recognition with heterogeneous fonts and graphics, while Chest X-Ray focuses on classifying pneumonia

2579

Authorized licensed use limited to: KAUST. Downloaded on March 02,2023 at 07:32:51 UTC from IEEE Xplore. Restrictions apply.

Fig. 6. The efficacy of I-SPLIT on different datasets. Both the figures show the CUI curve of I-SPLIT (solid yellow) and the accuracy when splitting between a particular layer, retraining, and testing (dashed purple). On the left, the notMNIST [14] dataset. On the right, the Chest X-Ray Pneumonia [15] dataset. In both the cases, the CUI curve shows to be proportional to the accuracy.

Fig. 8. The comparison of splitting results for different subsets of classes. Top: CUI curve computed on two different subsets of 15 classes of the VGG16 architecture. Bottom: classification accuracy for two models trained on the same subsets of 15 classes on layers 13 and 15.

Fig. 7. Results of the CDE [5], I-SPLIT, and accuracy on the ResNet-50. In particular, the local minimum points of CDE correspond to the local maximum points of I-SPLIT, and the CUI curve shows to be once again proportional to the accuracy. The “star” markers show the extra points that our method is able to identify, and not identified by the CDE approach.
cases from chest x-rays. Chest X-Ray is unbalanced (cases: 3883, controls: 1349), and this is a further challenge for the I-SPLIT robustness.
In both cases, the employed deep network is the VGG16. Results are reported in the form of CUI curves in Fig. 6, paired with the a posteriori accuracy. In both cases, the CUI curves are proportional to the accuracy. This further promotes I-SPLIT as a prognostic tool toward a split configuration which maximizes the classification accuracy.
On the ResNet-50 architecture [12], we show the CUI curve, the CDE [5] comparative approach, and the post-split accuracy curve (Fig. 7). As visible, the local maxima of the CUI curve (indicated by the red markers) indicate plausible split locations. Overall, the CUI curve follows the slope of the accuracy, showing even in this case nice predictive properties. Additionally, we can observe that the CUI is almost constant in layers with the same features dimensionality, but it is also relatively uniform between different blocks.

identified two different behaviors in the last portion of the network. In particular, when referring to block5, we saw that most of the classes achieved a higher CUI at layer 15, while 15 classes had a global maximum at layer 13 (see Fig. 8top). We investigated this phenomenon by generating two alternative models by splitting the network at both points and then retraining these models with two subsets of 15 classes, one for each different behavior. Results, shown in Fig. 8bottom, demonstrate that the same shape of the I-SPLIT curve translates to the accuracy curve.
V. CONCLUSION
In this paper we presented I-SPLIT, a new split computing method to identify the best splitting point in order to preserve higher classification accuracy in a DNN. Our approach exploits interpretability principles, specifically Grad-CAM approach, to extract an estimate of the importance of each layer of the network related to a classification task. The assumption is that feature maps with high importance values (dubbed CUI) are more suitable to be compressed and sent through a communication network. With respect to the state-of-the-art, ISPLIT introduces major benefits: (i) it is inherently faster than most of the competitors because it does not require retraining the model on more than one splitting point; (ii) it is able to discriminate between layers with the same size, which are usually considered equivalent; and (iii) it can provide different optimal splitting points according to priors on the classes the system is expected to deal with. Future works will include further investigation of interpretability methods as a way to extract additional metrics to be used in the generation of the ISPLIT curve, and the development of a bottleneck architecture specifically designed to preserve classification accuracy rather than preserving the input data.

B. Class-Dependent Splitting Point Selection
In this work, we also claim that different subsets of classes can lead to different selections of the best splitting point, as guessed in the previous section. To validate this claim we analyzed the I-SPLIT curve for each class separately and we

ACKNOWLEDGEMENTS
The work has been partially supported by the Italian Ministry of Education, University and Research (MIUR) with the grant “Dipartimenti di Eccellenza” 2018-2022 and by Fondazione Cariverona with the grant “Ricerca & Sviluppo”.

2580

Authorized licensed use limited to: KAUST. Downloaded on March 02,2023 at 07:32:51 UTC from IEEE Xplore. Restrictions apply.

REFERENCES
[1] Y. Matsubara, M. Levorato, and F. Restuccia, “Split computing and early exiting for deep learning applications: Survey and research challenges,” arXiv preprint arXiv:2103.04505, 2021.
[2] W.-T. Tsai, X. Sun, and J. Balasooriya, “Service-oriented cloud computing architecture,” in 2010 seventh international conference on information technology: new generations. IEEE, 2010, pp. 684–689.
[3] S. P. Singh, A. Nayyar, R. Kumar, and A. Sharma, “Fog computing: from architecture to edge computing and big data processing,” The Journal of Supercomputing, vol. 75, no. 4, pp. 2070–2105, 2019.
[4] J. Shao and J. Zhang, “Bottlenet++: An end-to-end approach for feature compression in device-edge co-inference systems,” in 2020 IEEE International Conference on Communications Workshops (ICC Workshops). IEEE, 2020, pp. 1–6.
[5] M. Sbai, M. R. U. Saputra, N. Trigoni, and A. Markham, “Cut, distil and encode (cde): Split cloud-edge deep inference,” in 2021 18th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON). IEEE, 2021, pp. 1–9.
[6] Y. Matsubara, R. Yang, M. Levorato, and S. Mandt, “Supervised compression for resource-constrained edge computing systems,” in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2022, pp. 2685–2695.
[7] Y. Matsubara, S. Baidya, D. Callegaro, M. Levorato, and S. Singh, “Distilled split deep neural networks for edge-assisted real-time systems,” in Proceedings of the 2019 Workshop on Hot Topics in Video Analytics and Intelligent Edges, 2019, pp. 21–26.
[8] K. X. Du, G. Carrozzo, M. S. Siddiqui, O. Carrasco, B. Sayadi, F. Lazarakis, A. Kourtis, J. Sterle, and R. Bruschi, “Definition and evaluation of latency in 5g: A framework approach,” in 2019 IEEE 2nd 5G World Forum (5GWF). IEEE, 2019, pp. 135–140.
[9] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra, “Grad-cam: Visual explanations from deep networks via gradient-based localization,” in Proceedings of the IEEE international conference on computer vision, 2017, pp. 618–626.
[10] J. Adebayo, J. Gilmer, M. Muelly, I. Goodfellow, M. Hardt, and B. Kim, “Sanity checks for saliency maps,” arXiv preprint arXiv:1810.03292, 2018.
[11] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale image recognition,” arXiv preprint arXiv:1409.1556, 2014.
[12] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.
[13] Y. Le and X. Yang, “Tiny imagenet visual recognition challenge,” CS 231N, vol. 7, no. 7, p. 3, 2015.
[14] “notMNIST dataset,” https://www.kaggle.com/datasets/jwjohnson314/ notmnist, accessed: 2022-04-14.
[15] “Chest X-Ray Images (Pneumonia) dataset,” https://www.kaggle.com/ datasets/paultimothymooney/chest-xray-pneumonia, accessed: 2022-0414.
[16] C. Olah, A. Satyanarayan, I. Johnson, S. Carter, L. Schubert, K. Ye, and A. Mordvintsev, “The building blocks of interpretability,” Distill, vol. 3, no. 3, p. e10, 2018.
[17] A. E. Eshratifar, M. S. Abrishami, and M. Pedram, “Jointdnn: An efficient training and inference engine for intelligent mobile cloud computing services,” IEEE Transactions on Mobile Computing, 2019.
[18] Y. Kang, J. Hauswald, C. Gao, A. Rovinski, T. Mudge, J. Mars, and L. Tang, “Neurosurgeon: Collaborative intelligence between the cloud and mobile edge,” ACM SIGARCH Computer Architecture News, vol. 45, no. 1, pp. 615–629, 2017.
[19] G. Li, L. Liu, X. Wang, X. Dong, P. Zhao, and X. Feng, “Auto-tuning neural network quantization framework for collaborative inference between the cloud and edge,” in International Conference on Artificial Neural Networks. Springer, 2018, pp. 402–411.
[20] H. Choi and I. V. Bajic´, “Deep feature compression for collaborative object detection,” in 2018 25th IEEE International Conference on Image Processing (ICIP). IEEE, 2018, pp. 3743–3747.
[21] R. A. Cohen, H. Choi, and I. V. Bajic´, “Lightweight compression of neural network feature tensors for collaborative intelligence,” in 2020 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 2020, pp. 1–6.
[22] A. E. Eshratifar, A. Esmaili, and M. Pedram, “Bottlenet: A deep learning architecture for intelligent mobile cloud computing services,” in 2019

IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED). IEEE, 2019, pp. 1–6. [23] M. Jankowski, D. Gu¨ndu¨z, and K. Mikolajczyk, “Joint device-edge inference over wireless links with pruning,” in 2020 IEEE 21st International Workshop on Signal Processing Advances in Wireless Communications (SPAWC). IEEE, 2020, pp. 1–5. [24] D. Hu and B. Krishnamachari, “Fast and accurate streaming cnn inference via communication compression on the edge,” in 2020 IEEE/ACM Fifth International Conference on Internet-of-Things Design and Implementation (IoTDI). IEEE, 2020, pp. 157–163. [25] S. Yao, J. Li, D. Liu, T. Wang, S. Liu, H. Shao, and T. Abdelzaher, “Deep compressive offloading: Speeding up neural network inference by trading edge computation for network latency,” in Proceedings of the 18th Conference on Embedded Networked Sensor Systems, 2020, pp. 476–488. [26] Y. Matsubara, R. Yang, M. Levorato, and S. Mandt, “Supervised compression for resource-constrained edge computing systems,” arXiv preprint arXiv:2108.11898, 2021. [27] Y. Matsubara and M. Levorato, “Neural compression and filtering for edge-assisted real-time object detection in challenged networks,” in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021, pp. 2272–2279. [28] X. Li, H. Xiong, X. Li, X. Wu, X. Zhang, J. Liu, J. Bian, and D. Dou, “Interpretable deep learning: Interpretation, interpretability, trustworthiness, and beyond,” arXiv preprint arXiv:2103.10689, 2021. [29] G. Stiglic, P. Kocbek, N. Fijacko, M. Zitnik, K. Verbert, and L. Cilar, “Interpretability of machine learning-based prediction models in healthcare,” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 10, no. 5, p. e1379, 2020. [30] D. V. Carvalho, E. M. Pereira, and J. S. Cardoso, “Machine learning interpretability: A survey on methods and metrics,” Electronics, vol. 8, no. 8, p. 832, 2019. [31] G. Peake and J. Wang, “Explanation mining: Post hoc interpretability of latent factor models for recommendation systems,” in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2018, pp. 2060–2069. [32] D. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, and K.-R. Mu¨ller, “How to explain individual classification decisions,” The Journal of Machine Learning Research, vol. 11, pp. 1803–1831, 2010. [33] A. Shrikumar, P. Greenside, A. Shcherbina, and A. Kundaje, “Not just a black box: Learning important features through propagating activation differences,” arXiv preprint arXiv:1605.01713, 2016. [34] M. Sundararajan, A. Taly, and Q. Yan, “Axiomatic attribution for deep networks,” in International Conference on Machine Learning. PMLR, 2017, pp. 3319–3328. [35] J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller, “Striving for simplicity: The all convolutional net,” arXiv preprint arXiv:1412.6806, 2014. [36] W. H. L. Pinaya, S. Vieira, R. Garcia-Dias, and A. Mechelli, “Autoencoders,” in Machine learning. Elsevier, 2020, pp. 193–208.

2581

Authorized licensed use limited to: KAUST. Downloaded on March 02,2023 at 07:32:51 UTC from IEEE Xplore. Restrictions apply.

